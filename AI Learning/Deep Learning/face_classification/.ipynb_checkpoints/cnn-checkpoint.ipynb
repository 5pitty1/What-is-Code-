{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_cnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2zG_gzb9nXB"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNLkDijm9oJF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA NOT supported\n",
      "Nnet(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 21, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(21, 20, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Conv2d(20, 15, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(15, 7, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1575, out_features=300, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=300, out_features=201, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "net=Nnet().to(computing_device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(net)\n",
    "\n",
    "#loss criteria are defined in the torch.nn package\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#Instantiate the gradient descent optimizer - use Adam optimizer with default parameters\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'root_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-484ea312f5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshuffle_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'root_dir'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(256), transforms.ToTensor()])\n",
    "dataset = loader('train.csv',transform=transform)\n",
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStatistics(labels, outputs):\n",
    "    decisions = outputs.argmax(axis=1)\n",
    "\n",
    "    for i in range (1,201):\n",
    "        truePositives[i-1] += int(torch.sum((decisions == i) & (decisions == labels)))\n",
    "        falsePositives[i-1] += int(torch.sum((decisions == i) & (decisions != labels)))\n",
    "        falseNegatives[i-1] += int(torch.sum((labels == i) & (decisions != labels)))\n",
    "\n",
    "\n",
    "def printStatistics():\n",
    "    acc = accuracy(truePositives, batch_size)\n",
    "    prec = precision(truePositives, falsePositives)\n",
    "    rec = recall(truePositives, falseNegatives)\n",
    "    bal = bcr(prec, rec)\n",
    "\n",
    "    print(\"True Positives: \", truePositives)    \n",
    "    print(\"False Positives: \", falsePositives)\n",
    "    print(\"False Negatives: \", falseNegatives)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"Recall: \", rec)\n",
    "    print(\"Balanced Classification Rate: \", bal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_batch 0\n",
      "mini_batch 1\n",
      "mini_batch 2\n",
      "mini_batch 3\n",
      "mini_batch 4\n",
      "mini_batch 5\n",
      "mini_batch 6\n",
      "mini_batch 7\n",
      "mini_batch 8\n",
      "mini_batch 9\n",
      "mini_batch 10\n",
      "mini_batch 11\n",
      "mini_batch 12\n",
      "mini_batch 13\n",
      "mini_batch 14\n",
      "mini_batch 15\n",
      "mini_batch 16\n",
      "mini_batch 17\n",
      "mini_batch 18\n",
      "mini_batch 19\n",
      "mini_batch 20\n",
      "mini_batch 21\n",
      "mini_batch 22\n",
      "mini_batch 23\n",
      "mini_batch 24\n",
      "mini_batch 25\n",
      "mini_batch 26\n",
      "mini_batch 27\n",
      "mini_batch 28\n",
      "mini_batch 29\n",
      "mini_batch 30\n",
      "mini_batch 31\n",
      "mini_batch 32\n",
      "mini_batch 33\n",
      "mini_batch 34\n",
      "mini_batch 35\n",
      "mini_batch 36\n",
      "mini_batch 37\n",
      "mini_batch 38\n",
      "mini_batch 39\n",
      "mini_batch 40\n",
      "mini_batch 41\n",
      "mini_batch 42\n",
      "mini_batch 43\n",
      "mini_batch 44\n",
      "mini_batch 45\n",
      "mini_batch 46\n",
      "mini_batch 47\n",
      "mini_batch 48\n",
      "mini_batch 49\n",
      "Epoch 1\n",
      "average minibatch 50 loss: 5.182\n",
      "\n",
      "Labels:  tensor([115,  22, 170, 187, 155, 146, 155, 131,  60, 132,  81, 179, 180, 192,\n",
      "        163, 170,  47, 127, 182, 151, 124,   9,  79,  60,  95,   1,  71,  54,\n",
      "        158,  52,  71, 129, 170, 132,  70, 113, 174, 164, 123,  42, 104,  84,\n",
      "        154, 115, 123, 136, 125, 101,  51, 118, 122, 102, 110,  47, 127,   1,\n",
      "        151, 142,  33,  33,  38, 164,  81, 166], device='cuda:0')\n",
      "Output:  tensor([105,   1,   1,   7,   1,   1, 137,   1, 105,  21,   1,   1,  95, 137,\n",
      "        137, 105,   1,  24,  36, 137, 137,   1,   1,   1,   1,  95, 137, 105,\n",
      "        155, 105, 105,  21, 137, 105,   1,  95, 105, 105,   1,  21,   1,   1,\n",
      "          7, 105,  95,   1,   1,  21,   1, 137,  21,  95,  75, 105, 105,   1,\n",
      "        137,   1,   7,  36, 100,   1, 100, 105], device='cuda:0')\n",
      "True Positives:  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [21.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  5.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  5.  0.  0.  0.  0.  2.  0.  0.  0.  0. 13.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "False Negatives:  [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 2. 0. 0. 1. 0. 0.\n",
      " 0. 1. 2. 1. 1. 0. 2. 0. 1. 0. 1. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 2. 0. 0. 1. 2. 0. 0. 1. 0. 0. 0. 0. 1. 2. 0. 1. 0. 0.\n",
      " 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.04545455 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0. ]\n",
      "Balanced Classification Rate:  [0.27272727 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 50\n",
      "mini_batch 51\n",
      "mini_batch 52\n",
      "mini_batch 53\n",
      "mini_batch 54\n",
      "mini_batch 55\n",
      "mini_batch 56\n",
      "mini_batch 57\n",
      "mini_batch 58\n",
      "mini_batch 59\n",
      "mini_batch 60\n",
      "mini_batch 61\n",
      "mini_batch 62\n",
      "mini_batch 63\n",
      "mini_batch 64\n",
      "mini_batch 65\n",
      "mini_batch 66\n",
      "mini_batch 67\n",
      "mini_batch 68\n",
      "mini_batch 69\n",
      "mini_batch 70\n",
      "mini_batch 71\n",
      "mini_batch 72\n",
      "mini_batch 73\n",
      "mini_batch 74\n",
      "mini_batch 75\n",
      "mini_batch 76\n",
      "mini_batch 77\n",
      "mini_batch 78\n",
      "mini_batch 79\n",
      "mini_batch 80\n",
      "mini_batch 81\n",
      "mini_batch 82\n",
      "mini_batch 83\n",
      "mini_batch 84\n",
      "mini_batch 85\n",
      "mini_batch 86\n",
      "mini_batch 87\n",
      "mini_batch 88\n",
      "mini_batch 89\n",
      "mini_batch 90\n",
      "mini_batch 91\n",
      "mini_batch 92\n",
      "mini_batch 93\n",
      "mini_batch 94\n",
      "mini_batch 95\n",
      "mini_batch 96\n",
      "mini_batch 97\n",
      "mini_batch 98\n",
      "mini_batch 99\n",
      "Epoch 1\n",
      "average minibatch 100 loss: 4.789\n",
      "\n",
      "Labels:  tensor([ 62, 184, 181,  37, 123,  37, 116,  20, 192, 186, 101, 144, 134,  33,\n",
      "        194,  94, 182, 175,  65, 172, 127,  22,  88, 175, 144,  67, 135, 101,\n",
      "        190, 100, 193,  71, 122,  37, 104,  54,  50, 161, 172,  95,  38, 110,\n",
      "         24,  21, 132,  10,  29, 101, 148, 122, 134, 109,  11,  34, 123, 115,\n",
      "        190,  32, 153,  41, 110,  22,  33, 185], device='cuda:0')\n",
      "Output:  tensor([ 36,  36,  72,  37,  58, 125, 148, 125,  37,  37,  67, 105,  29,  67,\n",
      "        127,  13, 125,  36,  65, 105, 127,  13, 106,  36,  13,  67, 106, 127,\n",
      "         58, 154,  13, 127, 105,  67, 125, 106, 127, 184, 105, 105,  93, 106,\n",
      "         72, 105, 155, 148, 125, 106,  13, 155, 105,  13, 106,  72,  13, 105,\n",
      "        192,  29,  29,  36, 105,   1,  13, 105], device='cuda:0')\n",
      "True Positives:  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [22.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  8.  0.  0.  0.  0.  0.\n",
      "  0.  0.  5.  0.  0.  1.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  7.\n",
      "  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  3.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  5.  0.  0.  0.  0.  2.  0.  0.  0.  0. 23.  6.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  0.\n",
      "  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  2.  0.  0.  0.  0.  0.  1.  3.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "False Negatives:  [1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 3. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 4. 1. 0. 0. 2. 2. 0. 0. 1. 1. 0. 0. 0. 0. 2. 0.\n",
      " 0. 1. 1. 1. 0. 2. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 3. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 2. 0.\n",
      " 0. 0. 0. 1. 4. 1. 0. 2. 0. 0. 0. 0. 1. 3. 0. 0. 1. 0. 3. 1. 0. 1. 0. 0.\n",
      " 0. 3. 4. 1. 1. 0. 2. 0. 1. 0. 1. 3. 0. 2. 1. 1. 0. 0. 0. 0. 0. 1. 0. 2.\n",
      " 0. 1. 0. 1. 0. 0. 2. 0. 1. 1. 2. 0. 0. 1. 0. 0. 1. 0. 1. 2. 0. 1. 0. 0.\n",
      " 0. 3. 0. 2. 0. 1. 2. 0. 0. 0. 1. 1. 1. 2. 0. 1. 1. 1. 1. 0. 0. 2. 0. 2.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.015625 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.015625 0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.04347826 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.         0.\n",
      " 0.25       0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.5        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.27173913 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.         0.\n",
      " 0.625      0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26666667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 100\n",
      "mini_batch 101\n",
      "mini_batch 102\n",
      "mini_batch 103\n",
      "mini_batch 104\n",
      "mini_batch 105\n",
      "mini_batch 106\n",
      "mini_batch 107\n",
      "mini_batch 108\n",
      "mini_batch 109\n",
      "mini_batch 110\n",
      "mini_batch 111\n",
      "mini_batch 112\n",
      "mini_batch 113\n",
      "mini_batch 114\n",
      "mini_batch 115\n",
      "mini_batch 116\n",
      "mini_batch 117\n",
      "mini_batch 118\n",
      "mini_batch 119\n",
      "mini_batch 120\n",
      "mini_batch 121\n",
      "mini_batch 122\n",
      "mini_batch 123\n",
      "mini_batch 124\n",
      "mini_batch 125\n",
      "mini_batch 126\n",
      "mini_batch 127\n",
      "mini_batch 128\n",
      "mini_batch 129\n",
      "mini_batch 130\n",
      "mini_batch 131\n",
      "mini_batch 132\n",
      "mini_batch 133\n",
      "mini_batch 134\n",
      "mini_batch 135\n",
      "mini_batch 136\n",
      "mini_batch 137\n",
      "mini_batch 138\n",
      "mini_batch 139\n",
      "mini_batch 140\n",
      "mini_batch 141\n",
      "mini_batch 142\n",
      "mini_batch 143\n",
      "mini_batch 144\n",
      "mini_batch 145\n",
      "mini_batch 146\n",
      "mini_batch 147\n",
      "mini_batch 148\n",
      "mini_batch 149\n",
      "Epoch 1\n",
      "average minibatch 150 loss: 4.438\n",
      "\n",
      "Labels:  tensor([126, 193,  66,  49,  85, 106, 195,   7, 162, 187,  76, 155,  87,  62,\n",
      "         87, 161, 157,  75,  89, 126, 116, 172,  46,  29, 140, 164,  77,  98,\n",
      "         60,  81, 123, 105,  59,  17,   8,  42, 153,  17, 160,  85,  67,  71,\n",
      "        152,  18,  27,  22,  21,  62,  21,   9,  38, 186, 153, 170, 198, 132,\n",
      "         99,  97, 195,  48, 194, 107,   1,   1], device='cuda:0')\n",
      "Output:  tensor([126, 151,  36, 106,  37, 106, 109,   7, 145, 126, 106, 106, 155,  62,\n",
      "        122,  18,  16, 151,   9,  13, 155, 172,  78,  36, 180,  23,  58,  58,\n",
      "        151,  36, 146,  23,  74,  16, 126, 198,  37,  69,  16,  28,  67, 126,\n",
      "         58,  68,  36,  67,  37,  62, 107, 134,  16,  37,  23, 153,  82,  23,\n",
      "        126,  16,  82, 126, 151, 107,  16, 198], device='cuda:0')\n",
      "True Positives:  [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 2. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [22.  0.  0.  0.  0.  0.  3.  0.  1.  0.  0.  0.  9.  0.  0.  6.  0.  1.\n",
      "  0.  0.  5.  0.  4.  1.  0.  0.  0.  1.  3.  0.  0.  0.  0.  0.  0. 11.\n",
      "  6.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  4.  1.  1.  0.  0.  3.\n",
      "  0.  1.  1.  0.  0.  1.  0.  0.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  5.  0.  0.  0.  0.  2.  0.  0.  0.  0. 23.  9.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  5.  5.\n",
      "  4.  0.  0.  0.  0.  0.  0.  1.  0.  0.  9.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  2.  0.  0.  4.  0.  1.  1.  5.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  2.\n",
      "  0.  0.]\n",
      "False Negatives:  [3. 0. 0. 0. 0. 0. 0. 1. 2. 1. 1. 0. 0. 0. 0. 0. 2. 1. 0. 1. 3. 4. 0. 1.\n",
      " 0. 0. 1. 0. 2. 0. 0. 1. 4. 1. 0. 0. 2. 3. 0. 0. 1. 2. 0. 0. 0. 1. 2. 1.\n",
      " 1. 1. 1. 1. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 4. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 3. 0. 0. 1. 2. 0. 2. 1. 1. 0. 0. 0. 0. 1. 2. 0.\n",
      " 1. 1. 1. 1. 4. 1. 0. 2. 1. 0. 0. 0. 1. 3. 0. 0. 1. 0. 3. 2. 0. 1. 0. 0.\n",
      " 0. 3. 5. 1. 1. 1. 2. 0. 1. 0. 1. 4. 0. 2. 1. 1. 0. 0. 0. 1. 0. 1. 0. 2.\n",
      " 0. 1. 0. 1. 0. 0. 2. 1. 3. 1. 3. 0. 1. 1. 0. 1. 2. 1. 1. 3. 0. 1. 0. 0.\n",
      " 0. 4. 0. 2. 0. 1. 2. 0. 0. 0. 1. 1. 1. 2. 0. 1. 1. 2. 2. 0. 0. 2. 0. 2.\n",
      " 2. 2. 2. 0. 0. 1. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.       0.       0.       0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.015625 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.03125  0.       0.\n",
      " 0.015625 0.       0.03125  0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.015625 0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.04347826 0.         0.         0.         0.         0.\n",
      " 0.25       0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.14285714 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.         1.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.1        0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.16666667\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.25       0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.66666667 0.         0.         1.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.14673913 0.         0.         0.         0.         0.\n",
      " 0.625      0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.23809524 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.83333333 0.         0.         1.         0.\n",
      " 0.66666667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.55       0.75       0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.26666667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.66666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 150\n",
      "mini_batch 151\n",
      "mini_batch 152\n",
      "mini_batch 153\n",
      "mini_batch 154\n",
      "mini_batch 155\n",
      "mini_batch 156\n",
      "mini_batch 157\n",
      "mini_batch 158\n",
      "mini_batch 159\n",
      "mini_batch 160\n",
      "mini_batch 161\n",
      "mini_batch 162\n",
      "mini_batch 163\n",
      "mini_batch 164\n",
      "mini_batch 165\n",
      "mini_batch 166\n",
      "mini_batch 167\n",
      "mini_batch 168\n",
      "mini_batch 169\n",
      "mini_batch 170\n",
      "mini_batch 171\n",
      "mini_batch 172\n",
      "mini_batch 173\n",
      "mini_batch 174\n",
      "mini_batch 175\n",
      "mini_batch 176\n",
      "mini_batch 177\n",
      "mini_batch 178\n",
      "mini_batch 179\n",
      "mini_batch 180\n",
      "mini_batch 181\n",
      "mini_batch 182\n",
      "mini_batch 183\n",
      "mini_batch 184\n",
      "mini_batch 185\n",
      "mini_batch 186\n",
      "mini_batch 187\n",
      "mini_batch 188\n",
      "mini_batch 189\n",
      "mini_batch 190\n",
      "mini_batch 191\n",
      "mini_batch 192\n",
      "mini_batch 193\n",
      "mini_batch 194\n",
      "mini_batch 195\n",
      "mini_batch 196\n",
      "mini_batch 197\n",
      "mini_batch 198\n",
      "mini_batch 199\n",
      "Epoch 1\n",
      "average minibatch 200 loss: 4.070\n",
      "\n",
      "Labels:  tensor([ 99,  86, 119,  19,  20, 171,  62, 164,  38, 102, 172,  49, 177,  58,\n",
      "          1, 111,  30,  69, 132, 105,   1, 114,  93,  31, 152, 140, 127,  79,\n",
      "        159,  70, 189, 179,  37, 113,   2,   6, 158, 115, 143, 105,  15, 188,\n",
      "         95, 121, 179,  62,  54, 155, 147, 118,  48, 132, 178, 169,  21,   6,\n",
      "         68, 185, 107,  37, 189,  46, 191,  65], device='cuda:0')\n",
      "Output:  tensor([118,  86, 119,  35,  35, 171,  62, 121,  48,  62,  60,  87, 177, 100,\n",
      "        109,  29,  33,  69, 132,  23,   7, 114,  18, 169, 114, 100, 132,  35,\n",
      "        106, 155,  65,  36,  37,   9, 132, 136, 153,   5,  23,  37, 123,  37,\n",
      "         63,  37, 179,  32,  17, 130, 147, 118, 153, 132, 168,  35,  25, 141,\n",
      "        123,  29,  23, 169,  72, 105,  29, 147], device='cuda:0')\n",
      "True Positives:  [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 1. 0. 2. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [22.  0.  0.  0.  1.  0.  4.  0.  2.  0.  0.  0.  9.  0.  0.  6.  1.  2.\n",
      "  0.  0.  5.  0.  7.  1.  1.  0.  0.  1.  6.  0.  0.  1.  1.  0.  4. 12.\n",
      "  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  5.  0.  1.  0.  1.  1.  0.  1.  0.  4.  1.  1.  0.  0.  4.\n",
      "  0.  1.  1.  0.  0.  1.  0.  0.  0.  2.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  1.  0.  5.  0.  0.  0.  0.  4.  0.  0.  0.  0. 24. 10.  1.  0.\n",
      "  2.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  2.  0.  5.  5.\n",
      "  4.  0.  0.  1.  0.  2.  0.  1.  0.  1.  9.  0.  0.  0.  1.  0.  0.  0.\n",
      "  1.  1.  1.  2.  0.  0.  4.  0.  3.  1.  6.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  2.\n",
      "  0.  0.]\n",
      "False Negatives:  [5. 1. 0. 0. 0. 2. 0. 1. 2. 1. 1. 0. 0. 0. 1. 0. 2. 1. 1. 2. 4. 4. 0. 1.\n",
      " 0. 0. 1. 0. 2. 1. 1. 1. 4. 1. 0. 0. 3. 4. 0. 0. 1. 2. 0. 0. 0. 2. 2. 2.\n",
      " 2. 1. 1. 1. 0. 3. 0. 0. 0. 1. 1. 3. 0. 2. 0. 0. 1. 1. 0. 1. 0. 2. 4. 0.\n",
      " 0. 0. 1. 1. 1. 0. 2. 0. 3. 0. 0. 1. 2. 0. 2. 1. 1. 0. 0. 0. 1. 1. 3. 0.\n",
      " 1. 1. 2. 1. 4. 2. 0. 2. 3. 0. 1. 0. 1. 3. 1. 0. 2. 0. 4. 2. 0. 1. 0. 0.\n",
      " 1. 3. 5. 1. 1. 1. 3. 0. 1. 0. 1. 4. 0. 2. 1. 1. 0. 0. 0. 2. 0. 1. 1. 2.\n",
      " 0. 1. 0. 1. 0. 0. 2. 2. 3. 1. 4. 0. 1. 2. 1. 1. 2. 1. 1. 4. 0. 1. 0. 0.\n",
      " 1. 4. 0. 3. 0. 1. 2. 0. 0. 1. 2. 1. 1. 2. 0. 1. 2. 2. 2. 1. 2. 2. 1. 2.\n",
      " 2. 2. 2. 0. 0. 1. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.       0.       0.       0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.03125  0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.046875 0.       0.\n",
      " 0.015625 0.       0.03125  0.       0.015625 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.03125  0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.015625 0.015625 0.       0.       0.       0.\n",
      " 0.015625 0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.04347826 0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.18181818 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.75       0.         0.         0.5        0.\n",
      " 0.33333333 0.         0.5        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09090909 0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.16666667\n",
      " 0.2        0.         0.         0.         0.         0.5\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         0.         0.\n",
      " 0.         0.         1.         0.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.16666667 0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.6        0.         0.         0.5        0.\n",
      " 1.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.5        0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.25       0.         0.         0.         0.         0.33333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.25       0.         0.\n",
      " 0.         0.         1.         0.         0.33333333 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.10507246 0.         0.         0.         0.         0.\n",
      " 0.6        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29090909 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.675      0.         0.         0.5        0.\n",
      " 0.66666667 0.         0.75       0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.54545455 0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.75\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.225      0.         0.         0.         0.         0.41666667\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.75       0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.625      0.         0.\n",
      " 0.         0.         1.         0.         0.66666667 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 200\n",
      "mini_batch 201\n",
      "mini_batch 202\n",
      "mini_batch 203\n",
      "mini_batch 204\n",
      "mini_batch 205\n",
      "mini_batch 206\n",
      "mini_batch 207\n",
      "mini_batch 208\n",
      "mini_batch 209\n",
      "mini_batch 210\n",
      "mini_batch 211\n",
      "mini_batch 212\n",
      "mini_batch 213\n",
      "mini_batch 214\n",
      "mini_batch 215\n",
      "mini_batch 216\n",
      "mini_batch 217\n",
      "mini_batch 218\n",
      "mini_batch 219\n",
      "mini_batch 220\n",
      "mini_batch 221\n",
      "mini_batch 222\n",
      "mini_batch 223\n",
      "mini_batch 224\n",
      "mini_batch 225\n",
      "mini_batch 226\n",
      "mini_batch 227\n",
      "mini_batch 228\n",
      "mini_batch 229\n",
      "mini_batch 230\n",
      "mini_batch 231\n",
      "mini_batch 232\n",
      "mini_batch 233\n",
      "mini_batch 234\n",
      "mini_batch 235\n",
      "mini_batch 236\n",
      "mini_batch 237\n",
      "mini_batch 238\n",
      "mini_batch 239\n",
      "mini_batch 240\n",
      "mini_batch 241\n",
      "mini_batch 242\n",
      "mini_batch 243\n",
      "mini_batch 244\n",
      "mini_batch 245\n",
      "mini_batch 246\n",
      "mini_batch 247\n",
      "mini_batch 248\n",
      "mini_batch 249\n",
      "Epoch 1\n",
      "average minibatch 250 loss: 3.815\n",
      "\n",
      "Labels:  tensor([ 41,  83,   8, 157,  85,  27,  64,  31, 111,  70, 136,  18,  91,  37,\n",
      "         27, 175, 165,  82, 179,  86,  29,   4,  39,  20, 192,  37,  54, 142,\n",
      "        179,  64, 145, 127,  58, 192,  49, 124, 155,  13,  85, 172, 169,  20,\n",
      "          9,  75,  45,  79,  25,  70,  96,  17,  16, 100, 145, 153, 160,  99,\n",
      "        197,  43,  15, 145,  95,   7,  48, 190], device='cuda:0')\n",
      "Output:  tensor([ 58,  62,  62, 157, 110,  64,  64, 139,  59,  64, 136,  18,  27, 122,\n",
      "        147,  62,  28, 180,  69,  89, 157, 157, 147,  58, 110, 105,  29,  89,\n",
      "         65, 137, 171, 137, 149,  22, 105, 173, 118, 164, 190, 105, 169,  14,\n",
      "          9, 136, 180,  74, 200,  64, 191,  59,  74, 100, 171,  69, 125, 110,\n",
      "        161,  78,  15, 191, 169,  53,  59, 105], device='cuda:0')\n",
      "True Positives:  [1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 1. 1. 0. 2. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [22.  0.  0.  0.  1.  0.  4.  0.  2.  0.  0.  0.  9.  1.  0.  6.  1.  2.\n",
      "  0.  0.  5.  1.  7.  1.  1.  0.  1.  2.  7.  0.  0.  1.  1.  0.  4. 12.\n",
      "  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  7.  3.  1.  0.  4.  1.  3.  2.  0.  4.  1.  3.  0.  0.  4.\n",
      "  0.  3.  1.  0.  0.  2.  0.  0.  0.  2.  0.  0.  0.  0.  1.  0.  2.  0.\n",
      "  0.  0.  1.  0.  5.  0.  0.  0.  0.  4.  0.  0.  0.  0. 28. 10.  1.  0.\n",
      "  2.  3.  0.  0.  0.  1.  0.  0.  0.  2.  0.  0.  1.  2.  2.  0.  6.  5.\n",
      "  4.  0.  0.  1.  0.  2.  0.  1.  0.  2. 11.  0.  1.  0.  1.  0.  0.  0.\n",
      "  1.  1.  3.  2.  1.  0.  4.  0.  3.  1.  6.  0.  2.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  0.  0.  1.  3.  0.  2.  0.  1.  0.  0.  0.  0.  0.  0.  3.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  2.  1.  0.  0.  0.  0.  0.  2.\n",
      "  0.  1.]\n",
      "False Negatives:  [5. 1. 0. 1. 0. 2. 1. 2. 2. 1. 1. 0. 1. 0. 1. 1. 3. 1. 1. 4. 4. 4. 0. 1.\n",
      " 1. 0. 3. 0. 3. 1. 2. 1. 4. 1. 0. 0. 5. 4. 1. 0. 2. 2. 1. 0. 1. 2. 2. 3.\n",
      " 3. 1. 1. 1. 0. 4. 0. 0. 0. 2. 1. 3. 0. 2. 0. 1. 1. 1. 0. 1. 0. 4. 4. 0.\n",
      " 0. 0. 2. 1. 1. 0. 3. 0. 3. 1. 1. 1. 4. 1. 2. 1. 1. 0. 1. 0. 1. 1. 4. 1.\n",
      " 1. 1. 3. 1. 4. 2. 0. 2. 3. 0. 1. 0. 1. 3. 2. 0. 2. 0. 4. 2. 0. 1. 0. 0.\n",
      " 1. 3. 5. 2. 1. 1. 4. 0. 1. 0. 1. 4. 0. 2. 1. 1. 0. 0. 0. 2. 0. 2. 1. 2.\n",
      " 3. 1. 0. 1. 0. 0. 2. 2. 4. 1. 5. 0. 1. 2. 1. 2. 2. 1. 1. 4. 1. 1. 0. 0.\n",
      " 1. 4. 0. 4. 0. 1. 3. 0. 0. 1. 4. 1. 1. 2. 0. 1. 2. 2. 2. 1. 2. 3. 1. 4.\n",
      " 2. 2. 2. 0. 1. 1. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.       0.       0.       0.       0.015625 0.\n",
      " 0.015625 0.       0.       0.       0.       0.       0.015625 0.\n",
      " 0.       0.015625 0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.03125  0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.046875 0.       0.015625\n",
      " 0.015625 0.       0.03125  0.       0.015625 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.015625 0.       0.       0.       0.\n",
      " 0.       0.015625 0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.03125  0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.015625 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.015625 0.       0.015625 0.015625 0.       0.       0.       0.\n",
      " 0.015625 0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.04347826 0.         0.         0.         0.         0.\n",
      " 0.2        0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.33333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.18181818 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.42857143 0.         0.25       0.33333333 0.\n",
      " 0.33333333 0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.09090909 0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.         0.         0.         0.33333333 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.16666667\n",
      " 0.2        0.         0.         0.         0.         0.5\n",
      " 0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.25       0.         0.33333333 1.         0.         0.\n",
      " 0.         0.         1.         0.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.16666667 0.         0.         0.         0.         0.\n",
      " 0.5        0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.5        0.         0.         0.5\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.28571429 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.6        0.         0.5        0.5        0.\n",
      " 1.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.5        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         1.         0.5        0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.2        0.         0.         0.         0.         0.33333333\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.5        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.5        0.         1.         0.2        0.         0.\n",
      " 0.         0.         1.         0.         0.2        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.10507246 0.         0.         0.         0.         0.\n",
      " 0.35       0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.75       0.         0.         0.41666667\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.23376623 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.51428571 0.         0.375      0.41666667 0.\n",
      " 0.66666667 0.         0.625      0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.75       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.35       0.         0.\n",
      " 0.         0.         0.         0.54545455 0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.75\n",
      " 0.         0.         0.         0.41666667 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.2        0.         0.         0.         0.         0.41666667\n",
      " 0.         0.         0.         0.41666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.625      0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.41666667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.375      0.         0.66666667 0.6        0.         0.\n",
      " 0.         0.         1.         0.         0.6        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 250\n",
      "mini_batch 251\n",
      "mini_batch 252\n",
      "mini_batch 253\n",
      "mini_batch 254\n",
      "mini_batch 255\n",
      "mini_batch 256\n",
      "mini_batch 257\n",
      "mini_batch 258\n",
      "mini_batch 259\n",
      "mini_batch 260\n",
      "mini_batch 261\n",
      "mini_batch 262\n",
      "mini_batch 263\n",
      "mini_batch 264\n",
      "mini_batch 265\n",
      "mini_batch 266\n",
      "mini_batch 267\n",
      "mini_batch 268\n",
      "mini_batch 269\n",
      "mini_batch 270\n",
      "mini_batch 271\n",
      "mini_batch 272\n",
      "mini_batch 273\n",
      "mini_batch 274\n",
      "mini_batch 275\n",
      "mini_batch 276\n",
      "mini_batch 277\n",
      "mini_batch 278\n",
      "mini_batch 279\n",
      "mini_batch 280\n",
      "mini_batch 281\n",
      "mini_batch 282\n",
      "mini_batch 283\n",
      "mini_batch 284\n",
      "mini_batch 285\n",
      "mini_batch 286\n",
      "mini_batch 287\n",
      "mini_batch 288\n",
      "mini_batch 289\n",
      "mini_batch 290\n",
      "mini_batch 291\n",
      "mini_batch 292\n",
      "mini_batch 293\n",
      "mini_batch 294\n",
      "mini_batch 295\n",
      "mini_batch 296\n",
      "mini_batch 297\n",
      "mini_batch 298\n",
      "mini_batch 299\n",
      "Epoch 1\n",
      "average minibatch 300 loss: 3.518\n",
      "\n",
      "Labels:  tensor([ 59, 190, 103, 140, 123,  94,  62, 113, 145, 108, 158,  52, 166,  17,\n",
      "         66,  67,  73,  62,   8, 106, 131, 157,  20,  44, 198, 171, 104, 147,\n",
      "        151, 142,  11, 167,  67,  83, 184, 131, 153,  34, 172,   1, 159, 116,\n",
      "        197,  13, 109,  51,  22,  34,  97,  15, 188, 161,  37, 112,  93, 145,\n",
      "        166, 127, 154, 186, 113, 179, 179,  63], device='cuda:0')\n",
      "Output:  tensor([ 76, 190,  75,  17, 168,   7,  62,  67, 145, 108, 164, 141,  67, 112,\n",
      "         15,  93, 109,  59, 171,  75,  58, 154, 185, 159,  17,  15,  59, 147,\n",
      "        151, 148, 135,  95,  74, 154, 184,  37, 105, 151, 105,  95, 154, 145,\n",
      "         18,  13, 144,  93,  22,  34,   1,  15,  37, 190,  37,  68, 200, 123,\n",
      "        118, 180,  59,  21, 190,  13,  59, 194], device='cuda:0')\n",
      "True Positives:  [1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 2. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4. 0. 1. 1. 0. 2. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [23.  0.  0.  0.  1.  0.  5.  0.  2.  0.  0.  0. 10.  1.  2.  6.  3.  3.\n",
      "  0.  0.  6.  1.  7.  1.  1.  0.  1.  2.  7.  0.  0.  1.  1.  0.  4. 12.\n",
      " 11.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  8.  7.  1.  0.  4.  1.  3.  2.  0.  6.  2.  3.  0.  0.  4.\n",
      "  0.  4.  3.  1.  0.  2.  0.  0.  0.  2.  0.  0.  0.  0.  1.  0.  2.  0.\n",
      "  0.  0.  3.  0.  7.  0.  0.  0.  0.  4.  0.  0.  0.  0. 30. 10.  1.  0.\n",
      "  3.  3.  0.  1.  0.  1.  0.  0.  0.  3.  0.  0.  1.  2.  3.  0.  6.  5.\n",
      "  4.  0.  0.  1.  0.  2.  0.  1.  1.  2. 11.  0.  1.  0.  2.  0.  0.  1.\n",
      "  2.  1.  3.  3.  1.  0.  5.  0.  3.  4.  6.  0.  2.  0.  1.  0.  1.  0.\n",
      "  0.  2.  0.  0.  0.  2.  3.  0.  3.  0.  1.  0.  0.  0.  0.  0.  0.  4.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  0.  3.  2.  1.  0.  1.  0.  0.  0.  2.\n",
      "  0.  2.]\n",
      "False Negatives:  [6. 1. 0. 1. 0. 2. 1. 3. 2. 1. 2. 0. 1. 0. 1. 1. 4. 1. 1. 5. 4. 4. 0. 1.\n",
      " 1. 0. 3. 0. 3. 1. 2. 1. 4. 2. 0. 0. 5. 4. 1. 0. 2. 2. 1. 1. 1. 2. 2. 3.\n",
      " 3. 1. 2. 2. 0. 4. 0. 0. 0. 2. 2. 3. 0. 3. 1. 1. 1. 2. 2. 1. 0. 4. 4. 0.\n",
      " 1. 0. 2. 1. 1. 0. 3. 0. 3. 1. 2. 1. 4. 1. 2. 1. 1. 0. 1. 0. 2. 2. 4. 1.\n",
      " 2. 1. 3. 1. 4. 2. 1. 3. 3. 1. 1. 0. 2. 3. 2. 1. 4. 0. 4. 3. 0. 1. 0. 0.\n",
      " 1. 3. 6. 2. 1. 1. 5. 0. 1. 0. 3. 4. 0. 2. 1. 1. 0. 0. 0. 3. 0. 3. 1. 2.\n",
      " 4. 1. 0. 1. 0. 0. 2. 2. 5. 2. 5. 0. 2. 3. 2. 2. 3. 1. 1. 4. 1. 3. 1. 0.\n",
      " 1. 4. 1. 5. 0. 1. 3. 0. 0. 1. 6. 1. 1. 2. 0. 1. 2. 3. 2. 2. 2. 3. 1. 4.\n",
      " 2. 2. 2. 0. 2. 2. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.       0.       0.       0.       0.015625 0.\n",
      " 0.015625 0.       0.       0.       0.015625 0.       0.03125  0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.       0.       0.046875 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.0625   0.       0.015625\n",
      " 0.015625 0.       0.03125  0.       0.015625 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.015625 0.       0.       0.       0.\n",
      " 0.       0.015625 0.015625 0.015625 0.       0.       0.       0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.03125  0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.015625 0.       0.03125  0.       0.       0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.015625 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.015625 0.       0.015625 0.015625 0.       0.       0.       0.\n",
      " 0.015625 0.       0.015625 0.       0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.       0.       0.015625 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.04166667 0.         0.         0.         0.         0.\n",
      " 0.16666667 0.         0.33333333 0.         0.         0.\n",
      " 0.09090909 0.         0.5        0.         0.         0.25\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.21428571 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.5        0.         0.25       0.33333333 0.\n",
      " 0.25       0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.09090909 0.5        1.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.         0.         0.         0.25       1.         0.\n",
      " 0.         0.         0.         0.         0.         0.16666667\n",
      " 0.2        0.         0.         0.         0.         0.5\n",
      " 0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.4        0.         0.         0.\n",
      " 0.16666667 0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.25       0.         0.25       1.         0.         0.\n",
      " 0.         0.         1.         0.         1.         0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.25       0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.14285714 0.         0.         0.         0.         0.\n",
      " 0.5        0.         0.33333333 0.         0.         0.\n",
      " 0.5        0.         0.66666667 0.         0.         0.5\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.33333333 0.         0.\n",
      " 0.375      0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.57142857 0.         0.5        0.5        0.\n",
      " 0.5        0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.5        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.5        0.5        1.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.16666667 0.         0.         0.         0.         0.33333333\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.         1.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.5        0.         0.5        0.16666667 0.         0.\n",
      " 0.         0.         1.         0.         0.14285714 0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.25       0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.0922619  0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.33333333 0.         0.         0.\n",
      " 0.29545455 0.         0.58333333 0.         0.         0.375\n",
      " 0.         0.         0.         0.35       0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.66666667 0.         0.\n",
      " 0.29464286 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.53571429 0.         0.375      0.41666667 0.\n",
      " 0.375      0.         0.625      0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.75       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.35       0.         0.\n",
      " 0.         0.         0.         0.29545455 0.5        1.\n",
      " 0.         0.         0.         0.         0.         0.75\n",
      " 0.         0.         0.         0.375      1.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.18333333 0.         0.         0.         0.         0.41666667\n",
      " 0.         0.         0.         0.41666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26666667 0.         0.7        0.         0.         0.\n",
      " 0.25       0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.375      0.         0.375      0.58333333 0.         0.\n",
      " 0.         0.         1.         0.         0.57142857 0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.25       0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 300\n",
      "mini_batch 301\n",
      "mini_batch 302\n",
      "mini_batch 303\n",
      "mini_batch 304\n",
      "mini_batch 305\n",
      "mini_batch 306\n",
      "mini_batch 307\n",
      "mini_batch 308\n",
      "mini_batch 309\n",
      "mini_batch 310\n",
      "mini_batch 311\n",
      "mini_batch 312\n",
      "mini_batch 313\n",
      "mini_batch 314\n",
      "mini_batch 315\n",
      "mini_batch 316\n",
      "mini_batch 317\n",
      "mini_batch 318\n",
      "mini_batch 319\n",
      "mini_batch 320\n",
      "mini_batch 321\n",
      "mini_batch 322\n",
      "mini_batch 323\n",
      "mini_batch 324\n",
      "mini_batch 325\n",
      "mini_batch 326\n",
      "mini_batch 327\n",
      "mini_batch 328\n",
      "mini_batch 329\n",
      "mini_batch 330\n",
      "mini_batch 331\n",
      "mini_batch 332\n",
      "mini_batch 333\n",
      "mini_batch 334\n",
      "mini_batch 335\n",
      "mini_batch 336\n",
      "mini_batch 337\n",
      "mini_batch 338\n",
      "mini_batch 339\n",
      "mini_batch 340\n",
      "mini_batch 341\n",
      "mini_batch 342\n",
      "mini_batch 343\n",
      "mini_batch 344\n",
      "mini_batch 345\n",
      "mini_batch 346\n",
      "mini_batch 347\n",
      "mini_batch 348\n",
      "mini_batch 349\n",
      "Epoch 1\n",
      "average minibatch 350 loss: 3.381\n",
      "\n",
      "Labels:  tensor([ 12,  68, 179,  37,  91,  94,  23,  53, 106, 179, 113,  37,   1,  68,\n",
      "         42, 151, 152, 110, 190,  69,  82,  67, 164, 106,  14,  82, 185,   3,\n",
      "        132,  33,  78, 194,  71, 168, 153, 146,  78, 159, 171, 173,  79,  89,\n",
      "        192,  97,  31,  64, 156, 123,  71, 142, 187,  24,  36, 112,  36,  99,\n",
      "         50, 198, 166, 177,  34,  27, 128,  13], device='cuda:0')\n",
      "Output:  tensor([200,  84,  13, 192,  27, 109,  23, 184,  75,  72, 177, 124, 148,  68,\n",
      "         29, 118,  68, 136, 101,  69,  82,  67, 105, 106,  58,  82, 169,   3,\n",
      "        132,  13, 168, 102,  27, 168, 153, 146, 105, 159, 171, 190, 124,  89,\n",
      "         24,  58,  86,  29, 139,  84,  71, 196,   1, 109,  36, 112, 184,  90,\n",
      "         75, 154, 101, 177, 148,  27,  98,  13], device='cuda:0')\n",
      "True Positives:  [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 2. 0. 2. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4. 0. 1. 1. 0. 3. 1. 2. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 2. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 2. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [24.  0.  0.  0.  1.  0.  5.  0.  2.  0.  0.  0. 12.  1.  2.  6.  3.  3.\n",
      "  0.  0.  6.  1.  7.  2.  1.  0.  3.  2.  9.  0.  0.  1.  1.  0.  4. 12.\n",
      " 11.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0. 10.  7.  1.  0.  4.  1.  3.  2.  0.  6.  3.  3.  0.  0.  5.\n",
      "  0.  4.  5.  1.  0.  2.  0.  0.  0.  2.  0.  2.  0.  1.  1.  0.  2.  1.\n",
      "  0.  0.  3.  0.  7.  0.  0.  1.  0.  4.  2.  1.  0.  0. 32. 10.  1.  0.\n",
      "  5.  3.  0.  1.  0.  1.  0.  0.  0.  4.  0.  0.  1.  2.  3.  2.  6.  5.\n",
      "  4.  0.  0.  1.  0.  2.  0.  1.  1.  3. 11.  0.  2.  0.  2.  0.  0.  1.\n",
      "  2.  1.  3.  5.  1.  0.  5.  0.  3.  5.  6.  0.  2.  0.  1.  0.  1.  0.\n",
      "  0.  2.  0.  0.  0.  3.  4.  0.  3.  0.  1.  0.  0.  0.  1.  0.  0.  4.\n",
      "  0.  0.  0.  3.  1.  0.  0.  0.  0.  4.  2.  2.  0.  1.  0.  1.  0.  2.\n",
      "  0.  3.]\n",
      "False Negatives:  [7. 1. 0. 1. 0. 2. 1. 3. 2. 1. 2. 1. 1. 1. 1. 1. 4. 1. 1. 5. 4. 4. 0. 2.\n",
      " 1. 0. 3. 0. 3. 1. 3. 1. 5. 3. 0. 1. 7. 4. 1. 0. 2. 3. 1. 1. 1. 2. 2. 3.\n",
      " 3. 2. 2. 2. 1. 4. 0. 0. 0. 2. 2. 3. 0. 3. 1. 2. 1. 2. 2. 2. 0. 4. 5. 0.\n",
      " 1. 0. 2. 1. 1. 2. 4. 0. 3. 1. 2. 1. 4. 1. 2. 1. 1. 0. 2. 0. 2. 3. 4. 1.\n",
      " 3. 1. 4. 1. 4. 2. 1. 3. 3. 2. 1. 0. 2. 4. 2. 1. 5. 0. 4. 3. 0. 1. 0. 0.\n",
      " 1. 3. 7. 2. 1. 1. 5. 1. 1. 0. 3. 4. 0. 2. 1. 1. 0. 0. 0. 3. 0. 4. 1. 2.\n",
      " 4. 1. 0. 1. 0. 0. 3. 3. 5. 2. 5. 1. 2. 3. 2. 2. 3. 1. 1. 5. 1. 4. 1. 0.\n",
      " 1. 4. 1. 5. 1. 1. 3. 0. 0. 1. 8. 1. 1. 2. 0. 1. 3. 3. 3. 2. 2. 4. 1. 5.\n",
      " 2. 3. 2. 0. 2. 3. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.015625 0.       0.       0.       0.015625 0.\n",
      " 0.015625 0.       0.       0.       0.03125  0.       0.03125  0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.       0.015625 0.046875 0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.0625   0.       0.015625\n",
      " 0.015625 0.       0.046875 0.015625 0.03125  0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.03125  0.       0.       0.       0.015625 0.       0.\n",
      " 0.015625 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.015625 0.       0.       0.       0.\n",
      " 0.       0.03125  0.015625 0.015625 0.       0.       0.       0.015625\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.046875 0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.015625 0.015625 0.03125  0.       0.       0.       0.015625 0.\n",
      " 0.015625 0.       0.       0.       0.015625 0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.015625\n",
      " 0.015625 0.       0.03125  0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.       0.015625 0.       0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.       0.       0.015625 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.04       0.         1.         0.         0.         0.\n",
      " 0.16666667 0.         0.33333333 0.         0.         0.\n",
      " 0.14285714 0.         0.5        0.         0.         0.25\n",
      " 0.         0.         0.         0.5        0.125      0.\n",
      " 0.         0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.07692308\n",
      " 0.21428571 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.5        0.         0.25       0.33333333 0.\n",
      " 0.33333333 0.25       0.4        0.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.5        0.         0.         0.33333333 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.16666667 0.5        1.\n",
      " 0.         0.         0.         0.5        0.         0.5\n",
      " 0.         0.         0.         0.2        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.16666667\n",
      " 0.2        0.         0.         0.         0.         0.6\n",
      " 0.         0.         0.         0.25       0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.5        0.4        0.         0.         0.\n",
      " 0.16666667 0.         0.25       0.         0.         0.\n",
      " 0.33333333 0.         0.5        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25\n",
      " 0.2        0.         0.4        1.         0.         0.\n",
      " 0.         0.         0.66666667 0.         1.         0.\n",
      " 0.         0.         0.         0.25       0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.125      0.         1.         0.         0.         0.\n",
      " 0.5        0.         0.33333333 0.         0.         0.\n",
      " 0.66666667 0.         0.66666667 0.         0.         0.5\n",
      " 0.         0.         0.         0.2        1.         0.\n",
      " 0.         0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.25       0.         0.5\n",
      " 0.3        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.57142857 0.         0.33333333 0.5        0.\n",
      " 0.6        0.33333333 1.         0.         0.16666667 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.66666667 0.         0.\n",
      " 0.         0.5        0.         0.         0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.5        0.5        1.\n",
      " 0.         0.         0.         0.5        0.         1.\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.16666667 0.         0.         0.         0.         0.42857143\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2        0.5        1.         0.         0.         0.\n",
      " 0.25       0.         0.16666667 0.         0.         0.\n",
      " 0.33333333 0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.5        0.         0.66666667 0.16666667 0.         0.\n",
      " 0.         0.         1.         0.         0.11111111 0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.0825     0.         1.         0.         0.         0.\n",
      " 0.33333333 0.         0.33333333 0.         0.         0.\n",
      " 0.4047619  0.         0.58333333 0.         0.         0.375\n",
      " 0.         0.         0.         0.35       0.5625     0.\n",
      " 0.         0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.625      0.         0.28846154\n",
      " 0.25714286 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.53571429 0.         0.29166667 0.41666667 0.\n",
      " 0.46666667 0.29166667 0.7        0.         0.58333333 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.58333333 0.         0.\n",
      " 0.         0.5        0.         0.         0.41666667 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.35       0.         0.\n",
      " 0.         0.         0.         0.33333333 0.5        1.\n",
      " 0.         0.         0.         0.5        0.         0.75\n",
      " 0.         0.         0.         0.35       1.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.18333333 0.         0.         0.         0.         0.51428571\n",
      " 0.         0.         0.         0.375      0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26666667 0.5        0.7        0.         0.         0.\n",
      " 0.20833333 0.         0.20833333 0.         0.         0.\n",
      " 0.33333333 0.         0.41666667 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.625\n",
      " 0.35       0.         0.53333333 0.58333333 0.         0.\n",
      " 0.         0.         0.83333333 0.         0.55555556 0.\n",
      " 0.         0.         0.         0.375      0.         0.\n",
      " 0.         0.         0.         0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 350\n",
      "mini_batch 351\n",
      "mini_batch 352\n",
      "mini_batch 353\n",
      "mini_batch 354\n",
      "mini_batch 355\n",
      "mini_batch 356\n",
      "mini_batch 357\n",
      "mini_batch 358\n",
      "mini_batch 359\n",
      "mini_batch 360\n",
      "mini_batch 361\n",
      "mini_batch 362\n",
      "mini_batch 363\n",
      "mini_batch 364\n",
      "mini_batch 365\n",
      "mini_batch 366\n",
      "mini_batch 367\n",
      "mini_batch 368\n",
      "mini_batch 369\n",
      "mini_batch 370\n",
      "mini_batch 371\n",
      "mini_batch 372\n",
      "mini_batch 373\n",
      "mini_batch 374\n",
      "mini_batch 375\n",
      "Finished 1 epochs of training\n",
      "mini_batch 0\n",
      "mini_batch 1\n",
      "mini_batch 2\n",
      "mini_batch 3\n",
      "mini_batch 4\n",
      "mini_batch 5\n",
      "mini_batch 6\n",
      "mini_batch 7\n",
      "mini_batch 8\n",
      "mini_batch 9\n",
      "mini_batch 10\n",
      "mini_batch 11\n",
      "mini_batch 12\n",
      "mini_batch 13\n",
      "mini_batch 14\n",
      "mini_batch 15\n",
      "mini_batch 16\n",
      "mini_batch 17\n",
      "mini_batch 18\n",
      "mini_batch 19\n",
      "mini_batch 20\n",
      "mini_batch 21\n",
      "mini_batch 22\n",
      "mini_batch 23\n",
      "mini_batch 24\n",
      "mini_batch 25\n",
      "mini_batch 26\n",
      "mini_batch 27\n",
      "mini_batch 28\n",
      "mini_batch 29\n",
      "mini_batch 30\n",
      "mini_batch 31\n",
      "mini_batch 32\n",
      "mini_batch 33\n",
      "mini_batch 34\n",
      "mini_batch 35\n",
      "mini_batch 36\n",
      "mini_batch 37\n",
      "mini_batch 38\n",
      "mini_batch 39\n",
      "mini_batch 40\n",
      "mini_batch 41\n",
      "mini_batch 42\n",
      "mini_batch 43\n",
      "mini_batch 44\n",
      "mini_batch 45\n",
      "mini_batch 46\n",
      "mini_batch 47\n",
      "mini_batch 48\n",
      "mini_batch 49\n",
      "Epoch 2\n",
      "average minibatch 50 loss: 2.889\n",
      "\n",
      "Labels:  tensor([112, 195, 114, 193,  48, 160,  65,   7,  41, 193, 121, 180,  82,  27,\n",
      "        148, 157,  35,  17,  16, 176, 128, 186, 173,  99, 100,  63,  57,  38,\n",
      "         22,  82,  27,  32, 151, 137,  51,  68,  75,  90, 122,  59, 159, 141,\n",
      "        145,  92,  40,  53,   3,  69, 190, 180, 188, 113,  49,  22,  83,  54,\n",
      "        145, 116, 172, 179, 109, 127,  76,  48], device='cuda:0')\n",
      "Output:  tensor([198,  29, 171,  72,  81,  59, 101,   7,  41,  97,  58, 140,  82,  27,\n",
      "        114, 157,  35,  10, 140,  99, 128,  67,  66, 118, 100,  63,  57, 113,\n",
      "          1,  82,  27,  38, 151, 137, 153,  68,  75, 118, 105,  59, 113, 159,\n",
      "        145,  33,  98,  53, 149,  69, 190, 137, 188, 113,  87,  59,  90, 140,\n",
      "        145, 109,  60, 179, 109, 106,  33,  48], device='cuda:0')\n",
      "True Positives:  [1. 0. 1. 0. 0. 0. 2. 0. 1. 0. 0. 0. 2. 0. 2. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 3. 0. 0. 0. 0. 0. 0. 1. 1. 1. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 4. 1. 1. 1. 0. 3. 2. 3. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 4. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 2. 0. 0. 0. 0. 0. 2. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 3. 1. 2. 0. 0. 0. 2. 0. 1. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [25.  0.  0.  0.  1.  0.  5.  0.  2.  1.  0.  0. 12.  1.  2.  6.  3.  3.\n",
      "  0.  0.  6.  1.  7.  2.  1.  0.  3.  2. 10.  0.  0.  1.  3.  0.  4. 12.\n",
      " 11.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0. 11.  9.  2.  0.  4.  1.  3.  2.  1.  7.  3.  3.  0.  0.  6.\n",
      "  0.  4.  5.  1.  0.  2.  0.  0.  1.  2.  0.  2.  0.  1.  2.  0.  2.  2.\n",
      "  0.  0.  3.  0.  7.  0.  1.  2.  1.  4.  3.  1.  0.  0. 33. 11.  1.  0.\n",
      "  6.  3.  0.  1.  2.  2.  0.  0.  0.  6.  0.  0.  1.  2.  3.  2.  6.  5.\n",
      "  4.  0.  0.  1.  0.  2.  0.  1.  1.  3. 12.  0.  2.  3.  2.  0.  0.  1.\n",
      "  2.  1.  3.  5.  2.  0.  5.  0.  4.  5.  6.  0.  2.  0.  2.  0.  1.  0.\n",
      "  0.  2.  0.  0.  0.  3.  4.  0.  4.  0.  1.  0.  0.  0.  1.  0.  0.  4.\n",
      "  0.  0.  0.  3.  1.  0.  0.  0.  0.  4.  2.  2.  0.  1.  0.  1.  0.  3.\n",
      "  0.  3.]\n",
      "False Negatives:  [7. 1. 1. 1. 0. 2. 1. 3. 2. 1. 2. 1. 1. 1. 1. 2. 5. 1. 1. 5. 4. 6. 0. 2.\n",
      " 1. 0. 3. 0. 3. 1. 3. 2. 5. 3. 0. 1. 7. 5. 1. 1. 2. 3. 1. 1. 1. 2. 2. 4.\n",
      " 4. 2. 3. 2. 1. 5. 0. 0. 0. 2. 2. 3. 0. 3. 1. 2. 2. 2. 2. 2. 0. 4. 5. 0.\n",
      " 1. 0. 2. 2. 1. 2. 4. 0. 3. 1. 3. 1. 4. 1. 2. 1. 1. 1. 2. 1. 2. 3. 4. 1.\n",
      " 3. 1. 5. 1. 4. 2. 1. 3. 3. 2. 1. 0. 2. 4. 2. 2. 5. 1. 4. 4. 0. 1. 0. 0.\n",
      " 2. 4. 7. 2. 1. 1. 6. 1. 1. 0. 3. 4. 0. 2. 1. 1. 0. 0. 0. 3. 1. 4. 1. 2.\n",
      " 4. 1. 0. 2. 0. 0. 3. 3. 5. 2. 5. 1. 2. 3. 3. 3. 3. 1. 1. 5. 1. 4. 1. 0.\n",
      " 1. 4. 1. 6. 2. 1. 3. 1. 0. 1. 8. 3. 1. 2. 0. 1. 3. 4. 3. 2. 2. 4. 1. 5.\n",
      " 4. 3. 3. 0. 2. 3. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.015625 0.       0.       0.       0.03125  0.\n",
      " 0.015625 0.       0.       0.       0.03125  0.       0.03125  0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.046875 0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.015625 0.015625 0.046875 0.       0.       0.\n",
      " 0.015625 0.       0.       0.       0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.       0.015625 0.       0.       0.\n",
      " 0.015625 0.       0.015625 0.       0.       0.0625   0.015625 0.015625\n",
      " 0.015625 0.       0.046875 0.03125  0.046875 0.       0.015625 0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.0625   0.       0.       0.       0.015625 0.       0.\n",
      " 0.015625 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.03125  0.       0.       0.       0.\n",
      " 0.       0.03125  0.015625 0.015625 0.015625 0.       0.       0.015625\n",
      " 0.015625 0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.015625 0.015625\n",
      " 0.       0.       0.       0.046875 0.       0.       0.       0.015625\n",
      " 0.015625 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.046875 0.015625 0.03125  0.       0.       0.       0.03125  0.\n",
      " 0.015625 0.       0.       0.       0.03125  0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.015625\n",
      " 0.015625 0.       0.03125  0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.       0.03125  0.       0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.015625 0.       0.03125  0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.03846154 0.         1.         0.         0.         0.\n",
      " 0.28571429 0.         0.33333333 0.         0.         0.\n",
      " 0.14285714 0.         0.5        0.         0.         0.25\n",
      " 0.         0.         0.         0.5        0.125      0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.         0.         1.         0.2        0.07692308\n",
      " 0.21428571 0.         0.         0.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.         0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.         0.1        0.\n",
      " 0.         0.5        0.5        0.25       0.33333333 0.\n",
      " 0.3        0.4        0.5        0.         1.         0.\n",
      " 0.         0.         0.16666667 0.         0.         0.\n",
      " 0.         0.         0.         0.66666667 0.         0.\n",
      " 0.         0.5        0.         0.         0.33333333 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.15384615 0.5        1.\n",
      " 0.14285714 0.         0.         0.5        0.33333333 0.33333333\n",
      " 0.         0.         0.         0.14285714 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.16666667\n",
      " 0.2        1.         0.         0.         0.         0.6\n",
      " 0.         0.         0.         0.25       0.07692308 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.6        0.5        0.4        0.         0.         0.\n",
      " 0.28571429 0.         0.2        0.         0.         0.\n",
      " 0.5        0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25\n",
      " 0.2        0.         0.33333333 1.         0.         0.\n",
      " 0.         0.         0.66666667 0.         1.         0.\n",
      " 0.         0.         0.         0.25       0.         0.\n",
      " 0.         1.         0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.125      0.         0.5        0.         0.         0.\n",
      " 0.66666667 0.         0.33333333 0.         0.         0.\n",
      " 0.66666667 0.         0.66666667 0.         0.         0.5\n",
      " 0.         0.         0.         0.14285714 1.         0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.         0.         0.25       1.         0.5\n",
      " 0.3        0.         0.         0.         0.33333333 0.\n",
      " 0.         0.         0.         0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.         0.33333333 0.\n",
      " 0.         0.57142857 0.5        0.33333333 0.33333333 0.\n",
      " 0.6        0.5        1.         0.         0.16666667 0.\n",
      " 0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.8        0.         0.\n",
      " 0.         0.5        0.         0.         0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.66666667 0.         0.\n",
      " 0.         0.         0.         0.5        0.5        1.\n",
      " 0.33333333 0.         0.         0.33333333 0.16666667 0.5\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.14285714 0.5        0.         0.         0.         0.42857143\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.42857143 0.5        1.         0.         0.         0.\n",
      " 0.4        0.         0.16666667 0.         0.         0.\n",
      " 0.5        0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.5        0.         0.66666667 0.14285714 0.         0.\n",
      " 0.         0.         1.         0.         0.2        0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.33333333 0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.08173077 0.         0.75       0.         0.         0.\n",
      " 0.47619048 0.         0.33333333 0.         0.         0.\n",
      " 0.4047619  0.         0.58333333 0.         0.         0.375\n",
      " 0.         0.         0.         0.32142857 0.5625     0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.         0.         0.625      0.6        0.28846154\n",
      " 0.25714286 0.         0.         0.         0.66666667 0.\n",
      " 0.         0.         0.         0.         0.         0.35\n",
      " 0.         0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.         0.21666667 0.\n",
      " 0.         0.53571429 0.5        0.29166667 0.33333333 0.\n",
      " 0.45       0.45       0.75       0.         0.58333333 0.\n",
      " 0.         0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.73333333 0.         0.\n",
      " 0.         0.5        0.         0.         0.41666667 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.         0.         0.32692308 0.5        1.\n",
      " 0.23809524 0.         0.         0.41666667 0.25       0.41666667\n",
      " 0.         0.         0.         0.32142857 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.17142857 0.75       0.         0.         0.         0.51428571\n",
      " 0.         0.         0.         0.375      0.53846154 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.51428571 0.5        0.7        0.         0.         0.\n",
      " 0.34285714 0.         0.18333333 0.         0.         0.\n",
      " 0.5        0.         0.29166667 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.625\n",
      " 0.35       0.         0.5        0.57142857 0.         0.\n",
      " 0.         0.         0.83333333 0.         0.6        0.\n",
      " 0.         0.         0.         0.375      0.         0.\n",
      " 0.         0.66666667 0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 50\n",
      "mini_batch 51\n",
      "mini_batch 52\n",
      "mini_batch 53\n",
      "mini_batch 54\n",
      "mini_batch 55\n",
      "mini_batch 56\n",
      "mini_batch 57\n",
      "mini_batch 58\n",
      "mini_batch 59\n",
      "mini_batch 60\n",
      "mini_batch 61\n",
      "mini_batch 62\n",
      "mini_batch 63\n",
      "mini_batch 64\n",
      "mini_batch 65\n",
      "mini_batch 66\n",
      "mini_batch 67\n",
      "mini_batch 68\n",
      "mini_batch 69\n",
      "mini_batch 70\n",
      "mini_batch 71\n",
      "mini_batch 72\n",
      "mini_batch 73\n",
      "mini_batch 74\n",
      "mini_batch 75\n",
      "mini_batch 76\n",
      "mini_batch 77\n",
      "mini_batch 78\n",
      "mini_batch 79\n",
      "mini_batch 80\n",
      "mini_batch 81\n",
      "mini_batch 82\n",
      "mini_batch 83\n",
      "mini_batch 84\n",
      "mini_batch 85\n",
      "mini_batch 86\n",
      "mini_batch 87\n",
      "mini_batch 88\n",
      "mini_batch 89\n",
      "mini_batch 90\n",
      "mini_batch 91\n",
      "mini_batch 92\n",
      "mini_batch 93\n",
      "mini_batch 94\n",
      "mini_batch 95\n",
      "mini_batch 96\n",
      "mini_batch 97\n",
      "mini_batch 98\n",
      "mini_batch 99\n",
      "Epoch 2\n",
      "average minibatch 100 loss: 2.692\n",
      "\n",
      "Labels:  tensor([ 12, 112, 168,  97,  67, 140, 114, 141, 192,  30, 179, 194, 180,  45,\n",
      "          9, 128, 187, 121,  52,  77,  64, 143, 102, 131,  31, 107, 145, 134,\n",
      "         65, 105, 103, 191, 164,  59, 141,  40, 161,  27, 173, 192,  70,  12,\n",
      "         59, 132,  10, 194,   9,  76,  70,  71, 114, 146, 129, 137, 109,  63,\n",
      "        102,  65, 173, 109, 185, 142, 159,   3], device='cuda:0')\n",
      "Output:  tensor([ 21, 194, 186,  97, 172,  54, 149, 141, 192, 156,  98, 194, 180,  45,\n",
      "          9, 177, 169,  98, 163,  32,  64, 143, 194, 194,  33, 105, 145, 134,\n",
      "         65, 105, 136,   1, 114,  59, 194, 143, 115, 149,  72,  43,   4,  21,\n",
      "         59, 132, 194, 194,   9,  87,  27,  71,  74, 146,  75, 137, 109, 109,\n",
      "        102, 153, 153,  21, 132,  68, 149, 126], device='cuda:0')\n",
      "True Positives:  [1. 0. 1. 0. 0. 0. 2. 0. 3. 0. 0. 0. 2. 0. 2. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 3. 0. 0. 0. 0. 0. 0. 1. 1. 1. 3. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 3. 0. 0. 4. 1. 2. 2. 0. 3. 2. 3. 0. 2. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 4. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 2. 0. 1. 0. 0. 1. 2. 1. 1. 2. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 4. 0. 1. 0. 1. 2. 0. 0. 0. 1. 0. 1. 0.\n",
      " 4. 2. 2. 0. 0. 0. 2. 0. 1. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 2. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 2. 0. 1.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0.]\n",
      "False Positives:  [26.  0.  0.  1.  1.  0.  5.  0.  2.  1.  0.  0. 12.  1.  2.  6.  3.  3.\n",
      "  0.  0.  9.  1.  7.  2.  1.  0.  4.  2. 10.  0.  0.  2.  4.  0.  4. 12.\n",
      " 11.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  0. 11.  9.  2.  0.  4.  1.  3.  2.  1.  7.  4.  3.  0.  0.  7.\n",
      "  0.  5.  6.  1.  0.  2.  0.  0.  1.  2.  0.  2.  0.  1.  3.  0.  2.  2.\n",
      "  0.  0.  3.  0.  7.  0.  1.  4.  1.  4.  3.  1.  0.  0. 34. 11.  1.  0.\n",
      "  7.  3.  0.  1.  2.  3.  1.  0.  0.  6.  0.  0.  1.  2.  3.  2.  6.  6.\n",
      "  4.  0.  0.  1.  0.  3.  0.  1.  1.  4. 12.  0.  2.  3.  2.  0.  1.  1.\n",
      "  2.  1.  3.  5.  5.  0.  5.  0.  6.  5.  6.  1.  2.  0.  2.  0.  1.  0.\n",
      "  1.  2.  0.  0.  0.  3.  5.  0.  4.  1.  1.  0.  0.  0.  2.  0.  0.  4.\n",
      "  0.  0.  0.  3.  1.  1.  0.  0.  0.  4.  2.  2.  0.  6.  0.  1.  0.  3.\n",
      "  0.  3.]\n",
      "False Negatives:  [7. 1. 2. 1. 0. 2. 1. 3. 2. 2. 2. 3. 1. 1. 1. 2. 5. 1. 1. 5. 4. 6. 0. 2.\n",
      " 1. 0. 4. 0. 3. 2. 4. 2. 5. 3. 0. 1. 7. 5. 1. 2. 2. 3. 1. 1. 1. 2. 2. 4.\n",
      " 4. 2. 3. 3. 1. 5. 0. 0. 0. 2. 2. 3. 0. 3. 2. 2. 3. 2. 3. 2. 0. 6. 5. 0.\n",
      " 1. 0. 2. 3. 2. 2. 4. 0. 3. 1. 3. 1. 4. 1. 2. 1. 1. 1. 2. 1. 2. 3. 4. 1.\n",
      " 3. 1. 5. 1. 4. 3. 2. 3. 3. 2. 2. 0. 3. 4. 2. 3. 5. 3. 4. 4. 0. 1. 0. 0.\n",
      " 3. 4. 7. 2. 1. 1. 6. 2. 2. 0. 4. 4. 0. 2. 1. 1. 0. 0. 0. 4. 2. 5. 1. 2.\n",
      " 4. 1. 0. 2. 0. 0. 3. 3. 5. 2. 5. 1. 2. 3. 4. 3. 4. 1. 1. 6. 1. 4. 1. 1.\n",
      " 1. 4. 1. 6. 4. 1. 3. 1. 0. 1. 9. 3. 1. 2. 0. 1. 4. 4. 4. 2. 2. 4. 2. 6.\n",
      " 4. 3. 3. 0. 2. 3. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.015625 0.       0.       0.       0.03125  0.\n",
      " 0.046875 0.       0.       0.       0.03125  0.       0.03125  0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.046875 0.       0.       0.       0.       0.\n",
      " 0.       0.015625 0.015625 0.015625 0.046875 0.       0.       0.\n",
      " 0.015625 0.       0.       0.       0.015625 0.       0.       0.015625\n",
      " 0.       0.       0.       0.       0.015625 0.       0.       0.\n",
      " 0.015625 0.       0.046875 0.       0.       0.0625   0.015625 0.03125\n",
      " 0.03125  0.       0.046875 0.03125  0.046875 0.       0.03125  0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.       0.0625   0.       0.       0.       0.015625 0.       0.\n",
      " 0.015625 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.015625 0.       0.       0.03125  0.       0.015625 0.       0.\n",
      " 0.015625 0.03125  0.015625 0.015625 0.03125  0.       0.       0.015625\n",
      " 0.015625 0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.015625 0.015625 0.015625\n",
      " 0.       0.       0.       0.0625   0.       0.015625 0.       0.015625\n",
      " 0.03125  0.       0.       0.       0.015625 0.       0.015625 0.\n",
      " 0.0625   0.03125  0.03125  0.       0.       0.       0.03125  0.\n",
      " 0.015625 0.       0.       0.       0.03125  0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.015625\n",
      " 0.015625 0.       0.03125  0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.       0.03125  0.015625 0.       0.       0.       0.015625\n",
      " 0.       0.       0.       0.015625 0.       0.03125  0.       0.015625\n",
      " 0.       0.03125  0.       0.       0.       0.       0.       0.      ]\n",
      "Precision:  [0.03703704 0.         1.         0.         0.         0.\n",
      " 0.28571429 0.         0.6        0.         0.         0.\n",
      " 0.14285714 0.         0.5        0.         0.         0.25\n",
      " 0.         0.         0.         0.5        0.125      0.\n",
      " 0.         0.         0.42857143 0.         0.         0.\n",
      " 0.         0.         0.         1.         0.2        0.07692308\n",
      " 0.21428571 0.         0.         0.         1.         0.\n",
      " 0.         0.         1.         0.         0.         0.5\n",
      " 0.         0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.         0.25       0.\n",
      " 0.         0.5        0.5        0.4        0.5        0.\n",
      " 0.3        0.33333333 0.5        0.         1.         0.\n",
      " 0.         0.         0.14285714 0.         0.         0.\n",
      " 0.         0.         0.         0.66666667 0.         0.\n",
      " 0.         0.5        0.         0.         0.33333333 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.5        0.         0.         0.33333333 0.         0.5\n",
      " 0.         0.         0.02857143 0.15384615 0.5        1.\n",
      " 0.22222222 0.         0.         0.5        0.33333333 0.25\n",
      " 0.         0.         0.         0.14285714 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.14285714\n",
      " 0.2        1.         0.         0.         0.         0.57142857\n",
      " 0.         0.5        0.         0.2        0.14285714 0.\n",
      " 0.         0.         0.33333333 0.         0.5        0.\n",
      " 0.66666667 0.66666667 0.4        0.         0.         0.\n",
      " 0.28571429 0.         0.14285714 0.         0.         0.\n",
      " 0.5        0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25\n",
      " 0.16666667 0.         0.33333333 0.5        0.         0.\n",
      " 0.         0.         0.5        0.         1.         0.2\n",
      " 0.         0.         0.         0.25       0.         0.\n",
      " 0.         1.         0.         0.33333333 0.         0.33333333\n",
      " 0.         0.25       0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Recall:  [0.125      0.         0.33333333 0.         0.         0.\n",
      " 0.66666667 0.         0.6        0.         0.         0.\n",
      " 0.66666667 0.         0.66666667 0.         0.         0.5\n",
      " 0.         0.         0.         0.14285714 1.         0.\n",
      " 0.         0.         0.42857143 0.         0.         0.\n",
      " 0.         0.         0.         0.25       1.         0.5\n",
      " 0.3        0.         0.         0.         0.33333333 0.\n",
      " 0.         0.         0.5        0.         0.         0.2\n",
      " 0.         0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.         0.6        0.\n",
      " 0.         0.57142857 0.33333333 0.5        0.4        0.\n",
      " 0.5        0.5        1.         0.         0.28571429 0.\n",
      " 0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.8        0.         0.\n",
      " 0.         0.5        0.         0.         0.5        0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.25       0.         0.         0.66666667 0.         0.25\n",
      " 0.         0.         0.25       0.5        0.33333333 1.\n",
      " 0.4        0.         0.         0.25       0.16666667 0.25\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.14285714 0.33333333 0.         0.         0.         0.5\n",
      " 0.         0.33333333 0.         0.5        1.         0.\n",
      " 0.         0.         0.33333333 0.         0.5        0.\n",
      " 0.5        0.66666667 1.         0.         0.         0.\n",
      " 0.4        0.         0.16666667 0.         0.         0.\n",
      " 0.5        0.         0.2        0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.5        0.         0.66666667 0.14285714 0.         0.\n",
      " 0.         0.         1.         0.         0.18181818 0.25\n",
      " 0.         0.         0.         0.5        0.         0.\n",
      " 0.         0.33333333 0.         0.33333333 0.         0.14285714\n",
      " 0.         0.4        0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.08101852 0.         0.66666667 0.         0.         0.\n",
      " 0.47619048 0.         0.6        0.         0.         0.\n",
      " 0.4047619  0.         0.58333333 0.         0.         0.375\n",
      " 0.         0.         0.         0.32142857 0.5625     0.\n",
      " 0.         0.         0.42857143 0.         0.         0.\n",
      " 0.         0.         0.         0.625      0.6        0.28846154\n",
      " 0.25714286 0.         0.         0.         0.66666667 0.\n",
      " 0.         0.         0.75       0.         0.         0.35\n",
      " 0.         0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.         0.425      0.\n",
      " 0.         0.53571429 0.41666667 0.45       0.45       0.\n",
      " 0.4        0.41666667 0.75       0.         0.64285714 0.\n",
      " 0.         0.         0.23809524 0.         0.         0.\n",
      " 0.         0.         0.         0.73333333 0.         0.\n",
      " 0.         0.5        0.         0.         0.41666667 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.375      0.         0.         0.5        0.         0.375\n",
      " 0.         0.         0.13928571 0.32692308 0.41666667 1.\n",
      " 0.31111111 0.         0.         0.375      0.25       0.25\n",
      " 0.         0.         0.         0.32142857 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.32142857\n",
      " 0.17142857 0.66666667 0.         0.         0.         0.53571429\n",
      " 0.         0.41666667 0.         0.35       0.57142857 0.\n",
      " 0.         0.         0.33333333 0.         0.5        0.\n",
      " 0.58333333 0.66666667 0.7        0.         0.         0.\n",
      " 0.34285714 0.         0.1547619  0.         0.         0.\n",
      " 0.5        0.         0.26666667 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.375\n",
      " 0.33333333 0.         0.5        0.32142857 0.         0.\n",
      " 0.         0.         0.75       0.         0.59090909 0.225\n",
      " 0.         0.         0.         0.375      0.         0.\n",
      " 0.         0.66666667 0.         0.33333333 0.         0.23809524\n",
      " 0.         0.325      0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "mini_batch 100\n",
      "mini_batch 101\n",
      "mini_batch 102\n",
      "mini_batch 103\n",
      "mini_batch 104\n",
      "mini_batch 105\n",
      "mini_batch 106\n",
      "mini_batch 107\n",
      "mini_batch 108\n",
      "mini_batch 109\n",
      "mini_batch 110\n",
      "mini_batch 111\n",
      "mini_batch 112\n",
      "mini_batch 113\n",
      "mini_batch 114\n",
      "mini_batch 115\n",
      "mini_batch 116\n",
      "mini_batch 117\n",
      "mini_batch 118\n",
      "mini_batch 119\n",
      "mini_batch 120\n",
      "mini_batch 121\n",
      "mini_batch 122\n",
      "mini_batch 123\n",
      "mini_batch 124\n",
      "mini_batch 125\n",
      "mini_batch 126\n",
      "mini_batch 127\n",
      "mini_batch 128\n",
      "mini_batch 129\n",
      "mini_batch 130\n",
      "mini_batch 131\n",
      "mini_batch 132\n",
      "mini_batch 133\n",
      "mini_batch 134\n",
      "mini_batch 135\n",
      "mini_batch 136\n",
      "mini_batch 137\n",
      "mini_batch 138\n",
      "mini_batch 139\n",
      "mini_batch 140\n",
      "mini_batch 141\n",
      "mini_batch 142\n",
      "mini_batch 143\n",
      "mini_batch 144\n",
      "mini_batch 145\n",
      "mini_batch 146\n",
      "mini_batch 147\n",
      "mini_batch 148\n",
      "mini_batch 149\n",
      "Epoch 2\n",
      "average minibatch 150 loss: 2.649\n",
      "\n",
      "Labels:  tensor([158,   9, 145, 161, 183, 153,  14, 139,  21,  15, 176,  49, 111, 110,\n",
      "         44,  61,  76, 144,  74, 134, 148,  41, 159, 154,  50, 167,  71, 163,\n",
      "        186,  53,  31,  72,  81, 111, 132, 100, 122,  72, 191,  99,  83, 154,\n",
      "         45,  32,  40,  93, 130,   7, 114,  49, 109,  60,  99,  90, 180, 189,\n",
      "        198, 104, 173, 108, 184, 152, 149, 100], device='cuda:0')\n",
      "Output:  tensor([169, 169, 145,  89, 183, 153, 186, 139,  55,  15, 116, 131, 160, 105,\n",
      "        106,  61, 146, 178, 123, 134, 148,  41, 149,  81, 106, 139, 149,  29,\n",
      "         49,  59, 188, 105,  81, 140, 132, 100, 122,  72, 189, 175,  83, 154,\n",
      "         45,  32,  11, 104, 149,  33,  38,  49, 109,  75, 118,  90, 180, 132,\n",
      "        198, 173, 154, 169, 184,  35, 149, 100], device='cuda:0')\n",
      "True Positives:  [1. 0. 1. 0. 0. 0. 2. 0. 3. 0. 0. 0. 2. 0. 3. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 3. 0. 0. 0. 0. 1. 0. 1. 1. 1. 3. 0. 0. 0. 2. 0. 0. 0. 2. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 3. 0. 1. 4. 1. 2. 2. 0. 3. 2. 3. 0. 2. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 4. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 4. 0. 1. 0. 0. 1. 2. 1. 1. 3. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 5. 0. 2. 0. 1. 2. 0. 1. 0. 1. 0. 1. 0.\n",
      " 5. 2. 2. 1. 1. 0. 2. 0. 2. 1. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 2. 2. 0. 0. 1. 2. 0. 0. 0. 1. 0. 2. 0. 1.\n",
      " 0. 2. 0. 0. 0. 1. 0. 0.]\n",
      "False Positives:  [26.  0.  0.  1.  1.  0.  5.  0.  2.  1.  1.  0. 12.  1.  2.  6.  3.  3.\n",
      "  0.  0.  9.  1.  7.  2.  1.  0.  4.  2. 11.  0.  0.  2.  5.  0.  5. 12.\n",
      " 11.  2.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.\n",
      "  1.  0.  0. 11. 10.  2.  0.  4.  1.  3.  2.  1.  7.  4.  3.  0.  0.  7.\n",
      "  0.  5.  7.  1.  0.  2.  0.  0.  2.  2.  0.  2.  0.  1.  3.  0.  3.  2.\n",
      "  0.  0.  3.  0.  7.  0.  1.  4.  1.  4.  3.  1.  0.  1. 36. 13.  1.  0.\n",
      "  7.  3.  0.  1.  2.  3.  1.  1.  0.  7.  0.  0.  1.  2.  4.  2.  6.  6.\n",
      "  4.  0.  0.  1.  1.  4.  0.  1.  1.  4. 12.  0.  3.  4.  2.  0.  1.  1.\n",
      "  2.  2.  3.  5.  8.  0.  5.  0.  6.  6.  6.  1.  2.  0.  2.  1.  1.  0.\n",
      "  1.  2.  0.  0.  0.  3.  8.  0.  4.  1.  2.  0.  1.  0.  2.  1.  0.  4.\n",
      "  0.  0.  0.  3.  1.  2.  0.  1.  1.  4.  2.  2.  0.  6.  0.  1.  0.  3.\n",
      "  0.  3.]\n",
      "False Negatives:  [7. 1. 2. 1. 0. 2. 2. 3. 3. 2. 2. 3. 1. 2. 1. 2. 5. 1. 1. 5. 5. 6. 0. 2.\n",
      " 1. 0. 4. 0. 3. 2. 5. 2. 5. 3. 0. 1. 7. 5. 1. 3. 2. 3. 1. 2. 1. 2. 2. 4.\n",
      " 5. 3. 3. 3. 2. 5. 0. 0. 0. 2. 2. 4. 0. 3. 2. 2. 3. 2. 3. 2. 0. 6. 6. 1.\n",
      " 1. 1. 2. 4. 2. 2. 4. 0. 3. 1. 3. 1. 4. 1. 2. 1. 1. 1. 2. 1. 3. 3. 4. 1.\n",
      " 3. 1. 7. 1. 4. 3. 2. 4. 3. 2. 2. 1. 3. 5. 4. 3. 5. 4. 4. 4. 0. 1. 0. 0.\n",
      " 3. 4. 7. 2. 1. 1. 6. 2. 2. 1. 4. 4. 0. 2. 1. 1. 0. 0. 0. 4. 2. 5. 1. 3.\n",
      " 4. 1. 0. 2. 0. 0. 3. 4. 5. 3. 5. 1. 2. 4. 5. 3. 5. 1. 2. 6. 1. 4. 2. 1.\n",
      " 1. 4. 1. 6. 5. 1. 3. 2. 0. 1. 9. 3. 1. 2. 0. 1. 4. 5. 4. 2. 3. 4. 3. 6.\n",
      " 4. 3. 3. 0. 2. 3. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.015625 0.       0.       0.       0.03125  0.\n",
      " 0.046875 0.       0.       0.       0.03125  0.       0.046875 0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.046875 0.       0.       0.       0.       0.015625\n",
      " 0.       0.015625 0.015625 0.015625 0.046875 0.       0.       0.\n",
      " 0.03125  0.       0.       0.       0.03125  0.       0.       0.015625\n",
      " 0.015625 0.       0.       0.       0.015625 0.       0.       0.\n",
      " 0.015625 0.       0.046875 0.       0.015625 0.0625   0.015625 0.03125\n",
      " 0.03125  0.       0.046875 0.03125  0.046875 0.       0.03125  0.015625\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.015625 0.0625   0.015625 0.       0.       0.015625 0.       0.\n",
      " 0.015625 0.015625 0.       0.       0.       0.       0.       0.\n",
      " 0.015625 0.       0.       0.0625   0.       0.015625 0.       0.\n",
      " 0.015625 0.03125  0.015625 0.015625 0.046875 0.       0.       0.015625\n",
      " 0.015625 0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.015625\n",
      " 0.       0.       0.       0.078125 0.       0.03125  0.       0.015625\n",
      " 0.03125  0.       0.015625 0.       0.015625 0.       0.015625 0.\n",
      " 0.078125 0.03125  0.03125  0.015625 0.015625 0.       0.03125  0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.       0.015625 0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.015625\n",
      " 0.015625 0.       0.03125  0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.       0.03125  0.03125  0.       0.       0.015625 0.03125\n",
      " 0.       0.       0.       0.015625 0.       0.03125  0.       0.015625\n",
      " 0.       0.03125  0.       0.       0.       0.015625 0.       0.      ]\n",
      "Precision:  [0.03703704 0.         1.         0.         0.         0.\n",
      " 0.28571429 0.         0.6        0.         0.         0.\n",
      " 0.14285714 0.         0.6        0.         0.         0.25\n",
      " 0.         0.         0.         0.5        0.125      0.\n",
      " 0.         0.         0.42857143 0.         0.         0.\n",
      " 0.         0.33333333 0.         1.         0.16666667 0.07692308\n",
      " 0.21428571 0.         0.         0.         1.         0.\n",
      " 0.         0.         1.         0.         0.         0.5\n",
      " 0.5        0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.         0.23076923 0.\n",
      " 1.         0.5        0.5        0.4        0.5        0.\n",
      " 0.3        0.33333333 0.5        0.         1.         0.125\n",
      " 0.         0.         0.125      0.         0.         0.\n",
      " 0.         0.         0.33333333 0.66666667 1.         0.\n",
      " 0.         0.5        0.         0.         0.25       0.33333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.5        0.         0.         0.5        0.         0.5\n",
      " 0.         0.         0.02702703 0.13333333 0.5        1.\n",
      " 0.3        0.         0.         0.5        0.33333333 0.25\n",
      " 0.         0.         0.         0.125      1.         0.\n",
      " 0.         0.33333333 0.         0.         0.         0.14285714\n",
      " 0.2        1.         0.         0.         0.         0.55555556\n",
      " 0.         0.66666667 0.         0.2        0.14285714 0.\n",
      " 0.25       0.         0.33333333 0.         0.5        0.\n",
      " 0.71428571 0.5        0.4        0.16666667 0.11111111 0.\n",
      " 0.28571429 0.         0.25       0.14285714 0.         0.\n",
      " 0.5        0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25\n",
      " 0.11111111 0.         0.33333333 0.5        0.         0.\n",
      " 0.         0.         0.5        0.         1.         0.33333333\n",
      " 0.         0.         1.         0.4        0.         0.\n",
      " 0.         0.5        0.         0.33333333 0.         0.33333333\n",
      " 0.         0.25       0.         0.         0.         0.25\n",
      " 0.         0.        ]\n",
      "Recall:  [0.125      0.         0.33333333 0.         0.         0.\n",
      " 0.5        0.         0.5        0.         0.         0.\n",
      " 0.66666667 0.         0.75       0.         0.         0.5\n",
      " 0.         0.         0.         0.14285714 1.         0.\n",
      " 0.         0.         0.42857143 0.         0.         0.\n",
      " 0.         0.33333333 0.         0.25       1.         0.5\n",
      " 0.3        0.         0.         0.         0.5        0.\n",
      " 0.         0.         0.66666667 0.         0.         0.2\n",
      " 0.16666667 0.         0.         0.         0.33333333 0.\n",
      " 0.         0.         1.         0.         0.6        0.\n",
      " 1.         0.57142857 0.33333333 0.5        0.4        0.\n",
      " 0.5        0.5        1.         0.         0.25       0.5\n",
      " 0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.25       0.8        0.25       0.\n",
      " 0.         0.5        0.         0.         0.5        0.5\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.25       0.         0.         0.8        0.         0.25\n",
      " 0.         0.         0.25       0.5        0.33333333 0.5\n",
      " 0.5        0.         0.         0.25       0.16666667 0.2\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.2        0.         0.         0.         0.5\n",
      " 0.14285714 0.33333333 0.         0.         0.         0.55555556\n",
      " 0.         0.5        0.         0.5        1.         0.\n",
      " 1.         0.         0.33333333 0.         0.5        0.\n",
      " 0.55555556 0.66666667 1.         0.33333333 1.         0.\n",
      " 0.4        0.         0.28571429 0.25       0.         0.\n",
      " 0.5        0.         0.16666667 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5\n",
      " 0.5        0.         0.66666667 0.14285714 0.         0.\n",
      " 0.         0.         1.         0.         0.18181818 0.4\n",
      " 0.         0.         1.         0.66666667 0.         0.\n",
      " 0.         0.33333333 0.         0.33333333 0.         0.14285714\n",
      " 0.         0.4        0.         0.         0.         0.25\n",
      " 0.         0.        ]\n",
      "Balanced Classification Rate:  [0.08101852 0.         0.66666667 0.         0.         0.\n",
      " 0.39285714 0.         0.55       0.         0.         0.\n",
      " 0.4047619  0.         0.675      0.         0.         0.375\n",
      " 0.         0.         0.         0.32142857 0.5625     0.\n",
      " 0.         0.         0.42857143 0.         0.         0.\n",
      " 0.         0.33333333 0.         0.625      0.58333333 0.28846154\n",
      " 0.25714286 0.         0.         0.         0.75       0.\n",
      " 0.         0.         0.83333333 0.         0.         0.35\n",
      " 0.33333333 0.         0.         0.         0.41666667 0.\n",
      " 0.         0.         1.         0.         0.41538462 0.\n",
      " 1.         0.53571429 0.41666667 0.45       0.45       0.\n",
      " 0.4        0.41666667 0.75       0.         0.625      0.3125\n",
      " 0.         0.         0.22916667 0.         0.         0.\n",
      " 0.         0.         0.29166667 0.73333333 0.625      0.\n",
      " 0.         0.5        0.         0.         0.375      0.41666667\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.375      0.         0.         0.65       0.         0.375\n",
      " 0.         0.         0.13851351 0.31666667 0.41666667 0.75\n",
      " 0.4        0.         0.         0.375      0.25       0.225\n",
      " 0.         0.         0.         0.3125     1.         0.\n",
      " 0.         0.26666667 0.         0.         0.         0.32142857\n",
      " 0.17142857 0.66666667 0.         0.         0.         0.55555556\n",
      " 0.         0.58333333 0.         0.35       0.57142857 0.\n",
      " 0.625      0.         0.33333333 0.         0.5        0.\n",
      " 0.63492063 0.58333333 0.7        0.25       0.55555556 0.\n",
      " 0.34285714 0.         0.26785714 0.19642857 0.         0.\n",
      " 0.5        0.         0.25       0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.375\n",
      " 0.30555556 0.         0.5        0.32142857 0.         0.\n",
      " 0.         0.         0.75       0.         0.59090909 0.36666667\n",
      " 0.         0.         1.         0.53333333 0.         0.\n",
      " 0.         0.41666667 0.         0.33333333 0.         0.23809524\n",
      " 0.         0.325      0.         0.         0.         0.25\n",
      " 0.         0.        ]\n",
      "mini_batch 150\n",
      "mini_batch 151\n",
      "mini_batch 152\n",
      "mini_batch 153\n",
      "mini_batch 154\n",
      "mini_batch 155\n",
      "mini_batch 156\n",
      "mini_batch 157\n",
      "mini_batch 158\n",
      "mini_batch 159\n",
      "mini_batch 160\n",
      "mini_batch 161\n",
      "mini_batch 162\n",
      "mini_batch 163\n",
      "mini_batch 164\n",
      "mini_batch 165\n",
      "mini_batch 166\n",
      "mini_batch 167\n",
      "mini_batch 168\n",
      "mini_batch 169\n",
      "mini_batch 170\n",
      "mini_batch 171\n",
      "mini_batch 172\n",
      "mini_batch 173\n",
      "mini_batch 174\n",
      "mini_batch 175\n",
      "mini_batch 176\n",
      "mini_batch 177\n",
      "mini_batch 178\n",
      "mini_batch 179\n",
      "mini_batch 180\n",
      "mini_batch 181\n",
      "mini_batch 182\n",
      "mini_batch 183\n",
      "mini_batch 184\n",
      "mini_batch 185\n",
      "mini_batch 186\n",
      "mini_batch 187\n",
      "mini_batch 188\n",
      "mini_batch 189\n",
      "mini_batch 190\n",
      "mini_batch 191\n",
      "mini_batch 192\n",
      "mini_batch 193\n",
      "mini_batch 194\n",
      "mini_batch 195\n",
      "mini_batch 196\n",
      "mini_batch 197\n",
      "mini_batch 198\n",
      "mini_batch 199\n",
      "Epoch 2\n",
      "average minibatch 200 loss: 2.542\n",
      "\n",
      "Labels:  tensor([189, 110, 123,  58, 151, 181,  81, 191, 142,  39,  65, 152,  20, 146,\n",
      "        155,  27,  34, 157,  53, 163, 126, 131, 186, 159,  53,  85,  42, 108,\n",
      "        174,  60,  94, 105,  92,   7, 157, 200,   5,  63,   5, 100, 129, 132,\n",
      "        126,  63,  46, 101,  17, 163,  15,  37,  84,  30, 171, 125,  61,  93,\n",
      "         87, 185,  89,   6, 126,  39,  61, 132], device='cuda:0')\n",
      "Output:  tensor([189, 192, 123,  58, 151, 196, 100, 173, 100,  39,  24, 152,  35, 100,\n",
      "        155,  27, 106, 157, 102,  24,   2,   5, 107, 103,  53,  85,  42, 108,\n",
      "        115,  60,  94, 105, 104,  22, 178, 200,  32, 169,   5, 100, 115, 132,\n",
      "        126,  33,  46, 101, 112, 163,  15,  21,  56, 156, 171,   7,  70,  93,\n",
      "         90, 185,  22, 126, 126, 147, 143, 132], device='cuda:0')\n",
      "True Positives:  [1. 0. 1. 0. 1. 0. 2. 0. 3. 0. 0. 0. 2. 0. 4. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 4. 0. 0. 0. 0. 1. 0. 1. 1. 1. 3. 0. 1. 0. 2. 1. 0. 0. 2. 1. 0. 1.\n",
      " 1. 0. 0. 0. 2. 0. 0. 0. 1. 1. 3. 1. 1. 4. 1. 2. 2. 0. 3. 2. 3. 0. 2. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 4. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 5. 1. 1. 0. 0. 2. 2. 1. 2. 3. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 3. 1. 1. 0. 0. 0. 7. 0. 2. 0. 1. 2. 0. 1. 0. 1. 0. 1. 0.\n",
      " 5. 2. 2. 1. 1. 0. 3. 1. 2. 1. 1. 0. 3. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 0. 3. 1. 0. 0. 0. 0. 2. 0. 2. 2. 0. 0. 1. 2. 1. 0. 0. 1. 1. 2. 0. 1.\n",
      " 0. 2. 0. 0. 0. 1. 0. 1.]\n",
      "False Positives:  [26.  1.  0.  1.  2.  0.  6.  0.  2.  1.  1.  0. 12.  1.  2.  6.  3.  3.\n",
      "  0.  0. 10.  3.  7.  4.  1.  0.  4.  2. 11.  0.  0.  3.  6.  0.  6. 12.\n",
      " 11.  2.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0. 11. 10.  2.  0.  4.  1.  3.  2.  1.  7.  4.  3.  1.  0.  7.\n",
      "  0.  5.  7.  1.  0.  2.  0.  0.  2.  2.  0.  2.  0.  1.  3.  0.  3.  3.\n",
      "  0.  0.  3.  0.  7.  0.  1.  4.  1.  7.  3.  2.  1.  2. 36. 14.  2.  0.\n",
      "  7.  3.  0.  2.  2.  3.  3.  1.  0.  7.  0.  0.  1.  2.  4.  2.  6.  7.\n",
      "  4.  0.  0.  1.  1.  4.  0.  1.  1.  4. 12.  0.  3.  4.  2.  0.  2.  1.\n",
      "  2.  2.  4.  5.  8.  0.  5.  0.  6.  6.  6.  2.  2.  0.  2.  1.  1.  0.\n",
      "  1.  2.  0.  0.  0.  3.  9.  0.  4.  1.  3.  0.  1.  0.  2.  2.  0.  4.\n",
      "  0.  0.  0.  3.  1.  2.  0.  1.  1.  4.  2.  3.  0.  6.  0.  2.  0.  3.\n",
      "  0.  3.]\n",
      "False Negatives:  [7. 1. 2. 1. 1. 3. 3. 3. 3. 2. 2. 3. 1. 2. 1. 2. 6. 1. 1. 6. 5. 6. 0. 2.\n",
      " 1. 0. 4. 0. 3. 3. 5. 2. 5. 4. 0. 1. 8. 5. 2. 3. 2. 3. 1. 2. 1. 2. 2. 4.\n",
      " 5. 3. 3. 3. 3. 5. 0. 0. 0. 2. 2. 4. 2. 3. 4. 2. 4. 2. 3. 2. 0. 6. 6. 1.\n",
      " 1. 1. 2. 4. 2. 2. 4. 0. 4. 1. 3. 2. 4. 1. 3. 1. 2. 1. 2. 2. 3. 3. 4. 1.\n",
      " 3. 1. 7. 1. 4. 3. 2. 4. 3. 2. 2. 1. 3. 6. 4. 3. 5. 4. 4. 4. 0. 1. 0. 0.\n",
      " 3. 4. 7. 2. 2. 2. 6. 2. 3. 1. 5. 4. 0. 2. 1. 1. 0. 0. 0. 4. 2. 6. 1. 3.\n",
      " 4. 2. 0. 2. 0. 0. 3. 4. 5. 3. 5. 1. 3. 4. 6. 3. 5. 1. 3. 6. 1. 4. 2. 1.\n",
      " 1. 4. 1. 6. 5. 2. 3. 2. 0. 1. 9. 3. 2. 2. 0. 1. 4. 6. 4. 2. 3. 4. 4. 6.\n",
      " 4. 3. 3. 0. 2. 3. 0. 0.]\n",
      "Accuracy:  [0.015625 0.       0.015625 0.       0.015625 0.       0.03125  0.\n",
      " 0.046875 0.       0.       0.       0.03125  0.       0.0625   0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.0625   0.       0.       0.       0.       0.015625\n",
      " 0.       0.015625 0.015625 0.015625 0.046875 0.       0.015625 0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.015625 0.       0.015625\n",
      " 0.015625 0.       0.       0.       0.03125  0.       0.       0.\n",
      " 0.015625 0.015625 0.046875 0.015625 0.015625 0.0625   0.015625 0.03125\n",
      " 0.03125  0.       0.046875 0.03125  0.046875 0.       0.03125  0.015625\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.015625 0.0625   0.015625 0.       0.015625 0.015625 0.       0.\n",
      " 0.015625 0.015625 0.       0.       0.015625 0.015625 0.       0.\n",
      " 0.015625 0.       0.       0.078125 0.015625 0.015625 0.       0.\n",
      " 0.03125  0.03125  0.015625 0.03125  0.046875 0.       0.       0.015625\n",
      " 0.015625 0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.015625 0.015625 0.       0.       0.046875 0.015625 0.015625\n",
      " 0.       0.       0.       0.109375 0.       0.03125  0.       0.015625\n",
      " 0.03125  0.       0.015625 0.       0.015625 0.       0.015625 0.\n",
      " 0.078125 0.03125  0.03125  0.015625 0.015625 0.       0.046875 0.015625\n",
      " 0.03125  0.015625 0.015625 0.       0.046875 0.       0.015625 0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.015625\n",
      " 0.015625 0.       0.046875 0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.       0.03125  0.03125  0.       0.       0.015625 0.03125\n",
      " 0.015625 0.       0.       0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.       0.03125  0.       0.       0.       0.015625 0.       0.015625]\n",
      "Precision:  [0.03703704 0.         1.         0.         0.33333333 0.\n",
      " 0.25       0.         0.6        0.         0.         0.\n",
      " 0.14285714 0.         0.66666667 0.         0.         0.25\n",
      " 0.         0.         0.         0.25       0.125      0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.25       0.         1.         0.14285714 0.07692308\n",
      " 0.21428571 0.         1.         0.         1.         1.\n",
      " 0.         0.         1.         1.         0.         0.5\n",
      " 0.5        0.         0.         0.         0.66666667 0.\n",
      " 0.         0.         1.         0.08333333 0.23076923 0.33333333\n",
      " 1.         0.5        0.5        0.4        0.5        0.\n",
      " 0.3        0.33333333 0.5        0.         1.         0.125\n",
      " 0.         0.         0.125      0.         0.         0.\n",
      " 0.         0.         0.33333333 0.66666667 1.         0.\n",
      " 1.         0.5        0.         0.         0.25       0.25\n",
      " 0.         0.         0.25       1.         0.         0.\n",
      " 0.5        0.         0.         0.41666667 0.25       0.33333333\n",
      " 0.         0.         0.05263158 0.125      0.33333333 1.\n",
      " 0.3        0.         0.         0.33333333 0.33333333 0.25\n",
      " 0.         0.         0.         0.125      1.         0.\n",
      " 0.         0.33333333 0.2        0.         0.         0.3\n",
      " 0.2        1.         0.         0.         0.         0.63636364\n",
      " 0.         0.66666667 0.         0.2        0.14285714 0.\n",
      " 0.25       0.         0.33333333 0.         0.33333333 0.\n",
      " 0.71428571 0.5        0.33333333 0.16666667 0.11111111 0.\n",
      " 0.375      1.         0.25       0.14285714 0.14285714 0.\n",
      " 0.6        0.         0.33333333 0.         0.         0.\n",
      " 0.5        0.         0.         0.         0.         0.25\n",
      " 0.1        0.         0.42857143 0.5        0.         0.\n",
      " 0.         0.         0.5        0.         1.         0.33333333\n",
      " 0.         0.         1.         0.4        0.5        0.\n",
      " 0.         0.5        0.5        0.33333333 0.         0.25\n",
      " 0.         0.25       0.         0.         0.         0.25\n",
      " 0.         0.25      ]\n",
      "Recall:  [0.125      0.         0.33333333 0.         0.5        0.\n",
      " 0.4        0.         0.5        0.         0.         0.\n",
      " 0.66666667 0.         0.8        0.         0.         0.5\n",
      " 0.         0.         0.         0.14285714 1.         0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.33333333 0.         0.2        1.         0.5\n",
      " 0.27272727 0.         0.33333333 0.         0.5        0.25\n",
      " 0.         0.         0.66666667 0.33333333 0.         0.2\n",
      " 0.16666667 0.         0.         0.         0.4        0.\n",
      " 0.         0.         1.         0.33333333 0.6        0.2\n",
      " 0.33333333 0.57142857 0.2        0.5        0.33333333 0.\n",
      " 0.5        0.5        1.         0.         0.25       0.5\n",
      " 0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.2        0.8        0.25       0.\n",
      " 0.2        0.5        0.         0.         0.33333333 0.5\n",
      " 0.         0.         0.25       0.25       0.         0.\n",
      " 0.25       0.         0.         0.83333333 0.2        0.25\n",
      " 0.         0.         0.4        0.5        0.33333333 0.66666667\n",
      " 0.5        0.         0.         0.25       0.16666667 0.2\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.2        0.125      0.         0.         0.6\n",
      " 0.14285714 0.33333333 0.         0.         0.         0.63636364\n",
      " 0.         0.5        0.         0.5        1.         0.\n",
      " 1.         0.         0.33333333 0.         0.5        0.\n",
      " 0.55555556 0.5        1.         0.33333333 1.         0.\n",
      " 0.5        0.2        0.28571429 0.25       0.16666667 0.\n",
      " 0.5        0.         0.14285714 0.         0.         0.\n",
      " 0.25       0.         0.         0.         0.         0.5\n",
      " 0.5        0.         0.75       0.14285714 0.         0.\n",
      " 0.         0.         1.         0.         0.18181818 0.4\n",
      " 0.         0.         1.         0.66666667 0.2        0.\n",
      " 0.         0.33333333 0.25       0.33333333 0.         0.14285714\n",
      " 0.         0.4        0.         0.         0.         0.25\n",
      " 0.         1.        ]\n",
      "Balanced Classification Rate:  [0.08101852 0.         0.66666667 0.         0.41666667 0.\n",
      " 0.325      0.         0.55       0.         0.         0.\n",
      " 0.4047619  0.         0.73333333 0.         0.         0.375\n",
      " 0.         0.         0.         0.19642857 0.5625     0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.29166667 0.         0.6        0.57142857 0.28846154\n",
      " 0.24350649 0.         0.66666667 0.         0.75       0.625\n",
      " 0.         0.         0.83333333 0.66666667 0.         0.35\n",
      " 0.33333333 0.         0.         0.         0.53333333 0.\n",
      " 0.         0.         1.         0.20833333 0.41538462 0.26666667\n",
      " 0.66666667 0.53571429 0.35       0.45       0.41666667 0.\n",
      " 0.4        0.41666667 0.75       0.         0.625      0.3125\n",
      " 0.         0.         0.22916667 0.         0.         0.\n",
      " 0.         0.         0.26666667 0.73333333 0.625      0.\n",
      " 0.6        0.5        0.         0.         0.29166667 0.375\n",
      " 0.         0.         0.25       0.625      0.         0.\n",
      " 0.375      0.         0.         0.625      0.225      0.29166667\n",
      " 0.         0.         0.22631579 0.3125     0.33333333 0.83333333\n",
      " 0.4        0.         0.         0.29166667 0.25       0.225\n",
      " 0.         0.         0.         0.3125     1.         0.\n",
      " 0.         0.26666667 0.1625     0.         0.         0.45\n",
      " 0.17142857 0.66666667 0.         0.         0.         0.63636364\n",
      " 0.         0.58333333 0.         0.35       0.57142857 0.\n",
      " 0.625      0.         0.33333333 0.         0.41666667 0.\n",
      " 0.63492063 0.5        0.66666667 0.25       0.55555556 0.\n",
      " 0.4375     0.6        0.26785714 0.19642857 0.1547619  0.\n",
      " 0.55       0.         0.23809524 0.         0.         0.\n",
      " 0.375      0.         0.         0.         0.         0.375\n",
      " 0.3        0.         0.58928571 0.32142857 0.         0.\n",
      " 0.         0.         0.75       0.         0.59090909 0.36666667\n",
      " 0.         0.         1.         0.53333333 0.35       0.\n",
      " 0.         0.41666667 0.375      0.33333333 0.         0.19642857\n",
      " 0.         0.325      0.         0.         0.         0.25\n",
      " 0.         0.625     ]\n",
      "mini_batch 200\n",
      "mini_batch 201\n",
      "mini_batch 202\n",
      "mini_batch 203\n",
      "mini_batch 204\n",
      "mini_batch 205\n",
      "mini_batch 206\n",
      "mini_batch 207\n",
      "mini_batch 208\n",
      "mini_batch 209\n",
      "mini_batch 210\n",
      "mini_batch 211\n",
      "mini_batch 212\n",
      "mini_batch 213\n",
      "mini_batch 214\n",
      "mini_batch 215\n",
      "mini_batch 216\n",
      "mini_batch 217\n",
      "mini_batch 218\n",
      "mini_batch 219\n",
      "mini_batch 220\n",
      "mini_batch 221\n",
      "mini_batch 222\n",
      "mini_batch 223\n",
      "mini_batch 224\n",
      "mini_batch 225\n",
      "mini_batch 226\n",
      "mini_batch 227\n",
      "mini_batch 228\n",
      "mini_batch 229\n",
      "mini_batch 230\n",
      "mini_batch 231\n",
      "mini_batch 232\n",
      "mini_batch 233\n",
      "mini_batch 234\n",
      "mini_batch 235\n",
      "mini_batch 236\n",
      "mini_batch 237\n",
      "mini_batch 238\n",
      "mini_batch 239\n",
      "mini_batch 240\n",
      "mini_batch 241\n",
      "mini_batch 242\n",
      "mini_batch 243\n",
      "mini_batch 244\n",
      "mini_batch 245\n",
      "mini_batch 246\n",
      "mini_batch 247\n",
      "mini_batch 248\n",
      "mini_batch 249\n",
      "Epoch 2\n",
      "average minibatch 250 loss: 2.399\n",
      "\n",
      "Labels:  tensor([ 64,   1,  62, 177,  92, 174,  16,  84, 135,  46,   9, 114,  64,  67,\n",
      "        110,  92, 117,  16, 110,  81, 151,  52, 111,  89,  31,  36,  60, 176,\n",
      "        152,  40, 120, 172, 142,  67, 124, 171,  85, 170, 106,  89, 146, 125,\n",
      "        133, 131, 110, 126, 192,  24, 127, 119,  57, 184,   9, 162, 125, 168,\n",
      "        143, 176, 173,  93, 128,  50,  72, 200], device='cuda:0')\n",
      "Output:  tensor([ 22,   1,  62,  98,   3,  43, 114,  84, 135,  46, 114, 186, 170,  37,\n",
      "         60,  90, 173, 132, 186,  81, 151,  29, 147,  65,  13,  36,  60,  24,\n",
      "        149, 173,   1,  69,  68,  72, 124,  41,  85, 173,   6,  89, 191, 102,\n",
      "          1,  71,  34,  37, 118, 173,  34, 119,  57,  10, 114,  37, 125, 168,\n",
      "         64, 105, 154, 192, 128,  34,  72, 132], device='cuda:0')\n",
      "True Positives:  [2. 0. 1. 0. 1. 0. 2. 0. 3. 0. 0. 0. 2. 0. 4. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 4. 0. 0. 0. 0. 1. 0. 1. 1. 2. 3. 0. 1. 0. 2. 1. 0. 0. 2. 2. 0. 1.\n",
      " 1. 0. 0. 0. 2. 0. 0. 0. 2. 1. 3. 2. 1. 5. 1. 2. 2. 0. 3. 2. 3. 0. 2. 2.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 2. 4. 1. 1. 2. 1. 0. 0. 2. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 5. 1. 1. 0. 0. 2. 2. 1. 2. 3. 0. 0. 1. 1. 1. 0. 0. 0. 1. 2. 0.\n",
      " 0. 1. 1. 1. 1. 3. 1. 2. 0. 0. 0. 7. 0. 2. 1. 1. 2. 0. 1. 0. 1. 0. 1. 0.\n",
      " 5. 2. 2. 1. 1. 0. 4. 1. 2. 1. 1. 0. 3. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 2.\n",
      " 1. 0. 3. 1. 0. 0. 0. 0. 2. 0. 2. 2. 0. 0. 1. 2. 1. 0. 0. 1. 1. 2. 0. 1.\n",
      " 0. 2. 0. 0. 0. 1. 0. 1.]\n",
      "False Positives:  [28.  1.  1.  1.  2.  1.  6.  0.  2.  2.  1.  0. 13.  1.  2.  6.  3.  3.\n",
      "  0.  0. 10.  4.  7.  5.  1.  0.  4.  2. 12.  0.  0.  3.  6.  3.  6. 12.\n",
      " 14.  2.  0.  0.  1.  0.  2.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0. 11. 10.  3.  0.  4.  1.  4.  3.  1.  7.  5.  4.  1.  1.  8.\n",
      "  0.  5.  7.  1.  0.  2.  0.  0.  2.  2.  0.  2.  0.  1.  3.  0.  3.  4.\n",
      "  0.  0.  3.  0.  7.  0.  1.  5.  1.  7.  3.  3.  1.  2. 37. 14.  2.  0.\n",
      "  7.  3.  0.  2.  2.  6.  3.  1.  0.  8.  0.  0.  1.  2.  4.  2.  6.  7.\n",
      "  4.  0.  0.  1.  1.  6.  0.  1.  1.  4. 12.  0.  3.  4.  2.  0.  2.  1.\n",
      "  2.  2.  5.  5.  9.  0.  5.  0.  6.  7.  6.  2.  2.  0.  2.  1.  1.  0.\n",
      "  1.  2.  0.  0.  0.  3.  9.  1.  4.  1.  7.  0.  1.  0.  2.  2.  0.  4.\n",
      "  0.  0.  0.  3.  1.  4.  0.  1.  1.  4.  3.  4.  0.  6.  0.  2.  0.  3.\n",
      "  0.  3.]\n",
      "False Negatives:  [7. 1. 2. 1. 1. 3. 3. 3. 5. 2. 2. 3. 1. 2. 1. 4. 6. 1. 1. 6. 5. 6. 0. 3.\n",
      " 1. 0. 4. 0. 3. 3. 6. 2. 5. 4. 0. 1. 8. 5. 2. 4. 2. 3. 1. 2. 1. 2. 2. 4.\n",
      " 5. 4. 3. 4. 3. 5. 0. 0. 0. 2. 2. 4. 2. 3. 4. 4. 4. 2. 5. 2. 0. 6. 6. 1.\n",
      " 1. 1. 2. 4. 2. 2. 4. 0. 4. 1. 3. 2. 4. 1. 3. 1. 3. 1. 2. 4. 4. 3. 4. 1.\n",
      " 3. 1. 7. 1. 4. 3. 2. 4. 3. 3. 2. 1. 3. 9. 5. 3. 5. 5. 4. 4. 1. 1. 0. 1.\n",
      " 3. 4. 7. 2. 3. 3. 7. 2. 3. 1. 6. 4. 1. 2. 1. 1. 0. 0. 0. 4. 2. 7. 2. 3.\n",
      " 4. 3. 0. 2. 0. 0. 3. 5. 5. 3. 5. 1. 3. 4. 6. 3. 5. 2. 3. 6. 1. 4. 2. 1.\n",
      " 1. 5. 2. 7. 6. 3. 3. 4. 1. 1. 9. 3. 2. 2. 0. 2. 4. 6. 4. 2. 3. 4. 4. 7.\n",
      " 4. 3. 3. 0. 2. 3. 0. 1.]\n",
      "Accuracy:  [0.03125  0.       0.015625 0.       0.015625 0.       0.03125  0.\n",
      " 0.046875 0.       0.       0.       0.03125  0.       0.0625   0.\n",
      " 0.       0.015625 0.       0.       0.       0.015625 0.015625 0.\n",
      " 0.       0.       0.0625   0.       0.       0.       0.       0.015625\n",
      " 0.       0.015625 0.015625 0.03125  0.046875 0.       0.015625 0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.03125  0.       0.015625\n",
      " 0.015625 0.       0.       0.       0.03125  0.       0.       0.\n",
      " 0.03125  0.015625 0.046875 0.03125  0.015625 0.078125 0.015625 0.03125\n",
      " 0.03125  0.       0.046875 0.03125  0.046875 0.       0.03125  0.03125\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.\n",
      " 0.03125  0.0625   0.015625 0.015625 0.03125  0.015625 0.       0.\n",
      " 0.03125  0.015625 0.       0.       0.015625 0.015625 0.       0.\n",
      " 0.015625 0.       0.       0.078125 0.015625 0.015625 0.       0.\n",
      " 0.03125  0.03125  0.015625 0.03125  0.046875 0.       0.       0.015625\n",
      " 0.015625 0.015625 0.       0.       0.       0.015625 0.03125  0.\n",
      " 0.       0.015625 0.015625 0.015625 0.015625 0.046875 0.015625 0.03125\n",
      " 0.       0.       0.       0.109375 0.       0.03125  0.015625 0.015625\n",
      " 0.03125  0.       0.015625 0.       0.015625 0.       0.015625 0.\n",
      " 0.078125 0.03125  0.03125  0.015625 0.015625 0.       0.0625   0.015625\n",
      " 0.03125  0.015625 0.015625 0.       0.046875 0.       0.015625 0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.03125\n",
      " 0.015625 0.       0.046875 0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.       0.03125  0.03125  0.       0.       0.015625 0.03125\n",
      " 0.015625 0.       0.       0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.       0.03125  0.       0.       0.       0.015625 0.       0.015625]\n",
      "Precision:  [0.06666667 0.         0.5        0.         0.33333333 0.\n",
      " 0.25       0.         0.6        0.         0.         0.\n",
      " 0.13333333 0.         0.66666667 0.         0.         0.25\n",
      " 0.         0.         0.         0.2        0.125      0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.25       0.         0.25       0.14285714 0.14285714\n",
      " 0.17647059 0.         1.         0.         0.66666667 1.\n",
      " 0.         0.         1.         1.         0.         0.5\n",
      " 0.5        0.         0.         0.         0.66666667 0.\n",
      " 0.         0.         1.         0.08333333 0.23076923 0.4\n",
      " 1.         0.55555556 0.5        0.33333333 0.4        0.\n",
      " 0.3        0.28571429 0.42857143 0.         0.66666667 0.2\n",
      " 0.         0.         0.125      0.         0.         0.\n",
      " 0.         0.         0.5        0.66666667 1.         0.33333333\n",
      " 1.         0.5        0.         0.         0.4        0.2\n",
      " 0.         0.         0.25       1.         0.         0.\n",
      " 0.5        0.         0.         0.41666667 0.25       0.25\n",
      " 0.         0.         0.05128205 0.125      0.33333333 1.\n",
      " 0.3        0.         0.         0.33333333 0.33333333 0.14285714\n",
      " 0.         0.         0.         0.11111111 1.         0.\n",
      " 0.         0.33333333 0.2        0.33333333 0.14285714 0.3\n",
      " 0.2        1.         0.         0.         0.         0.53846154\n",
      " 0.         0.66666667 0.5        0.2        0.14285714 0.\n",
      " 0.25       0.         0.33333333 0.         0.33333333 0.\n",
      " 0.71428571 0.5        0.28571429 0.16666667 0.1        0.\n",
      " 0.44444444 1.         0.25       0.125      0.14285714 0.\n",
      " 0.6        0.         0.33333333 0.         0.         0.\n",
      " 0.5        0.         0.         0.         0.         0.4\n",
      " 0.1        0.         0.42857143 0.5        0.         0.\n",
      " 0.         0.         0.5        0.         1.         0.33333333\n",
      " 0.         0.         1.         0.4        0.5        0.\n",
      " 0.         0.5        0.5        0.33333333 0.         0.2\n",
      " 0.         0.25       0.         0.         0.         0.25\n",
      " 0.         0.25      ]\n",
      "Recall:  [0.22222222 0.         0.33333333 0.         0.5        0.\n",
      " 0.4        0.         0.375      0.         0.         0.\n",
      " 0.66666667 0.         0.8        0.         0.         0.5\n",
      " 0.         0.         0.         0.14285714 1.         0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.33333333 0.         0.2        1.         0.66666667\n",
      " 0.27272727 0.         0.33333333 0.         0.5        0.25\n",
      " 0.         0.         0.66666667 0.5        0.         0.2\n",
      " 0.16666667 0.         0.         0.         0.4        0.\n",
      " 0.         0.         1.         0.33333333 0.6        0.33333333\n",
      " 0.33333333 0.625      0.2        0.33333333 0.33333333 0.\n",
      " 0.375      0.5        1.         0.         0.25       0.66666667\n",
      " 0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.33333333 0.8        0.25       0.33333333\n",
      " 0.33333333 0.5        0.         0.         0.4        0.5\n",
      " 0.         0.         0.2        0.25       0.         0.\n",
      " 0.25       0.         0.         0.83333333 0.2        0.25\n",
      " 0.         0.         0.4        0.4        0.33333333 0.66666667\n",
      " 0.5        0.         0.         0.25       0.16666667 0.16666667\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.2        0.125      0.33333333 0.25       0.5\n",
      " 0.125      0.5        0.         0.         0.         0.63636364\n",
      " 0.         0.5        0.5        0.5        1.         0.\n",
      " 1.         0.         0.33333333 0.         0.33333333 0.\n",
      " 0.55555556 0.4        1.         0.33333333 1.         0.\n",
      " 0.57142857 0.16666667 0.28571429 0.25       0.16666667 0.\n",
      " 0.5        0.         0.14285714 0.         0.         0.\n",
      " 0.25       0.         0.         0.         0.         0.66666667\n",
      " 0.5        0.         0.6        0.125      0.         0.\n",
      " 0.         0.         0.66666667 0.         0.18181818 0.4\n",
      " 0.         0.         1.         0.5        0.2        0.\n",
      " 0.         0.33333333 0.25       0.33333333 0.         0.125\n",
      " 0.         0.4        0.         0.         0.         0.25\n",
      " 0.         0.5       ]\n",
      "Balanced Classification Rate:  [0.14444444 0.         0.41666667 0.         0.41666667 0.\n",
      " 0.325      0.         0.4875     0.         0.         0.\n",
      " 0.4        0.         0.73333333 0.         0.         0.375\n",
      " 0.         0.         0.         0.17142857 0.5625     0.\n",
      " 0.         0.         0.5        0.         0.         0.\n",
      " 0.         0.29166667 0.         0.225      0.57142857 0.4047619\n",
      " 0.22459893 0.         0.66666667 0.         0.58333333 0.625\n",
      " 0.         0.         0.83333333 0.75       0.         0.35\n",
      " 0.33333333 0.         0.         0.         0.53333333 0.\n",
      " 0.         0.         1.         0.20833333 0.41538462 0.36666667\n",
      " 0.66666667 0.59027778 0.35       0.33333333 0.36666667 0.\n",
      " 0.3375     0.39285714 0.71428571 0.         0.45833333 0.43333333\n",
      " 0.         0.         0.22916667 0.         0.         0.\n",
      " 0.         0.         0.41666667 0.73333333 0.625      0.33333333\n",
      " 0.66666667 0.5        0.         0.         0.4        0.35\n",
      " 0.         0.         0.225      0.625      0.         0.\n",
      " 0.375      0.         0.         0.625      0.225      0.25\n",
      " 0.         0.         0.22564103 0.2625     0.33333333 0.83333333\n",
      " 0.4        0.         0.         0.29166667 0.25       0.1547619\n",
      " 0.         0.         0.         0.30555556 1.         0.\n",
      " 0.         0.26666667 0.1625     0.33333333 0.19642857 0.4\n",
      " 0.1625     0.75       0.         0.         0.         0.58741259\n",
      " 0.         0.58333333 0.5        0.35       0.57142857 0.\n",
      " 0.625      0.         0.33333333 0.         0.33333333 0.\n",
      " 0.63492063 0.45       0.64285714 0.25       0.55       0.\n",
      " 0.50793651 0.58333333 0.26785714 0.1875     0.1547619  0.\n",
      " 0.55       0.         0.23809524 0.         0.         0.\n",
      " 0.375      0.         0.         0.         0.         0.53333333\n",
      " 0.3        0.         0.51428571 0.3125     0.         0.\n",
      " 0.         0.         0.58333333 0.         0.59090909 0.36666667\n",
      " 0.         0.         1.         0.45       0.35       0.\n",
      " 0.         0.41666667 0.375      0.33333333 0.         0.1625\n",
      " 0.         0.325      0.         0.         0.         0.25\n",
      " 0.         0.375     ]\n",
      "mini_batch 250\n",
      "mini_batch 251\n",
      "mini_batch 252\n",
      "mini_batch 253\n",
      "mini_batch 254\n",
      "mini_batch 255\n",
      "mini_batch 256\n",
      "mini_batch 257\n",
      "mini_batch 258\n",
      "mini_batch 259\n",
      "mini_batch 260\n",
      "mini_batch 261\n",
      "mini_batch 262\n",
      "mini_batch 263\n",
      "mini_batch 264\n",
      "mini_batch 265\n",
      "mini_batch 266\n",
      "mini_batch 267\n",
      "mini_batch 268\n",
      "mini_batch 269\n",
      "mini_batch 270\n",
      "mini_batch 271\n",
      "mini_batch 272\n",
      "mini_batch 273\n",
      "mini_batch 274\n",
      "mini_batch 275\n",
      "mini_batch 276\n",
      "mini_batch 277\n",
      "mini_batch 278\n",
      "mini_batch 279\n",
      "mini_batch 280\n",
      "mini_batch 281\n",
      "mini_batch 282\n",
      "mini_batch 283\n",
      "mini_batch 284\n",
      "mini_batch 285\n",
      "mini_batch 286\n",
      "mini_batch 287\n",
      "mini_batch 288\n",
      "mini_batch 289\n",
      "mini_batch 290\n",
      "mini_batch 291\n",
      "mini_batch 292\n",
      "mini_batch 293\n",
      "mini_batch 294\n",
      "mini_batch 295\n",
      "mini_batch 296\n",
      "mini_batch 297\n",
      "mini_batch 298\n",
      "mini_batch 299\n",
      "Epoch 2\n",
      "average minibatch 300 loss: 2.314\n",
      "\n",
      "Labels:  tensor([ 19,   4, 117, 163,   1, 139,  24,  93, 143, 102, 100,  42,  93,  37,\n",
      "         46, 132,  34, 191, 127, 107, 102, 183, 100,  86,  22,  15,  60, 160,\n",
      "        173, 177, 175,   6, 104, 136,  24, 188,  53, 150, 188,  36, 159, 172,\n",
      "        122, 103,  24,  74,  27,  13, 179, 146,  32, 116,  62, 184,  46,  58,\n",
      "         13,  88, 170, 100,   1, 153,   5, 178], device='cuda:0')\n",
      "Output:  tensor([114, 184,  38,  21, 111, 139,  24,  22,  70, 164,  58, 190,  93, 122,\n",
      "        103, 105,  76, 169,   5,  48,   3, 103, 100,  86,  22, 184, 107,   8,\n",
      "         42, 177, 194,   6,  24, 136, 109, 122,  53,   1, 107,  36,  98, 172,\n",
      "        122, 122, 111,  74,  27,  13,  63, 113,  38, 109,  62, 184, 126,  58,\n",
      "         33,  58,   4,   4, 109, 192,   5,  35], device='cuda:0')\n",
      "True Positives:  [2. 0. 1. 0. 2. 1. 2. 0. 3. 0. 0. 0. 3. 0. 4. 0. 0. 1. 0. 0. 0. 2. 1. 1.\n",
      " 0. 0. 5. 0. 0. 0. 0. 1. 0. 1. 1. 3. 3. 0. 1. 0. 2. 1. 0. 0. 2. 2. 0. 1.\n",
      " 1. 0. 0. 0. 3. 0. 0. 0. 2. 2. 3. 2. 1. 6. 1. 2. 2. 0. 3. 2. 3. 0. 2. 2.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 2. 4. 1. 1. 2. 2. 0. 0. 2. 1. 0. 0. 2. 1. 0. 0.\n",
      " 1. 0. 0. 6. 1. 1. 0. 0. 2. 2. 1. 2. 3. 0. 0. 1. 1. 1. 0. 0. 0. 1. 2. 0.\n",
      " 0. 2. 1. 1. 1. 3. 1. 2. 0. 0. 0. 7. 0. 2. 1. 2. 2. 0. 2. 0. 1. 0. 1. 0.\n",
      " 5. 2. 2. 1. 1. 0. 4. 1. 2. 1. 1. 0. 3. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 2.\n",
      " 1. 0. 3. 2. 0. 0. 0. 0. 3. 0. 2. 2. 0. 0. 1. 3. 1. 0. 0. 1. 1. 2. 0. 1.\n",
      " 0. 2. 0. 0. 0. 1. 0. 1.]\n",
      "False Positives:  [29.  1.  2.  3.  3.  1.  6.  1.  2.  2.  1.  0. 13.  1.  2.  6.  3.  3.\n",
      "  0.  0. 11.  5.  7.  6.  1.  0.  4.  2. 12.  0.  0.  3.  7.  3.  7. 12.\n",
      " 14.  4.  0.  0.  1.  1.  2.  0.  0.  0.  0.  2.  1.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0. 13. 10.  3.  0.  4.  2.  4.  3.  1.  7.  5.  4.  2.  1.  8.\n",
      "  0.  5.  7.  2.  0.  2.  0.  0.  2.  2.  0.  2.  0.  1.  3.  0.  3.  4.\n",
      "  0.  0.  3.  0.  7.  0.  1.  6.  1.  7.  3.  3.  3.  2. 38. 14.  4.  0.\n",
      " 10.  3.  2.  2.  3.  7.  3.  1.  0.  8.  0.  0.  1.  5.  4.  2.  6.  8.\n",
      "  4.  0.  0.  1.  1.  6.  0.  1.  1.  4. 12.  0.  3.  4.  2.  0.  2.  1.\n",
      "  2.  2.  5.  5.  9.  0.  5.  0.  6.  7.  6.  2.  2.  0.  2.  1.  1.  0.\n",
      "  1.  3.  0.  0.  0.  3. 10.  1.  4.  1.  7.  0.  1.  0.  2.  2.  0.  4.\n",
      "  0.  0.  0.  5.  1.  4.  0.  1.  1.  5.  3.  5.  0.  7.  0.  2.  0.  3.\n",
      "  0.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  2.  1.  3.  3.  3.  5.  2.  2.  3.  2.  2.  2.  4.  6.  1.\n",
      "  2.  6.  5.  6.  0.  5.  1.  0.  4.  0.  3.  3.  6.  3.  5.  5.  0.  1.\n",
      "  9.  5.  2.  4.  2.  4.  1.  2.  1.  4.  2.  4.  5.  4.  3.  4.  3.  5.\n",
      "  0.  0.  0.  2.  2.  5.  2.  3.  4.  4.  4.  2.  5.  2.  0.  6.  6.  1.\n",
      "  1.  1.  2.  4.  2.  2.  4.  0.  4.  1.  3.  2.  4.  1.  3.  2.  3.  1.\n",
      "  2.  4.  5.  3.  4.  1.  3.  1.  7.  3.  4.  5.  3.  5.  3.  3.  3.  1.\n",
      "  3.  9.  5.  3.  5.  5.  4.  5.  2.  1.  0.  1.  3.  4.  7.  2.  3.  3.\n",
      "  8.  2.  3.  1.  6.  5.  1.  2.  1.  1.  0.  0.  0.  4.  2.  7.  3.  3.\n",
      "  4.  4.  0.  2.  0.  1.  3.  5.  6.  3.  5.  1.  3.  4.  7.  4.  5.  2.\n",
      "  4.  6.  1.  4.  2.  1.  1.  6.  2.  7.  7.  3.  4.  4.  1.  2. 10.  3.\n",
      "  2.  2.  1.  2.  4.  6.  4.  4.  3.  4.  5.  7.  4.  3.  3.  0.  2.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.03125  0.       0.015625 0.       0.03125  0.015625 0.03125  0.\n",
      " 0.046875 0.       0.       0.       0.046875 0.       0.0625   0.\n",
      " 0.       0.015625 0.       0.       0.       0.03125  0.015625 0.015625\n",
      " 0.       0.       0.078125 0.       0.       0.       0.       0.015625\n",
      " 0.       0.015625 0.015625 0.046875 0.046875 0.       0.015625 0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.03125  0.       0.015625\n",
      " 0.015625 0.       0.       0.       0.046875 0.       0.       0.\n",
      " 0.03125  0.03125  0.046875 0.03125  0.015625 0.09375  0.015625 0.03125\n",
      " 0.03125  0.       0.046875 0.03125  0.046875 0.       0.03125  0.03125\n",
      " 0.       0.015625 0.015625 0.       0.       0.       0.       0.\n",
      " 0.03125  0.0625   0.015625 0.015625 0.03125  0.03125  0.       0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.015625 0.       0.\n",
      " 0.015625 0.       0.       0.09375  0.015625 0.015625 0.       0.\n",
      " 0.03125  0.03125  0.015625 0.03125  0.046875 0.       0.       0.015625\n",
      " 0.015625 0.015625 0.       0.       0.       0.015625 0.03125  0.\n",
      " 0.       0.03125  0.015625 0.015625 0.015625 0.046875 0.015625 0.03125\n",
      " 0.       0.       0.       0.109375 0.       0.03125  0.015625 0.03125\n",
      " 0.03125  0.       0.03125  0.       0.015625 0.       0.015625 0.\n",
      " 0.078125 0.03125  0.03125  0.015625 0.015625 0.       0.0625   0.015625\n",
      " 0.03125  0.015625 0.015625 0.       0.046875 0.       0.015625 0.\n",
      " 0.       0.       0.015625 0.       0.       0.       0.       0.03125\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.       0.\n",
      " 0.046875 0.       0.03125  0.03125  0.       0.       0.015625 0.046875\n",
      " 0.015625 0.       0.       0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.       0.03125  0.       0.       0.       0.015625 0.       0.015625]\n",
      "Precision:  [0.06451613 0.         0.33333333 0.         0.4        0.5\n",
      " 0.25       0.         0.6        0.         0.         0.\n",
      " 0.1875     0.         0.66666667 0.         0.         0.25\n",
      " 0.         0.         0.         0.28571429 0.125      0.14285714\n",
      " 0.         0.         0.55555556 0.         0.         0.\n",
      " 0.         0.25       0.         0.25       0.125      0.2\n",
      " 0.17647059 0.         1.         0.         0.66666667 0.5\n",
      " 0.         0.         1.         1.         0.         0.33333333\n",
      " 0.5        0.         0.         0.         0.75       0.\n",
      " 0.         0.         1.         0.13333333 0.23076923 0.4\n",
      " 1.         0.6        0.33333333 0.33333333 0.4        0.\n",
      " 0.3        0.28571429 0.42857143 0.         0.66666667 0.2\n",
      " 0.         0.16666667 0.125      0.         0.         0.\n",
      " 0.         0.         0.5        0.66666667 1.         0.33333333\n",
      " 1.         0.66666667 0.         0.         0.4        0.2\n",
      " 0.         0.         0.4        1.         0.         0.\n",
      " 0.5        0.         0.         0.46153846 0.25       0.25\n",
      " 0.         0.         0.05       0.125      0.2        1.\n",
      " 0.23076923 0.         0.         0.33333333 0.25       0.125\n",
      " 0.         0.         0.         0.11111111 1.         0.\n",
      " 0.         0.28571429 0.2        0.33333333 0.14285714 0.27272727\n",
      " 0.2        1.         0.         0.         0.         0.53846154\n",
      " 0.         0.66666667 0.5        0.33333333 0.14285714 0.\n",
      " 0.4        0.         0.33333333 0.         0.33333333 0.\n",
      " 0.71428571 0.5        0.28571429 0.16666667 0.1        0.\n",
      " 0.44444444 1.         0.25       0.125      0.14285714 0.\n",
      " 0.6        0.         0.33333333 0.         0.         0.\n",
      " 0.5        0.         0.         0.         0.         0.4\n",
      " 0.09090909 0.         0.42857143 0.66666667 0.         0.\n",
      " 0.         0.         0.6        0.         1.         0.33333333\n",
      " 0.         0.         1.         0.375      0.5        0.\n",
      " 0.         0.5        0.5        0.28571429 0.         0.16666667\n",
      " 0.         0.22222222 0.         0.         0.         0.25\n",
      " 0.         0.25      ]\n",
      "Recall:  [0.18181818 0.         0.33333333 0.         0.66666667 0.25\n",
      " 0.4        0.         0.375      0.         0.         0.\n",
      " 0.6        0.         0.66666667 0.         0.         0.5\n",
      " 0.         0.         0.         0.25       1.         0.16666667\n",
      " 0.         0.         0.55555556 0.         0.         0.\n",
      " 0.         0.25       0.         0.16666667 1.         0.75\n",
      " 0.25       0.         0.33333333 0.         0.5        0.2\n",
      " 0.         0.         0.66666667 0.33333333 0.         0.2\n",
      " 0.16666667 0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.5        0.6        0.28571429\n",
      " 0.33333333 0.66666667 0.2        0.33333333 0.33333333 0.\n",
      " 0.375      0.5        1.         0.         0.25       0.66666667\n",
      " 0.         0.5        0.33333333 0.         0.         0.\n",
      " 0.         0.         0.33333333 0.8        0.25       0.33333333\n",
      " 0.33333333 0.66666667 0.         0.         0.4        0.5\n",
      " 0.         0.         0.28571429 0.25       0.         0.\n",
      " 0.25       0.         0.         0.66666667 0.2        0.16666667\n",
      " 0.         0.         0.4        0.4        0.25       0.66666667\n",
      " 0.5        0.         0.         0.25       0.16666667 0.16666667\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.33333333 0.125      0.33333333 0.25       0.5\n",
      " 0.11111111 0.5        0.         0.         0.         0.58333333\n",
      " 0.         0.5        0.5        0.66666667 1.         0.\n",
      " 1.         0.         0.33333333 0.         0.25       0.\n",
      " 0.55555556 0.33333333 1.         0.33333333 1.         0.\n",
      " 0.57142857 0.16666667 0.25       0.25       0.16666667 0.\n",
      " 0.5        0.         0.125      0.         0.         0.\n",
      " 0.2        0.         0.         0.         0.         0.66666667\n",
      " 0.5        0.         0.6        0.22222222 0.         0.\n",
      " 0.         0.         0.75       0.         0.16666667 0.4\n",
      " 0.         0.         0.5        0.6        0.2        0.\n",
      " 0.         0.2        0.25       0.33333333 0.         0.125\n",
      " 0.         0.4        0.         0.         0.         0.25\n",
      " 0.         0.5       ]\n",
      "Balanced Classification Rate:  [0.12316716 0.         0.33333333 0.         0.53333333 0.375\n",
      " 0.325      0.         0.4875     0.         0.         0.\n",
      " 0.39375    0.         0.66666667 0.         0.         0.375\n",
      " 0.         0.         0.         0.26785714 0.5625     0.1547619\n",
      " 0.         0.         0.55555556 0.         0.         0.\n",
      " 0.         0.25       0.         0.20833333 0.5625     0.475\n",
      " 0.21323529 0.         0.66666667 0.         0.58333333 0.35\n",
      " 0.         0.         0.83333333 0.66666667 0.         0.26666667\n",
      " 0.33333333 0.         0.         0.         0.625      0.\n",
      " 0.         0.         1.         0.31666667 0.41538462 0.34285714\n",
      " 0.66666667 0.63333333 0.26666667 0.33333333 0.36666667 0.\n",
      " 0.3375     0.39285714 0.71428571 0.         0.45833333 0.43333333\n",
      " 0.         0.33333333 0.22916667 0.         0.         0.\n",
      " 0.         0.         0.41666667 0.73333333 0.625      0.33333333\n",
      " 0.66666667 0.66666667 0.         0.         0.4        0.35\n",
      " 0.         0.         0.34285714 0.625      0.         0.\n",
      " 0.375      0.         0.         0.56410256 0.225      0.20833333\n",
      " 0.         0.         0.225      0.2625     0.225      0.83333333\n",
      " 0.36538462 0.         0.         0.29166667 0.20833333 0.14583333\n",
      " 0.         0.         0.         0.30555556 1.         0.\n",
      " 0.         0.30952381 0.1625     0.33333333 0.19642857 0.38636364\n",
      " 0.15555556 0.75       0.         0.         0.         0.56089744\n",
      " 0.         0.58333333 0.5        0.5        0.57142857 0.\n",
      " 0.7        0.         0.33333333 0.         0.29166667 0.\n",
      " 0.63492063 0.41666667 0.64285714 0.25       0.55       0.\n",
      " 0.50793651 0.58333333 0.25       0.1875     0.1547619  0.\n",
      " 0.55       0.         0.22916667 0.         0.         0.\n",
      " 0.35       0.         0.         0.         0.         0.53333333\n",
      " 0.29545455 0.         0.51428571 0.44444444 0.         0.\n",
      " 0.         0.         0.675      0.         0.58333333 0.36666667\n",
      " 0.         0.         0.75       0.4875     0.35       0.\n",
      " 0.         0.35       0.375      0.30952381 0.         0.14583333\n",
      " 0.         0.31111111 0.         0.         0.         0.25\n",
      " 0.         0.375     ]\n",
      "mini_batch 300\n",
      "mini_batch 301\n",
      "mini_batch 302\n",
      "mini_batch 303\n",
      "mini_batch 304\n",
      "mini_batch 305\n",
      "mini_batch 306\n",
      "mini_batch 307\n",
      "mini_batch 308\n",
      "mini_batch 309\n",
      "mini_batch 310\n",
      "mini_batch 311\n",
      "mini_batch 312\n",
      "mini_batch 313\n",
      "mini_batch 314\n",
      "mini_batch 315\n",
      "mini_batch 316\n",
      "mini_batch 317\n",
      "mini_batch 318\n",
      "mini_batch 319\n",
      "mini_batch 320\n",
      "mini_batch 321\n",
      "mini_batch 322\n",
      "mini_batch 323\n",
      "mini_batch 324\n",
      "mini_batch 325\n",
      "mini_batch 326\n",
      "mini_batch 327\n",
      "mini_batch 328\n",
      "mini_batch 329\n",
      "mini_batch 330\n",
      "mini_batch 331\n",
      "mini_batch 332\n",
      "mini_batch 333\n",
      "mini_batch 334\n",
      "mini_batch 335\n",
      "mini_batch 336\n",
      "mini_batch 337\n",
      "mini_batch 338\n",
      "mini_batch 339\n",
      "mini_batch 340\n",
      "mini_batch 341\n",
      "mini_batch 342\n",
      "mini_batch 343\n",
      "mini_batch 344\n",
      "mini_batch 345\n",
      "mini_batch 346\n",
      "mini_batch 347\n",
      "mini_batch 348\n",
      "mini_batch 349\n",
      "Epoch 2\n",
      "average minibatch 350 loss: 2.314\n",
      "\n",
      "Labels:  tensor([ 34,  66, 112, 151,  28,  75, 198,  76,  30,  87, 200, 146, 159, 177,\n",
      "         90, 137,  24,  61, 184, 185,  28,  59,  34, 134,  43, 127,  61,  68,\n",
      "        196,  52,  64,  49, 174,  14, 184, 145,  94, 186, 186,  47,  95, 193,\n",
      "        186,  34,  34, 179,   3, 128,  29,  58, 125, 137, 163,  20, 162, 117,\n",
      "        184,  61, 119,  24, 148,  11, 137, 123], device='cuda:0')\n",
      "Output:  tensor([101,  66,   4, 151,  28, 106, 198,  76,  30, 180, 200, 146,  46, 177,\n",
      "         67, 137,  24,  61, 184, 118,  28,  38,  99, 134, 180, 127,  42,  68,\n",
      "         38, 154,  64, 196, 198, 168, 184, 171,  65,  67,  35,  47,  95, 193,\n",
      "        187,  34,  34, 175,   3, 128,  29,  58, 125,  42, 163, 175,  67,  42,\n",
      "        184, 182, 119,  24,  56,  45, 137, 123], device='cuda:0')\n",
      "True Positives:  [2. 0. 2. 0. 2. 1. 2. 0. 3. 0. 0. 0. 3. 0. 4. 0. 0. 1. 0. 0. 0. 2. 1. 3.\n",
      " 0. 0. 5. 2. 1. 1. 0. 1. 0. 3. 1. 3. 3. 0. 1. 0. 2. 1. 0. 0. 2. 2. 1. 1.\n",
      " 1. 0. 0. 0. 3. 0. 0. 0. 2. 3. 3. 2. 2. 6. 1. 3. 2. 1. 3. 3. 3. 0. 2. 2.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 2. 4. 1. 1. 2. 2. 0. 0. 2. 1. 0. 0. 2. 1. 1. 0.\n",
      " 1. 0. 0. 6. 1. 1. 0. 0. 2. 2. 1. 2. 3. 0. 0. 1. 1. 1. 0. 0. 0. 1. 3. 0.\n",
      " 0. 2. 2. 1. 2. 3. 2. 3. 0. 0. 0. 7. 0. 3. 1. 2. 4. 0. 2. 0. 1. 0. 1. 0.\n",
      " 5. 3. 2. 1. 1. 0. 5. 1. 2. 1. 1. 0. 3. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 2.\n",
      " 1. 0. 3. 2. 0. 0. 0. 0. 4. 0. 2. 2. 0. 0. 1. 6. 1. 0. 0. 1. 1. 2. 0. 1.\n",
      " 1. 2. 0. 0. 0. 2. 0. 2.]\n",
      "False Positives:  [29.  1.  2.  4.  3.  1.  6.  1.  2.  2.  1.  0. 13.  1.  2.  6.  3.  3.\n",
      "  0.  0. 11.  5.  7.  6.  1.  0.  4.  2. 12.  0.  0.  3.  7.  3.  8. 12.\n",
      " 14.  6.  0.  0.  1.  4.  2.  0.  1.  1.  0.  2.  1.  0.  0.  0.  1.  1.\n",
      "  1.  2.  0. 13. 10.  3.  0.  4.  2.  4.  4.  1. 10.  5.  4.  2.  1.  8.\n",
      "  0.  5.  7.  2.  0.  2.  0.  0.  2.  2.  0.  2.  0.  1.  3.  0.  3.  4.\n",
      "  0.  0.  3.  0.  7.  0.  1.  6.  2.  7.  4.  3.  3.  2. 38. 15.  4.  0.\n",
      " 10.  3.  2.  2.  3.  7.  3.  1.  0.  9.  0.  0.  1.  5.  4.  2.  6.  8.\n",
      "  4.  0.  0.  1.  1.  6.  0.  1.  1.  4. 12.  0.  3.  4.  2.  0.  2.  1.\n",
      "  2.  2.  5.  5.  9.  0.  5.  0.  6.  8.  6.  2.  2.  0.  2.  1.  1.  0.\n",
      "  1.  3.  0.  0.  0.  4. 10.  1.  5.  1.  7.  0.  3.  0.  2.  2.  0.  6.\n",
      "  0.  1.  0.  5.  1.  4.  1.  1.  1.  5.  3.  5.  0.  7.  0.  3.  0.  4.\n",
      "  0.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  2.  1.  3.  3.  3.  5.  2.  3.  3.  2.  3.  2.  4.  6.  1.\n",
      "  2.  7.  5.  6.  0.  5.  1.  0.  4.  0.  3.  3.  6.  3.  5.  7.  0.  1.\n",
      "  9.  5.  2.  4.  2.  4.  2.  2.  1.  4.  2.  4.  6.  4.  3.  5.  3.  5.\n",
      "  0.  0.  0.  2.  3.  5.  4.  3.  4.  4.  4.  2.  5.  2.  0.  6.  6.  1.\n",
      "  1.  1.  3.  4.  2.  2.  4.  0.  4.  1.  3.  2.  4.  1.  4.  2.  3.  2.\n",
      "  2.  4.  5.  4.  4.  1.  3.  1.  7.  3.  4.  5.  3.  5.  3.  3.  3.  1.\n",
      "  3.  9.  5.  4.  5.  5.  4.  5.  3.  1.  0.  1.  3.  4.  7.  2.  3.  3.\n",
      "  8.  2.  3.  1.  6.  5.  1.  2.  1.  1.  1.  0.  0.  4.  2.  7.  3.  3.\n",
      "  5.  4.  0.  3.  0.  1.  3.  5.  6.  3.  5.  1.  3.  4.  8.  4.  5.  3.\n",
      "  4.  6.  1.  4.  2.  1.  1.  6.  2.  7.  7.  4.  4.  4.  1.  2. 11.  3.\n",
      "  2.  2.  1.  2.  5.  9.  4.  4.  3.  4.  5.  7.  4.  3.  3.  1.  2.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.03125  0.       0.03125  0.       0.03125  0.015625 0.03125  0.\n",
      " 0.046875 0.       0.       0.       0.046875 0.       0.0625   0.\n",
      " 0.       0.015625 0.       0.       0.       0.03125  0.015625 0.046875\n",
      " 0.       0.       0.078125 0.03125  0.015625 0.015625 0.       0.015625\n",
      " 0.       0.046875 0.015625 0.046875 0.046875 0.       0.015625 0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.03125  0.015625 0.015625\n",
      " 0.015625 0.       0.       0.       0.046875 0.       0.       0.\n",
      " 0.03125  0.046875 0.046875 0.03125  0.03125  0.09375  0.015625 0.046875\n",
      " 0.03125  0.015625 0.046875 0.046875 0.046875 0.       0.03125  0.03125\n",
      " 0.       0.015625 0.015625 0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.0625   0.015625 0.015625 0.03125  0.03125  0.       0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.015625 0.015625 0.\n",
      " 0.015625 0.       0.       0.09375  0.015625 0.015625 0.       0.\n",
      " 0.03125  0.03125  0.015625 0.03125  0.046875 0.       0.       0.015625\n",
      " 0.015625 0.015625 0.       0.       0.       0.015625 0.046875 0.\n",
      " 0.       0.03125  0.03125  0.015625 0.03125  0.046875 0.03125  0.046875\n",
      " 0.       0.       0.       0.109375 0.       0.046875 0.015625 0.03125\n",
      " 0.0625   0.       0.03125  0.       0.015625 0.       0.015625 0.\n",
      " 0.078125 0.046875 0.03125  0.015625 0.015625 0.       0.078125 0.015625\n",
      " 0.03125  0.015625 0.015625 0.       0.046875 0.       0.015625 0.\n",
      " 0.       0.       0.03125  0.       0.       0.       0.       0.03125\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.       0.\n",
      " 0.0625   0.       0.03125  0.03125  0.       0.       0.015625 0.09375\n",
      " 0.015625 0.       0.       0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.015625 0.03125  0.       0.       0.       0.03125  0.       0.03125 ]\n",
      "Precision:  [0.06451613 0.         0.5        0.         0.4        0.5\n",
      " 0.25       0.         0.6        0.         0.         0.\n",
      " 0.1875     0.         0.66666667 0.         0.         0.25\n",
      " 0.         0.         0.         0.28571429 0.125      0.33333333\n",
      " 0.         0.         0.55555556 0.5        0.07692308 1.\n",
      " 0.         0.25       0.         0.5        0.11111111 0.2\n",
      " 0.17647059 0.         1.         0.         0.66666667 0.2\n",
      " 0.         0.         0.66666667 0.66666667 1.         0.33333333\n",
      " 0.5        0.         0.         0.         0.75       0.\n",
      " 0.         0.         1.         0.1875     0.23076923 0.4\n",
      " 1.         0.6        0.33333333 0.42857143 0.33333333 0.5\n",
      " 0.23076923 0.375      0.42857143 0.         0.66666667 0.2\n",
      " 0.         0.16666667 0.125      0.33333333 0.         0.\n",
      " 0.         0.         0.5        0.66666667 1.         0.33333333\n",
      " 1.         0.66666667 0.         0.         0.4        0.2\n",
      " 0.         0.         0.4        1.         0.125      0.\n",
      " 0.5        0.         0.         0.46153846 0.2        0.25\n",
      " 0.         0.         0.05       0.11764706 0.2        1.\n",
      " 0.23076923 0.         0.         0.33333333 0.25       0.125\n",
      " 0.         0.         0.         0.1        1.         0.\n",
      " 0.         0.28571429 0.33333333 0.33333333 0.25       0.27272727\n",
      " 0.33333333 1.         0.         0.         0.         0.53846154\n",
      " 0.         0.75       0.5        0.33333333 0.25       0.\n",
      " 0.4        0.         0.33333333 0.         0.33333333 0.\n",
      " 0.71428571 0.6        0.28571429 0.16666667 0.1        0.\n",
      " 0.5        1.         0.25       0.11111111 0.14285714 0.\n",
      " 0.6        0.         0.33333333 0.         0.         0.\n",
      " 0.66666667 0.         0.         0.         0.         0.33333333\n",
      " 0.09090909 0.         0.375      0.66666667 0.         0.\n",
      " 0.         0.         0.66666667 0.         1.         0.25\n",
      " 0.         0.         1.         0.54545455 0.5        0.\n",
      " 0.         0.5        0.5        0.28571429 0.         0.16666667\n",
      " 1.         0.22222222 0.         0.         0.         0.33333333\n",
      " 0.         0.4       ]\n",
      "Recall:  [0.18181818 0.         0.5        0.         0.66666667 0.25\n",
      " 0.4        0.         0.375      0.         0.         0.\n",
      " 0.6        0.         0.66666667 0.         0.         0.5\n",
      " 0.         0.         0.         0.25       1.         0.375\n",
      " 0.         0.         0.55555556 1.         0.25       0.25\n",
      " 0.         0.25       0.         0.3        1.         0.75\n",
      " 0.25       0.         0.33333333 0.         0.5        0.2\n",
      " 0.         0.         0.66666667 0.33333333 0.33333333 0.2\n",
      " 0.14285714 0.         0.         0.         0.5        0.\n",
      " 0.         0.         1.         0.6        0.5        0.28571429\n",
      " 0.33333333 0.66666667 0.2        0.42857143 0.33333333 0.33333333\n",
      " 0.375      0.6        1.         0.         0.25       0.66666667\n",
      " 0.         0.5        0.25       0.2        0.         0.\n",
      " 0.         0.         0.33333333 0.8        0.25       0.33333333\n",
      " 0.33333333 0.66666667 0.         0.         0.4        0.33333333\n",
      " 0.         0.         0.28571429 0.2        0.2        0.\n",
      " 0.25       0.         0.         0.66666667 0.2        0.16666667\n",
      " 0.         0.         0.4        0.4        0.25       0.66666667\n",
      " 0.5        0.         0.         0.2        0.16666667 0.16666667\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.33333333 0.22222222 0.33333333 0.4        0.5\n",
      " 0.2        0.6        0.         0.         0.         0.58333333\n",
      " 0.         0.6        0.5        0.66666667 0.8        0.\n",
      " 1.         0.         0.33333333 0.         0.25       0.\n",
      " 0.5        0.42857143 1.         0.25       1.         0.\n",
      " 0.625      0.16666667 0.25       0.25       0.16666667 0.\n",
      " 0.5        0.         0.11111111 0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.66666667\n",
      " 0.5        0.         0.6        0.22222222 0.         0.\n",
      " 0.         0.         0.8        0.         0.15384615 0.4\n",
      " 0.         0.         0.5        0.75       0.16666667 0.\n",
      " 0.         0.2        0.25       0.33333333 0.         0.125\n",
      " 0.2        0.4        0.         0.         0.         0.4\n",
      " 0.         0.66666667]\n",
      "Balanced Classification Rate:  [0.12316716 0.         0.5        0.         0.53333333 0.375\n",
      " 0.325      0.         0.4875     0.         0.         0.\n",
      " 0.39375    0.         0.66666667 0.         0.         0.375\n",
      " 0.         0.         0.         0.26785714 0.5625     0.35416667\n",
      " 0.         0.         0.55555556 0.75       0.16346154 0.625\n",
      " 0.         0.25       0.         0.4        0.55555556 0.475\n",
      " 0.21323529 0.         0.66666667 0.         0.58333333 0.2\n",
      " 0.         0.         0.66666667 0.5        0.66666667 0.26666667\n",
      " 0.32142857 0.         0.         0.         0.625      0.\n",
      " 0.         0.         1.         0.39375    0.36538462 0.34285714\n",
      " 0.66666667 0.63333333 0.26666667 0.42857143 0.33333333 0.41666667\n",
      " 0.30288462 0.4875     0.71428571 0.         0.45833333 0.43333333\n",
      " 0.         0.33333333 0.1875     0.26666667 0.         0.\n",
      " 0.         0.         0.41666667 0.73333333 0.625      0.33333333\n",
      " 0.66666667 0.66666667 0.         0.         0.4        0.26666667\n",
      " 0.         0.         0.34285714 0.6        0.1625     0.\n",
      " 0.375      0.         0.         0.56410256 0.2        0.20833333\n",
      " 0.         0.         0.225      0.25882353 0.225      0.83333333\n",
      " 0.36538462 0.         0.         0.26666667 0.20833333 0.14583333\n",
      " 0.         0.         0.         0.3        1.         0.\n",
      " 0.         0.30952381 0.27777778 0.33333333 0.325      0.38636364\n",
      " 0.26666667 0.8        0.         0.         0.         0.56089744\n",
      " 0.         0.675      0.5        0.5        0.525      0.\n",
      " 0.7        0.         0.33333333 0.         0.29166667 0.\n",
      " 0.60714286 0.51428571 0.64285714 0.20833333 0.55       0.\n",
      " 0.5625     0.58333333 0.25       0.18055556 0.1547619  0.\n",
      " 0.55       0.         0.22222222 0.         0.         0.\n",
      " 0.5        0.         0.         0.         0.         0.5\n",
      " 0.29545455 0.         0.4875     0.44444444 0.         0.\n",
      " 0.         0.         0.73333333 0.         0.57692308 0.325\n",
      " 0.         0.         0.75       0.64772727 0.33333333 0.\n",
      " 0.         0.35       0.375      0.30952381 0.         0.14583333\n",
      " 0.6        0.31111111 0.         0.         0.         0.36666667\n",
      " 0.         0.53333333]\n",
      "mini_batch 350\n",
      "mini_batch 351\n",
      "mini_batch 352\n",
      "mini_batch 353\n",
      "mini_batch 354\n",
      "mini_batch 355\n",
      "mini_batch 356\n",
      "mini_batch 357\n",
      "mini_batch 358\n",
      "mini_batch 359\n",
      "mini_batch 360\n",
      "mini_batch 361\n",
      "mini_batch 362\n",
      "mini_batch 363\n",
      "mini_batch 364\n",
      "mini_batch 365\n",
      "mini_batch 366\n",
      "mini_batch 367\n",
      "mini_batch 368\n",
      "mini_batch 369\n",
      "mini_batch 370\n",
      "mini_batch 371\n",
      "mini_batch 372\n",
      "mini_batch 373\n",
      "mini_batch 374\n",
      "mini_batch 375\n",
      "Finished 2 epochs of training\n",
      "mini_batch 0\n",
      "mini_batch 1\n",
      "mini_batch 2\n",
      "mini_batch 3\n",
      "mini_batch 4\n",
      "mini_batch 5\n",
      "mini_batch 6\n",
      "mini_batch 7\n",
      "mini_batch 8\n",
      "mini_batch 9\n",
      "mini_batch 10\n",
      "mini_batch 11\n",
      "mini_batch 12\n",
      "mini_batch 13\n",
      "mini_batch 14\n",
      "mini_batch 15\n",
      "mini_batch 16\n",
      "mini_batch 17\n",
      "mini_batch 18\n",
      "mini_batch 19\n",
      "mini_batch 20\n",
      "mini_batch 21\n",
      "mini_batch 22\n",
      "mini_batch 23\n",
      "mini_batch 24\n",
      "mini_batch 25\n",
      "mini_batch 26\n",
      "mini_batch 27\n",
      "mini_batch 28\n",
      "mini_batch 29\n",
      "mini_batch 30\n",
      "mini_batch 31\n",
      "mini_batch 32\n",
      "mini_batch 33\n",
      "mini_batch 34\n",
      "mini_batch 35\n",
      "mini_batch 36\n",
      "mini_batch 37\n",
      "mini_batch 38\n",
      "mini_batch 39\n",
      "mini_batch 40\n",
      "mini_batch 41\n",
      "mini_batch 42\n",
      "mini_batch 43\n",
      "mini_batch 44\n",
      "mini_batch 45\n",
      "mini_batch 46\n",
      "mini_batch 47\n",
      "mini_batch 48\n",
      "mini_batch 49\n",
      "Epoch 3\n",
      "average minibatch 50 loss: 1.844\n",
      "\n",
      "Labels:  tensor([ 58,  89,   1, 163,  97,  66, 177,   9, 128,   7, 110,  56,  30,  13,\n",
      "        102, 122, 151,  24, 120, 180,   7, 193,  64, 182,  87,  37,   4,  31,\n",
      "        183, 171,  83, 111,  67,  96,  48,  59, 109,  69,  98, 180,  37,  62,\n",
      "         23,  17,  44,   5,  16,  56, 134, 150,  71,  63,  56, 113,  94,  18,\n",
      "        105, 146, 179,  66,  44, 149, 193, 149], device='cuda:0')\n",
      "Output:  tensor([ 58, 109,   1,  45,  97,  66, 172,  72, 121,   7, 110,  47,  30,  13,\n",
      "        126, 158, 192,  24,  72, 180,   7, 192,  64, 182,  87,  37, 152, 169,\n",
      "         46,  71,  83,  92,  67, 188,  48,  59, 109,  69,  98, 141,  37,  62,\n",
      "         24,  17, 192,   5, 142,  56, 134, 142,  71, 169,  39, 113,   7,   8,\n",
      "        105, 146,  37,  66,  44,  40, 193, 149], device='cuda:0')\n",
      "True Positives:  [3. 0. 2. 0. 3. 1. 4. 0. 3. 0. 0. 0. 4. 0. 4. 0. 1. 1. 0. 0. 0. 2. 1. 4.\n",
      " 0. 0. 5. 2. 1. 2. 0. 1. 0. 3. 1. 3. 5. 0. 1. 0. 2. 1. 0. 1. 2. 2. 1. 2.\n",
      " 1. 0. 0. 0. 3. 0. 0. 1. 2. 4. 4. 2. 2. 7. 1. 4. 2. 3. 4. 3. 4. 0. 3. 2.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 2. 4. 2. 1. 2. 2. 1. 0. 2. 1. 0. 0. 2. 1. 1. 0.\n",
      " 2. 1. 0. 6. 1. 1. 0. 0. 3. 2. 1. 2. 4. 1. 0. 1. 2. 1. 0. 0. 0. 1. 3. 0.\n",
      " 0. 2. 2. 1. 2. 3. 2. 3. 0. 0. 0. 7. 0. 4. 1. 2. 4. 0. 2. 0. 1. 0. 1. 0.\n",
      " 5. 4. 2. 1. 2. 0. 5. 1. 2. 1. 1. 0. 3. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 2.\n",
      " 1. 0. 3. 2. 0. 0. 0. 0. 4. 0. 2. 3. 0. 1. 1. 6. 1. 0. 0. 1. 1. 2. 0. 1.\n",
      " 2. 2. 0. 0. 0. 2. 0. 2.]\n",
      "False Positives:  [29.  1.  2.  4.  3.  1.  7.  2.  2.  2.  1.  0. 13.  1.  2.  6.  3.  3.\n",
      "  0.  0. 11.  5.  7.  7.  1.  0.  4.  2. 12.  0.  0.  3.  7.  3.  8. 12.\n",
      " 15.  6.  1.  1.  1.  4.  2.  0.  2.  2.  1.  2.  1.  0.  0.  0.  1.  1.\n",
      "  1.  2.  0. 13. 10.  3.  0.  4.  2.  4.  4.  1. 10.  5.  4.  2.  2. 10.\n",
      "  0.  5.  7.  2.  0.  2.  0.  0.  2.  2.  0.  2.  0.  1.  3.  0.  3.  4.\n",
      "  0.  1.  3.  0.  7.  0.  1.  6.  2.  7.  4.  3.  3.  2. 38. 15.  4.  0.\n",
      " 11.  3.  2.  2.  3.  7.  3.  1.  0.  9.  0.  0.  2.  5.  4.  2.  6.  9.\n",
      "  4.  0.  0.  1.  1.  6.  0.  1.  1.  4. 12.  0.  3.  4.  3.  2.  2.  1.\n",
      "  2.  2.  5.  5.  9.  0.  5.  1.  6.  8.  6.  2.  2.  1.  2.  1.  1.  0.\n",
      "  1.  3.  0.  0.  0.  4. 12.  1.  5.  2.  7.  0.  3.  0.  2.  2.  0.  6.\n",
      "  0.  1.  0.  5.  1.  4.  1.  2.  1.  5.  3.  8.  0.  7.  0.  3.  0.  4.\n",
      "  0.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  3.  1.  3.  3.  3.  6.  2.  3.  3.  2.  3.  2.  5.  6.  2.\n",
      "  2.  7.  5.  6.  1.  5.  1.  0.  4.  0.  3.  3.  7.  3.  5.  7.  0.  1.\n",
      "  9.  5.  2.  4.  2.  4.  2.  3.  1.  4.  2.  4.  6.  4.  3.  5.  3.  5.\n",
      "  0.  2.  0.  2.  3.  5.  4.  3.  5.  4.  4.  2.  5.  2.  0.  6.  6.  1.\n",
      "  1.  1.  3.  4.  2.  2.  4.  0.  4.  1.  3.  2.  4.  1.  4.  2.  4.  2.\n",
      "  2.  4.  5.  5.  4.  2.  3.  1.  7.  3.  4.  6.  3.  5.  3.  3.  3.  1.\n",
      "  3.  9.  6.  4.  5.  5.  4.  5.  3.  1.  0.  2.  3.  5.  7.  2.  3.  3.\n",
      "  8.  3.  3.  1.  6.  5.  1.  2.  1.  1.  1.  0.  0.  4.  2.  7.  3.  3.\n",
      "  5.  4.  0.  3.  1.  2.  4.  5.  6.  3.  5.  1.  3.  4.  8.  4.  5.  3.\n",
      "  5.  6.  1.  4.  2.  1.  1.  6.  3.  7.  7.  4.  4.  4.  2.  2. 12.  4.\n",
      "  2.  2.  2.  2.  5.  9.  4.  4.  3.  4.  5.  7.  5.  3.  3.  1.  2.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.046875 0.       0.03125  0.       0.046875 0.015625 0.0625   0.\n",
      " 0.046875 0.       0.       0.       0.0625   0.       0.0625   0.\n",
      " 0.015625 0.015625 0.       0.       0.       0.03125  0.015625 0.0625\n",
      " 0.       0.       0.078125 0.03125  0.015625 0.03125  0.       0.015625\n",
      " 0.       0.046875 0.015625 0.046875 0.078125 0.       0.015625 0.\n",
      " 0.03125  0.015625 0.       0.015625 0.03125  0.03125  0.015625 0.03125\n",
      " 0.015625 0.       0.       0.       0.046875 0.       0.       0.015625\n",
      " 0.03125  0.0625   0.0625   0.03125  0.03125  0.109375 0.015625 0.0625\n",
      " 0.03125  0.046875 0.0625   0.046875 0.0625   0.       0.046875 0.03125\n",
      " 0.       0.015625 0.015625 0.015625 0.       0.       0.       0.\n",
      " 0.03125  0.0625   0.03125  0.015625 0.03125  0.03125  0.015625 0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.015625 0.015625 0.\n",
      " 0.03125  0.015625 0.       0.09375  0.015625 0.015625 0.       0.\n",
      " 0.046875 0.03125  0.015625 0.03125  0.0625   0.015625 0.       0.015625\n",
      " 0.03125  0.015625 0.       0.       0.       0.015625 0.046875 0.\n",
      " 0.       0.03125  0.03125  0.015625 0.03125  0.046875 0.03125  0.046875\n",
      " 0.       0.       0.       0.109375 0.       0.0625   0.015625 0.03125\n",
      " 0.0625   0.       0.03125  0.       0.015625 0.       0.015625 0.\n",
      " 0.078125 0.0625   0.03125  0.015625 0.03125  0.       0.078125 0.015625\n",
      " 0.03125  0.015625 0.015625 0.       0.046875 0.       0.015625 0.\n",
      " 0.       0.       0.03125  0.       0.       0.       0.       0.03125\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.       0.\n",
      " 0.0625   0.       0.03125  0.046875 0.       0.015625 0.015625 0.09375\n",
      " 0.015625 0.       0.       0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.03125  0.03125  0.       0.       0.       0.03125  0.       0.03125 ]\n",
      "Precision:  [0.09375    0.         0.5        0.         0.5        0.5\n",
      " 0.36363636 0.         0.6        0.         0.         0.\n",
      " 0.23529412 0.         0.66666667 0.         0.25       0.25\n",
      " 0.         0.         0.         0.28571429 0.125      0.36363636\n",
      " 0.         0.         0.55555556 0.5        0.07692308 1.\n",
      " 0.         0.25       0.         0.5        0.11111111 0.2\n",
      " 0.25       0.         0.5        0.         0.66666667 0.2\n",
      " 0.         1.         0.5        0.5        0.5        0.5\n",
      " 0.5        0.         0.         0.         0.75       0.\n",
      " 0.         0.33333333 1.         0.23529412 0.28571429 0.4\n",
      " 1.         0.63636364 0.33333333 0.5        0.33333333 0.75\n",
      " 0.28571429 0.375      0.5        0.         0.6        0.16666667\n",
      " 0.         0.16666667 0.125      0.33333333 0.         0.\n",
      " 0.         0.         0.5        0.66666667 1.         0.33333333\n",
      " 1.         0.66666667 0.25       0.         0.4        0.2\n",
      " 0.         0.         0.4        1.         0.125      0.\n",
      " 0.66666667 0.14285714 0.         0.46153846 0.2        0.25\n",
      " 0.         0.         0.07317073 0.11764706 0.2        1.\n",
      " 0.26666667 0.25       0.         0.33333333 0.4        0.125\n",
      " 0.         0.         0.         0.1        1.         0.\n",
      " 0.         0.28571429 0.33333333 0.33333333 0.25       0.25\n",
      " 0.33333333 1.         0.         0.         0.         0.53846154\n",
      " 0.         0.8        0.5        0.33333333 0.25       0.\n",
      " 0.4        0.         0.25       0.         0.33333333 0.\n",
      " 0.71428571 0.66666667 0.28571429 0.16666667 0.18181818 0.\n",
      " 0.5        0.5        0.25       0.11111111 0.14285714 0.\n",
      " 0.6        0.         0.33333333 0.         0.         0.\n",
      " 0.66666667 0.         0.         0.         0.         0.33333333\n",
      " 0.07692308 0.         0.375      0.5        0.         0.\n",
      " 0.         0.         0.66666667 0.         1.         0.33333333\n",
      " 0.         0.5        1.         0.54545455 0.5        0.\n",
      " 0.         0.33333333 0.5        0.28571429 0.         0.11111111\n",
      " 1.         0.22222222 0.         0.         0.         0.33333333\n",
      " 0.         0.4       ]\n",
      "Recall:  [0.25       0.         0.5        0.         0.75       0.25\n",
      " 0.57142857 0.         0.33333333 0.         0.         0.\n",
      " 0.66666667 0.         0.66666667 0.         0.14285714 0.33333333\n",
      " 0.         0.         0.         0.25       0.5        0.44444444\n",
      " 0.         0.         0.55555556 1.         0.25       0.4\n",
      " 0.         0.25       0.         0.3        1.         0.75\n",
      " 0.35714286 0.         0.33333333 0.         0.5        0.2\n",
      " 0.         0.25       0.66666667 0.33333333 0.33333333 0.33333333\n",
      " 0.14285714 0.         0.         0.         0.5        0.\n",
      " 0.         0.33333333 1.         0.66666667 0.57142857 0.28571429\n",
      " 0.33333333 0.7        0.16666667 0.5        0.33333333 0.6\n",
      " 0.44444444 0.6        1.         0.         0.33333333 0.66666667\n",
      " 0.         0.5        0.25       0.2        0.         0.\n",
      " 0.         0.         0.33333333 0.8        0.4        0.33333333\n",
      " 0.33333333 0.66666667 0.2        0.         0.33333333 0.33333333\n",
      " 0.         0.         0.28571429 0.16666667 0.2        0.\n",
      " 0.4        0.5        0.         0.66666667 0.2        0.14285714\n",
      " 0.         0.         0.5        0.4        0.25       0.66666667\n",
      " 0.57142857 0.1        0.         0.2        0.28571429 0.16666667\n",
      " 0.         0.         0.         0.5        1.         0.\n",
      " 0.         0.28571429 0.22222222 0.33333333 0.4        0.5\n",
      " 0.2        0.5        0.         0.         0.         0.58333333\n",
      " 0.         0.66666667 0.5        0.66666667 0.8        0.\n",
      " 1.         0.         0.33333333 0.         0.25       0.\n",
      " 0.5        0.5        1.         0.25       0.66666667 0.\n",
      " 0.55555556 0.16666667 0.25       0.25       0.16666667 0.\n",
      " 0.5        0.         0.11111111 0.         0.         0.\n",
      " 0.28571429 0.         0.         0.         0.         0.66666667\n",
      " 0.5        0.         0.5        0.22222222 0.         0.\n",
      " 0.         0.         0.66666667 0.         0.14285714 0.42857143\n",
      " 0.         0.33333333 0.33333333 0.75       0.16666667 0.\n",
      " 0.         0.2        0.25       0.33333333 0.         0.125\n",
      " 0.28571429 0.4        0.         0.         0.         0.4\n",
      " 0.         0.66666667]\n",
      "Balanced Classification Rate:  [0.171875   0.         0.5        0.         0.625      0.375\n",
      " 0.46753247 0.         0.46666667 0.         0.         0.\n",
      " 0.45098039 0.         0.66666667 0.         0.19642857 0.29166667\n",
      " 0.         0.         0.         0.26785714 0.3125     0.4040404\n",
      " 0.         0.         0.55555556 0.75       0.16346154 0.7\n",
      " 0.         0.25       0.         0.4        0.55555556 0.475\n",
      " 0.30357143 0.         0.41666667 0.         0.58333333 0.2\n",
      " 0.         0.625      0.58333333 0.41666667 0.41666667 0.41666667\n",
      " 0.32142857 0.         0.         0.         0.625      0.\n",
      " 0.         0.33333333 1.         0.45098039 0.42857143 0.34285714\n",
      " 0.66666667 0.66818182 0.25       0.5        0.33333333 0.675\n",
      " 0.36507937 0.4875     0.75       0.         0.46666667 0.41666667\n",
      " 0.         0.33333333 0.1875     0.26666667 0.         0.\n",
      " 0.         0.         0.41666667 0.73333333 0.7        0.33333333\n",
      " 0.66666667 0.66666667 0.225      0.         0.36666667 0.26666667\n",
      " 0.         0.         0.34285714 0.58333333 0.1625     0.\n",
      " 0.53333333 0.32142857 0.         0.56410256 0.2        0.19642857\n",
      " 0.         0.         0.28658537 0.25882353 0.225      0.83333333\n",
      " 0.41904762 0.175      0.         0.26666667 0.34285714 0.14583333\n",
      " 0.         0.         0.         0.3        1.         0.\n",
      " 0.         0.28571429 0.27777778 0.33333333 0.325      0.375\n",
      " 0.26666667 0.75       0.         0.         0.         0.56089744\n",
      " 0.         0.73333333 0.5        0.5        0.525      0.\n",
      " 0.7        0.         0.29166667 0.         0.29166667 0.\n",
      " 0.60714286 0.58333333 0.64285714 0.20833333 0.42424242 0.\n",
      " 0.52777778 0.33333333 0.25       0.18055556 0.1547619  0.\n",
      " 0.55       0.         0.22222222 0.         0.         0.\n",
      " 0.47619048 0.         0.         0.         0.         0.5\n",
      " 0.28846154 0.         0.4375     0.36111111 0.         0.\n",
      " 0.         0.         0.66666667 0.         0.57142857 0.38095238\n",
      " 0.         0.41666667 0.66666667 0.64772727 0.33333333 0.\n",
      " 0.         0.26666667 0.375      0.30952381 0.         0.11805556\n",
      " 0.64285714 0.31111111 0.         0.         0.         0.36666667\n",
      " 0.         0.53333333]\n",
      "mini_batch 50\n",
      "mini_batch 51\n",
      "mini_batch 52\n",
      "mini_batch 53\n",
      "mini_batch 54\n",
      "mini_batch 55\n",
      "mini_batch 56\n",
      "mini_batch 57\n",
      "mini_batch 58\n",
      "mini_batch 59\n",
      "mini_batch 60\n",
      "mini_batch 61\n",
      "mini_batch 62\n",
      "mini_batch 63\n",
      "mini_batch 64\n",
      "mini_batch 65\n",
      "mini_batch 66\n",
      "mini_batch 67\n",
      "mini_batch 68\n",
      "mini_batch 69\n",
      "mini_batch 70\n",
      "mini_batch 71\n",
      "mini_batch 72\n",
      "mini_batch 73\n",
      "mini_batch 74\n",
      "mini_batch 75\n",
      "mini_batch 76\n",
      "mini_batch 77\n",
      "mini_batch 78\n",
      "mini_batch 79\n",
      "mini_batch 80\n",
      "mini_batch 81\n",
      "mini_batch 82\n",
      "mini_batch 83\n",
      "mini_batch 84\n",
      "mini_batch 85\n",
      "mini_batch 86\n",
      "mini_batch 87\n",
      "mini_batch 88\n",
      "mini_batch 89\n",
      "mini_batch 90\n",
      "mini_batch 91\n",
      "mini_batch 92\n",
      "mini_batch 93\n",
      "mini_batch 94\n",
      "mini_batch 95\n",
      "mini_batch 96\n",
      "mini_batch 97\n",
      "mini_batch 98\n",
      "mini_batch 99\n",
      "Epoch 3\n",
      "average minibatch 100 loss: 1.867\n",
      "\n",
      "Labels:  tensor([163,  45, 122, 133,  20, 102, 127, 151, 115, 163, 101,  67,  68,  38,\n",
      "        113, 179,  46,  56,  64, 182,  13,  58,  19, 130,  53,  78, 129, 105,\n",
      "         20,  37,  58, 105, 179, 163, 163, 191, 122, 105,  24, 155, 181,  72,\n",
      "         15, 153, 113,  35, 197,  66, 187, 132, 163,  33, 181,  38, 124,  86,\n",
      "         72, 153,  46, 114,  21, 157,  71,  68], device='cuda:0')\n",
      "Output:  tensor([181,  45, 122, 133,  35, 117, 128, 151, 115, 173, 165,  67,  68, 141,\n",
      "        169, 179,  46,  56,  64, 182,  13,  58, 110, 130, 120,  78, 112, 105,\n",
      "        152,   9, 175, 105,  86,  64, 163,  18,  21, 105,  24,  94,  71,  72,\n",
      "        173, 153,   9,  35, 193,  66, 187,  67, 163,  33, 181, 143, 124, 193,\n",
      "         72, 153,  46, 114, 188, 157,  71,  68], device='cuda:0')\n",
      "True Positives:  [3. 0. 2. 0. 3. 1. 4. 0. 3. 0. 0. 0. 5. 0. 4. 0. 1. 1. 0. 0. 0. 2. 1. 5.\n",
      " 0. 0. 5. 2. 1. 2. 0. 1. 1. 3. 2. 3. 5. 0. 1. 0. 2. 1. 0. 1. 3. 4. 1. 2.\n",
      " 1. 0. 0. 0. 3. 0. 0. 2. 2. 5. 4. 2. 2. 7. 1. 5. 2. 4. 5. 5. 4. 0. 4. 4.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 2. 4. 2. 1. 2. 2. 1. 0. 2. 1. 0. 0. 2. 1. 1. 0.\n",
      " 2. 1. 0. 6. 1. 1. 0. 0. 6. 2. 1. 2. 4. 1. 0. 1. 2. 2. 1. 0. 0. 1. 3. 0.\n",
      " 0. 3. 2. 2. 2. 3. 2. 3. 0. 1. 0. 7. 1. 4. 1. 2. 4. 0. 2. 0. 1. 0. 1. 0.\n",
      " 5. 4. 2. 1. 2. 0. 6. 1. 4. 1. 1. 0. 4. 0. 1. 0. 0. 0. 4. 0. 0. 0. 0. 2.\n",
      " 1. 0. 3. 2. 0. 0. 0. 0. 4. 0. 3. 3. 1. 2. 1. 6. 1. 0. 1. 1. 1. 2. 0. 1.\n",
      " 2. 2. 0. 0. 0. 2. 0. 2.]\n",
      "False Positives:  [29.  1.  2.  4.  3.  1.  7.  2.  4.  2.  1.  0. 13.  1.  2.  6.  3.  4.\n",
      "  0.  0. 12.  5.  7.  7.  1.  0.  4.  2. 12.  0.  0.  3.  7.  3.  9. 12.\n",
      " 15.  6.  1.  1.  1.  4.  2.  0.  2.  2.  1.  2.  1.  0.  0.  0.  1.  1.\n",
      "  1.  2.  0. 13. 10.  3.  0.  4.  2.  5.  4.  1. 11.  5.  4.  2.  3. 10.\n",
      "  0.  5.  7.  2.  0.  2.  0.  0.  2.  2.  0.  2.  0.  2.  3.  0.  3.  4.\n",
      "  0.  1.  3.  1.  7.  0.  1.  6.  2.  7.  4.  3.  3.  2. 38. 15.  4.  0.\n",
      " 11.  4.  2.  3.  3.  7.  3.  1.  1.  9.  0.  1.  2.  5.  4.  2.  6.  9.\n",
      "  4.  1.  0.  1.  1.  6.  0.  1.  1.  4. 12.  0.  3.  4.  4.  2.  3.  1.\n",
      "  2.  2.  5.  5.  9.  0.  5.  2.  6.  8.  6.  2.  2.  1.  2.  1.  1.  0.\n",
      "  1.  3.  1.  0.  0.  4. 13.  1.  5.  2.  9.  0.  4.  0.  2.  2.  0.  6.\n",
      "  1.  1.  0.  5.  1.  4.  1.  3.  1.  5.  3.  8.  2.  7.  0.  3.  0.  4.\n",
      "  0.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  3.  1.  3.  3.  3.  6.  2.  3.  3.  2.  3.  3.  5.  6.  2.\n",
      "  3.  9.  6.  6.  1.  5.  1.  0.  4.  0.  3.  3.  7.  3.  5.  7.  0.  1.\n",
      " 10.  7.  2.  4.  2.  4.  2.  3.  1.  4.  2.  4.  6.  4.  3.  5.  4.  5.\n",
      "  0.  2.  0.  3.  3.  5.  4.  3.  5.  4.  4.  2.  5.  2.  0.  6.  6.  1.\n",
      "  1.  1.  3.  4.  2.  2.  4.  0.  4.  1.  3.  2.  4.  2.  4.  2.  4.  2.\n",
      "  2.  4.  5.  5.  4.  2.  3.  1.  7.  3.  5.  7.  3.  5.  3.  3.  3.  1.\n",
      "  3.  9.  6.  4.  7.  5.  4.  5.  3.  1.  0.  2.  3.  6.  7.  2.  3.  3.\n",
      "  9.  3.  4.  1.  6.  6.  1.  2.  1.  1.  1.  0.  0.  4.  2.  7.  3.  3.\n",
      "  5.  4.  0.  3.  1.  2.  4.  5.  6.  3.  6.  1.  3.  4.  8.  4.  5.  3.\n",
      "  8.  6.  1.  4.  2.  1.  1.  6.  3.  7.  7.  4.  4.  4.  2.  2. 13.  4.\n",
      "  3.  2.  2.  2.  5.  9.  4.  4.  3.  4.  6.  7.  5.  3.  3.  1.  3.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.046875 0.       0.03125  0.       0.046875 0.015625 0.0625   0.\n",
      " 0.046875 0.       0.       0.       0.078125 0.       0.0625   0.\n",
      " 0.015625 0.015625 0.       0.       0.       0.03125  0.015625 0.078125\n",
      " 0.       0.       0.078125 0.03125  0.015625 0.03125  0.       0.015625\n",
      " 0.015625 0.046875 0.03125  0.046875 0.078125 0.       0.015625 0.\n",
      " 0.03125  0.015625 0.       0.015625 0.046875 0.0625   0.015625 0.03125\n",
      " 0.015625 0.       0.       0.       0.046875 0.       0.       0.03125\n",
      " 0.03125  0.078125 0.0625   0.03125  0.03125  0.109375 0.015625 0.078125\n",
      " 0.03125  0.0625   0.078125 0.078125 0.0625   0.       0.0625   0.0625\n",
      " 0.       0.015625 0.015625 0.015625 0.       0.015625 0.       0.\n",
      " 0.03125  0.0625   0.03125  0.015625 0.03125  0.03125  0.015625 0.\n",
      " 0.03125  0.015625 0.       0.       0.03125  0.015625 0.015625 0.\n",
      " 0.03125  0.015625 0.       0.09375  0.015625 0.015625 0.       0.\n",
      " 0.09375  0.03125  0.015625 0.03125  0.0625   0.015625 0.       0.015625\n",
      " 0.03125  0.03125  0.015625 0.       0.       0.015625 0.046875 0.\n",
      " 0.       0.046875 0.03125  0.03125  0.03125  0.046875 0.03125  0.046875\n",
      " 0.       0.015625 0.       0.109375 0.015625 0.0625   0.015625 0.03125\n",
      " 0.0625   0.       0.03125  0.       0.015625 0.       0.015625 0.\n",
      " 0.078125 0.0625   0.03125  0.015625 0.03125  0.       0.09375  0.015625\n",
      " 0.0625   0.015625 0.015625 0.       0.0625   0.       0.015625 0.\n",
      " 0.       0.       0.0625   0.       0.       0.       0.       0.03125\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.       0.\n",
      " 0.0625   0.       0.046875 0.046875 0.015625 0.03125  0.015625 0.09375\n",
      " 0.015625 0.       0.015625 0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.03125  0.03125  0.       0.       0.       0.03125  0.       0.03125 ]\n",
      "Precision:  [0.09375    0.         0.5        0.         0.5        0.5\n",
      " 0.36363636 0.         0.42857143 0.         0.         0.\n",
      " 0.27777778 0.         0.66666667 0.         0.25       0.2\n",
      " 0.         0.         0.         0.28571429 0.125      0.41666667\n",
      " 0.         0.         0.55555556 0.5        0.07692308 1.\n",
      " 0.         0.25       0.125      0.5        0.18181818 0.2\n",
      " 0.25       0.         0.5        0.         0.66666667 0.2\n",
      " 0.         1.         0.6        0.66666667 0.5        0.5\n",
      " 0.5        0.         0.         0.         0.75       0.\n",
      " 0.         0.5        1.         0.27777778 0.28571429 0.4\n",
      " 1.         0.63636364 0.33333333 0.5        0.33333333 0.8\n",
      " 0.3125     0.5        0.5        0.         0.57142857 0.28571429\n",
      " 0.         0.16666667 0.125      0.33333333 0.         0.33333333\n",
      " 0.         0.         0.5        0.66666667 1.         0.33333333\n",
      " 1.         0.5        0.25       0.         0.4        0.2\n",
      " 0.         0.         0.4        0.5        0.125      0.\n",
      " 0.66666667 0.14285714 0.         0.46153846 0.2        0.25\n",
      " 0.         0.         0.13636364 0.11764706 0.2        1.\n",
      " 0.26666667 0.2        0.         0.25       0.4        0.22222222\n",
      " 0.25       0.         0.         0.1        1.         0.\n",
      " 0.         0.375      0.33333333 0.5        0.25       0.25\n",
      " 0.33333333 0.75       0.         0.5        0.         0.53846154\n",
      " 1.         0.8        0.5        0.33333333 0.25       0.\n",
      " 0.4        0.         0.2        0.         0.25       0.\n",
      " 0.71428571 0.66666667 0.28571429 0.16666667 0.18181818 0.\n",
      " 0.54545455 0.33333333 0.4        0.11111111 0.14285714 0.\n",
      " 0.66666667 0.         0.33333333 0.         0.         0.\n",
      " 0.8        0.         0.         0.         0.         0.33333333\n",
      " 0.07142857 0.         0.375      0.5        0.         0.\n",
      " 0.         0.         0.66666667 0.         1.         0.33333333\n",
      " 0.5        0.66666667 1.         0.54545455 0.5        0.\n",
      " 0.5        0.25       0.5        0.28571429 0.         0.11111111\n",
      " 0.5        0.22222222 0.         0.         0.         0.33333333\n",
      " 0.         0.4       ]\n",
      "Recall:  [0.25       0.         0.5        0.         0.75       0.25\n",
      " 0.57142857 0.         0.33333333 0.         0.         0.\n",
      " 0.71428571 0.         0.57142857 0.         0.14285714 0.33333333\n",
      " 0.         0.         0.         0.25       0.5        0.5\n",
      " 0.         0.         0.55555556 1.         0.25       0.4\n",
      " 0.         0.25       0.16666667 0.3        1.         0.75\n",
      " 0.33333333 0.         0.33333333 0.         0.5        0.2\n",
      " 0.         0.25       0.75       0.5        0.33333333 0.33333333\n",
      " 0.14285714 0.         0.         0.         0.42857143 0.\n",
      " 0.         0.5        1.         0.625      0.57142857 0.28571429\n",
      " 0.33333333 0.7        0.16666667 0.55555556 0.33333333 0.66666667\n",
      " 0.5        0.71428571 1.         0.         0.4        0.8\n",
      " 0.         0.5        0.25       0.2        0.         0.33333333\n",
      " 0.         0.         0.33333333 0.8        0.4        0.33333333\n",
      " 0.33333333 0.5        0.2        0.         0.33333333 0.33333333\n",
      " 0.         0.         0.28571429 0.16666667 0.2        0.\n",
      " 0.4        0.5        0.         0.66666667 0.16666667 0.125\n",
      " 0.         0.         0.66666667 0.4        0.25       0.66666667\n",
      " 0.57142857 0.1        0.         0.2        0.22222222 0.28571429\n",
      " 0.2        0.         0.         0.5        1.         0.\n",
      " 0.         0.33333333 0.22222222 0.5        0.4        0.5\n",
      " 0.18181818 0.5        0.         0.5        0.         0.53846154\n",
      " 0.5        0.66666667 0.5        0.66666667 0.8        0.\n",
      " 1.         0.         0.33333333 0.         0.25       0.\n",
      " 0.5        0.5        1.         0.25       0.66666667 0.\n",
      " 0.6        0.16666667 0.4        0.25       0.14285714 0.\n",
      " 0.57142857 0.         0.11111111 0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.66666667\n",
      " 0.5        0.         0.5        0.22222222 0.         0.\n",
      " 0.         0.         0.66666667 0.         0.1875     0.42857143\n",
      " 0.25       0.5        0.33333333 0.75       0.16666667 0.\n",
      " 0.2        0.2        0.25       0.33333333 0.         0.125\n",
      " 0.28571429 0.4        0.         0.         0.         0.4\n",
      " 0.         0.66666667]\n",
      "Balanced Classification Rate:  [0.171875   0.         0.5        0.         0.625      0.375\n",
      " 0.46753247 0.         0.38095238 0.         0.         0.\n",
      " 0.49603175 0.         0.61904762 0.         0.19642857 0.26666667\n",
      " 0.         0.         0.         0.26785714 0.3125     0.45833333\n",
      " 0.         0.         0.55555556 0.75       0.16346154 0.7\n",
      " 0.         0.25       0.14583333 0.4        0.59090909 0.475\n",
      " 0.29166667 0.         0.41666667 0.         0.58333333 0.2\n",
      " 0.         0.625      0.675      0.58333333 0.41666667 0.41666667\n",
      " 0.32142857 0.         0.         0.         0.58928571 0.\n",
      " 0.         0.5        1.         0.45138889 0.42857143 0.34285714\n",
      " 0.66666667 0.66818182 0.25       0.52777778 0.33333333 0.73333333\n",
      " 0.40625    0.60714286 0.75       0.         0.48571429 0.54285714\n",
      " 0.         0.33333333 0.1875     0.26666667 0.         0.33333333\n",
      " 0.         0.         0.41666667 0.73333333 0.7        0.33333333\n",
      " 0.66666667 0.5        0.225      0.         0.36666667 0.26666667\n",
      " 0.         0.         0.34285714 0.33333333 0.1625     0.\n",
      " 0.53333333 0.32142857 0.         0.56410256 0.18333333 0.1875\n",
      " 0.         0.         0.40151515 0.25882353 0.225      0.83333333\n",
      " 0.41904762 0.15       0.         0.225      0.31111111 0.25396825\n",
      " 0.225      0.         0.         0.3        1.         0.\n",
      " 0.         0.35416667 0.27777778 0.5        0.325      0.375\n",
      " 0.25757576 0.625      0.         0.5        0.         0.53846154\n",
      " 0.75       0.73333333 0.5        0.5        0.525      0.\n",
      " 0.7        0.         0.26666667 0.         0.25       0.\n",
      " 0.60714286 0.58333333 0.64285714 0.20833333 0.42424242 0.\n",
      " 0.57272727 0.25       0.4        0.18055556 0.14285714 0.\n",
      " 0.61904762 0.         0.22222222 0.         0.         0.\n",
      " 0.56666667 0.         0.         0.         0.         0.5\n",
      " 0.28571429 0.         0.4375     0.36111111 0.         0.\n",
      " 0.         0.         0.66666667 0.         0.59375    0.38095238\n",
      " 0.375      0.58333333 0.66666667 0.64772727 0.33333333 0.\n",
      " 0.35       0.225      0.375      0.30952381 0.         0.11805556\n",
      " 0.39285714 0.31111111 0.         0.         0.         0.36666667\n",
      " 0.         0.53333333]\n",
      "mini_batch 100\n",
      "mini_batch 101\n",
      "mini_batch 102\n",
      "mini_batch 103\n",
      "mini_batch 104\n",
      "mini_batch 105\n",
      "mini_batch 106\n",
      "mini_batch 107\n",
      "mini_batch 108\n",
      "mini_batch 109\n",
      "mini_batch 110\n",
      "mini_batch 111\n",
      "mini_batch 112\n",
      "mini_batch 113\n",
      "mini_batch 114\n",
      "mini_batch 115\n",
      "mini_batch 116\n",
      "mini_batch 117\n",
      "mini_batch 118\n",
      "mini_batch 119\n",
      "mini_batch 120\n",
      "mini_batch 121\n",
      "mini_batch 122\n",
      "mini_batch 123\n",
      "mini_batch 124\n",
      "mini_batch 125\n",
      "mini_batch 126\n",
      "mini_batch 127\n",
      "mini_batch 128\n",
      "mini_batch 129\n",
      "mini_batch 130\n",
      "mini_batch 131\n",
      "mini_batch 132\n",
      "mini_batch 133\n",
      "mini_batch 134\n",
      "mini_batch 135\n",
      "mini_batch 136\n",
      "mini_batch 137\n",
      "mini_batch 138\n",
      "mini_batch 139\n",
      "mini_batch 140\n",
      "mini_batch 141\n",
      "mini_batch 142\n",
      "mini_batch 143\n",
      "mini_batch 144\n",
      "mini_batch 145\n",
      "mini_batch 146\n",
      "mini_batch 147\n",
      "mini_batch 148\n",
      "mini_batch 149\n",
      "Epoch 3\n",
      "average minibatch 150 loss: 1.895\n",
      "\n",
      "Labels:  tensor([ 82,  24, 195,  15,  75, 128, 186,  11, 116,   6, 172,  23, 184, 106,\n",
      "        140,  66,  98,  54, 151,  80,  31, 109, 173, 114,  38, 175,  41, 165,\n",
      "        131,  54, 179,  71,  88,  37, 151,  37, 110, 164, 128,  48, 161,  44,\n",
      "         10,  90, 109,  23,  92, 194,  45, 143, 100,  65,  74,  59, 167, 186,\n",
      "         33, 175, 158,  36,  86, 121, 191,  13], device='cuda:0')\n",
      "Output:  tensor([ 34,  22,  29,  99,  46, 128, 186,  44,  51,   6, 177,  37,  20,   6,\n",
      "        140,  66,  98,  54, 151,  80,  33, 124, 181,  69,  10, 175,  81, 165,\n",
      "        198,   3,   8, 116, 124,  37, 151, 163, 163, 190, 128, 154,  89,  44,\n",
      "        124,  90, 109,  88,  92,   5,  45, 143, 124,  65,  58,  59, 167, 172,\n",
      "         33, 175, 186,  36,  33, 121, 116,  13], device='cuda:0')\n",
      "True Positives:  [3. 0. 2. 0. 3. 2. 4. 0. 3. 0. 0. 0. 6. 0. 4. 0. 1. 1. 0. 0. 0. 2. 1. 5.\n",
      " 0. 0. 5. 2. 1. 2. 0. 1. 2. 3. 2. 4. 6. 0. 1. 0. 2. 1. 0. 2. 4. 4. 1. 2.\n",
      " 1. 0. 0. 0. 3. 1. 0. 2. 2. 5. 5. 2. 2. 7. 1. 5. 3. 5. 5. 5. 4. 0. 4. 4.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 2. 4. 2. 1. 2. 2. 1. 0. 2. 2. 0. 1. 2. 1. 1. 0.\n",
      " 2. 2. 0. 6. 1. 1. 0. 0. 6. 2. 1. 2. 5. 1. 0. 1. 2. 2. 1. 0. 0. 1. 3. 0.\n",
      " 1. 3. 2. 2. 2. 3. 2. 5. 0. 1. 0. 7. 1. 4. 1. 2. 4. 0. 2. 1. 1. 0. 2. 0.\n",
      " 5. 4. 2. 1. 2. 0. 8. 1. 4. 1. 1. 0. 4. 0. 1. 0. 0. 0. 4. 0. 1. 0. 1. 2.\n",
      " 1. 0. 3. 2. 0. 0. 2. 0. 4. 0. 3. 3. 1. 2. 1. 6. 1. 1. 1. 1. 1. 2. 0. 1.\n",
      " 2. 2. 0. 0. 0. 2. 0. 2.]\n",
      "False Positives:  [29.  1.  3.  4.  4.  2.  7.  3.  4.  3.  1.  0. 13.  1.  2.  6.  3.  4.\n",
      "  0.  1. 12.  6.  7.  7.  1.  0.  4.  2. 13.  0.  0.  3.  9.  4.  9. 12.\n",
      " 16.  6.  1.  1.  1.  4.  2.  1.  2.  3.  1.  2.  1.  0.  1.  0.  1.  1.\n",
      "  1.  2.  0. 14. 10.  3.  0.  4.  2.  5.  4.  1. 11.  5.  5.  2.  3. 10.\n",
      "  0.  5.  7.  2.  0.  2.  0.  0.  3.  2.  0.  2.  0.  2.  3.  1.  4.  4.\n",
      "  0.  1.  3.  1.  7.  0.  1.  6.  3.  7.  4.  3.  3.  2. 38. 15.  4.  0.\n",
      " 11.  4.  2.  3.  3.  7.  3.  3.  1.  9.  0.  1.  2.  5.  4.  6.  6.  9.\n",
      "  4.  1.  0.  1.  1.  6.  0.  1.  1.  4. 12.  0.  3.  4.  4.  2.  3.  1.\n",
      "  2.  2.  5.  5.  9.  0.  5.  2.  6.  9.  6.  2.  2.  1.  2.  1.  1.  0.\n",
      "  3.  3.  1.  0.  0.  4. 13.  1.  5.  3.  9.  0.  4.  0.  3.  2.  0.  6.\n",
      "  2.  1.  0.  5.  1.  5.  1.  3.  1.  6.  3.  8.  2.  7.  0.  3.  0.  5.\n",
      "  0.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  3.  1.  3.  3.  3.  6.  3.  4.  3.  2.  3.  4.  5.  6.  2.\n",
      "  3.  9.  6.  6.  3.  6.  1.  0.  4.  0.  3.  3.  8.  3.  5.  7.  0.  1.\n",
      " 11.  8.  2.  4.  3.  4.  2.  3.  1.  4.  2.  5.  6.  4.  3.  5.  4.  6.\n",
      "  0.  2.  0.  3.  3.  5.  4.  3.  5.  4.  4.  2.  5.  2.  0.  6.  7.  1.\n",
      "  1.  2.  4.  4.  2.  2.  4.  0.  4.  2.  3.  2.  4.  3.  4.  3.  4.  2.\n",
      "  2.  4.  5.  5.  4.  2.  3.  1.  7.  4.  5.  7.  3.  5.  3.  4.  3.  1.\n",
      "  4. 10.  6.  4.  7.  6.  4.  6.  3.  1.  0.  2.  3.  6.  7.  2.  3.  3.\n",
      "  9.  3.  4.  1.  7.  6.  1.  2.  1.  1.  1.  0.  0.  4.  2.  7.  3.  3.\n",
      "  5.  4.  0.  3.  1.  2.  4.  5.  6.  3.  6.  1.  3.  5.  8.  4.  6.  3.\n",
      "  8.  7.  1.  4.  2.  1.  1.  6.  3.  8.  8.  4.  4.  4.  2.  2. 14.  4.\n",
      "  3.  2.  2.  3.  5. 10.  4.  4.  3.  4.  7.  7.  5.  4.  4.  1.  3.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.046875 0.       0.03125  0.       0.046875 0.03125  0.0625   0.\n",
      " 0.046875 0.       0.       0.       0.09375  0.       0.0625   0.\n",
      " 0.015625 0.015625 0.       0.       0.       0.03125  0.015625 0.078125\n",
      " 0.       0.       0.078125 0.03125  0.015625 0.03125  0.       0.015625\n",
      " 0.03125  0.046875 0.03125  0.0625   0.09375  0.       0.015625 0.\n",
      " 0.03125  0.015625 0.       0.03125  0.0625   0.0625   0.015625 0.03125\n",
      " 0.015625 0.       0.       0.       0.046875 0.015625 0.       0.03125\n",
      " 0.03125  0.078125 0.078125 0.03125  0.03125  0.109375 0.015625 0.078125\n",
      " 0.046875 0.078125 0.078125 0.078125 0.0625   0.       0.0625   0.0625\n",
      " 0.       0.015625 0.015625 0.015625 0.       0.015625 0.       0.015625\n",
      " 0.03125  0.0625   0.03125  0.015625 0.03125  0.03125  0.015625 0.\n",
      " 0.03125  0.03125  0.       0.015625 0.03125  0.015625 0.015625 0.\n",
      " 0.03125  0.03125  0.       0.09375  0.015625 0.015625 0.       0.\n",
      " 0.09375  0.03125  0.015625 0.03125  0.078125 0.015625 0.       0.015625\n",
      " 0.03125  0.03125  0.015625 0.       0.       0.015625 0.046875 0.\n",
      " 0.015625 0.046875 0.03125  0.03125  0.03125  0.046875 0.03125  0.078125\n",
      " 0.       0.015625 0.       0.109375 0.015625 0.0625   0.015625 0.03125\n",
      " 0.0625   0.       0.03125  0.015625 0.015625 0.       0.03125  0.\n",
      " 0.078125 0.0625   0.03125  0.015625 0.03125  0.       0.125    0.015625\n",
      " 0.0625   0.015625 0.015625 0.       0.0625   0.       0.015625 0.\n",
      " 0.       0.       0.0625   0.       0.015625 0.       0.015625 0.03125\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.03125  0.\n",
      " 0.0625   0.       0.046875 0.046875 0.015625 0.03125  0.015625 0.09375\n",
      " 0.015625 0.015625 0.015625 0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.03125  0.03125  0.       0.       0.       0.03125  0.       0.03125 ]\n",
      "Precision:  [0.09375    0.         0.4        0.         0.42857143 0.5\n",
      " 0.36363636 0.         0.42857143 0.         0.         0.\n",
      " 0.31578947 0.         0.66666667 0.         0.25       0.2\n",
      " 0.         0.         0.         0.25       0.125      0.41666667\n",
      " 0.         0.         0.55555556 0.5        0.07142857 1.\n",
      " 0.         0.25       0.18181818 0.42857143 0.18181818 0.25\n",
      " 0.27272727 0.         0.5        0.         0.66666667 0.2\n",
      " 0.         0.66666667 0.66666667 0.57142857 0.5        0.5\n",
      " 0.5        0.         0.         0.         0.75       0.5\n",
      " 0.         0.5        1.         0.26315789 0.33333333 0.4\n",
      " 1.         0.63636364 0.33333333 0.5        0.42857143 0.83333333\n",
      " 0.3125     0.5        0.44444444 0.         0.57142857 0.28571429\n",
      " 0.         0.16666667 0.125      0.33333333 0.         0.33333333\n",
      " 0.         1.         0.4        0.66666667 1.         0.33333333\n",
      " 1.         0.5        0.25       0.         0.33333333 0.33333333\n",
      " 0.         0.5        0.4        0.5        0.125      0.\n",
      " 0.66666667 0.25       0.         0.46153846 0.2        0.25\n",
      " 0.         0.         0.13636364 0.11764706 0.2        1.\n",
      " 0.3125     0.2        0.         0.25       0.4        0.22222222\n",
      " 0.25       0.         0.         0.1        1.         0.\n",
      " 0.33333333 0.375      0.33333333 0.25       0.25       0.25\n",
      " 0.33333333 0.83333333 0.         0.5        0.         0.53846154\n",
      " 1.         0.8        0.5        0.33333333 0.25       0.\n",
      " 0.4        0.2        0.2        0.         0.4        0.\n",
      " 0.71428571 0.66666667 0.28571429 0.16666667 0.18181818 0.\n",
      " 0.61538462 0.33333333 0.4        0.1        0.14285714 0.\n",
      " 0.66666667 0.         0.33333333 0.         0.         0.\n",
      " 0.57142857 0.         0.5        0.         1.         0.33333333\n",
      " 0.07142857 0.         0.375      0.4        0.         0.\n",
      " 0.33333333 0.         0.57142857 0.         1.         0.33333333\n",
      " 0.33333333 0.66666667 1.         0.54545455 0.5        0.16666667\n",
      " 0.5        0.25       0.5        0.25       0.         0.11111111\n",
      " 0.5        0.22222222 0.         0.         0.         0.28571429\n",
      " 0.         0.4       ]\n",
      "Recall:  [0.25       0.         0.5        0.         0.75       0.4\n",
      " 0.57142857 0.         0.33333333 0.         0.         0.\n",
      " 0.75       0.         0.5        0.         0.14285714 0.33333333\n",
      " 0.         0.         0.         0.25       0.25       0.45454545\n",
      " 0.         0.         0.55555556 1.         0.25       0.4\n",
      " 0.         0.25       0.28571429 0.3        1.         0.8\n",
      " 0.35294118 0.         0.33333333 0.         0.4        0.2\n",
      " 0.         0.4        0.8        0.5        0.33333333 0.28571429\n",
      " 0.14285714 0.         0.         0.         0.42857143 0.14285714\n",
      " 0.         0.5        1.         0.625      0.625      0.28571429\n",
      " 0.33333333 0.7        0.16666667 0.55555556 0.42857143 0.71428571\n",
      " 0.5        0.71428571 1.         0.         0.36363636 0.8\n",
      " 0.         0.33333333 0.2        0.2        0.         0.33333333\n",
      " 0.         1.         0.33333333 0.66666667 0.4        0.33333333\n",
      " 0.33333333 0.4        0.2        0.         0.33333333 0.5\n",
      " 0.         0.2        0.28571429 0.16666667 0.2        0.\n",
      " 0.4        0.66666667 0.         0.6        0.16666667 0.125\n",
      " 0.         0.         0.66666667 0.33333333 0.25       0.66666667\n",
      " 0.55555556 0.09090909 0.         0.2        0.22222222 0.25\n",
      " 0.2        0.         0.         0.5        1.         0.\n",
      " 0.25       0.33333333 0.22222222 0.5        0.4        0.5\n",
      " 0.18181818 0.625      0.         0.5        0.         0.53846154\n",
      " 0.5        0.66666667 0.5        0.66666667 0.8        0.\n",
      " 1.         0.2        0.33333333 0.         0.4        0.\n",
      " 0.5        0.5        1.         0.25       0.66666667 0.\n",
      " 0.66666667 0.16666667 0.4        0.25       0.14285714 0.\n",
      " 0.57142857 0.         0.11111111 0.         0.         0.\n",
      " 0.33333333 0.         0.5        0.         0.33333333 0.66666667\n",
      " 0.5        0.         0.5        0.2        0.         0.\n",
      " 0.33333333 0.         0.66666667 0.         0.17647059 0.42857143\n",
      " 0.25       0.5        0.33333333 0.66666667 0.16666667 0.09090909\n",
      " 0.2        0.2        0.25       0.33333333 0.         0.125\n",
      " 0.28571429 0.33333333 0.         0.         0.         0.4\n",
      " 0.         0.66666667]\n",
      "Balanced Classification Rate:  [0.171875   0.         0.45       0.         0.58928571 0.45\n",
      " 0.46753247 0.         0.38095238 0.         0.         0.\n",
      " 0.53289474 0.         0.58333333 0.         0.19642857 0.26666667\n",
      " 0.         0.         0.         0.25       0.1875     0.43560606\n",
      " 0.         0.         0.55555556 0.75       0.16071429 0.7\n",
      " 0.         0.25       0.23376623 0.36428571 0.59090909 0.525\n",
      " 0.31283422 0.         0.41666667 0.         0.53333333 0.2\n",
      " 0.         0.53333333 0.73333333 0.53571429 0.41666667 0.39285714\n",
      " 0.32142857 0.         0.         0.         0.58928571 0.32142857\n",
      " 0.         0.5        1.         0.44407895 0.47916667 0.34285714\n",
      " 0.66666667 0.66818182 0.25       0.52777778 0.42857143 0.77380952\n",
      " 0.40625    0.60714286 0.72222222 0.         0.46753247 0.54285714\n",
      " 0.         0.25       0.1625     0.26666667 0.         0.33333333\n",
      " 0.         1.         0.36666667 0.66666667 0.7        0.33333333\n",
      " 0.66666667 0.45       0.225      0.         0.33333333 0.41666667\n",
      " 0.         0.35       0.34285714 0.33333333 0.1625     0.\n",
      " 0.53333333 0.45833333 0.         0.53076923 0.18333333 0.1875\n",
      " 0.         0.         0.40151515 0.2254902  0.225      0.83333333\n",
      " 0.43402778 0.14545455 0.         0.225      0.31111111 0.23611111\n",
      " 0.225      0.         0.         0.3        1.         0.\n",
      " 0.29166667 0.35416667 0.27777778 0.375      0.325      0.375\n",
      " 0.25757576 0.72916667 0.         0.5        0.         0.53846154\n",
      " 0.75       0.73333333 0.5        0.5        0.525      0.\n",
      " 0.7        0.2        0.26666667 0.         0.4        0.\n",
      " 0.60714286 0.58333333 0.64285714 0.20833333 0.42424242 0.\n",
      " 0.64102564 0.25       0.4        0.175      0.14285714 0.\n",
      " 0.61904762 0.         0.22222222 0.         0.         0.\n",
      " 0.45238095 0.         0.5        0.         0.66666667 0.5\n",
      " 0.28571429 0.         0.4375     0.3        0.         0.\n",
      " 0.33333333 0.         0.61904762 0.         0.58823529 0.38095238\n",
      " 0.29166667 0.58333333 0.66666667 0.60606061 0.33333333 0.12878788\n",
      " 0.35       0.225      0.375      0.29166667 0.         0.11805556\n",
      " 0.39285714 0.27777778 0.         0.         0.         0.34285714\n",
      " 0.         0.53333333]\n",
      "mini_batch 150\n",
      "mini_batch 151\n",
      "mini_batch 152\n",
      "mini_batch 153\n",
      "mini_batch 154\n",
      "mini_batch 155\n",
      "mini_batch 156\n",
      "mini_batch 157\n",
      "mini_batch 158\n",
      "mini_batch 159\n",
      "mini_batch 160\n",
      "mini_batch 161\n",
      "mini_batch 162\n",
      "mini_batch 163\n",
      "mini_batch 164\n",
      "mini_batch 165\n",
      "mini_batch 166\n",
      "mini_batch 167\n",
      "mini_batch 168\n",
      "mini_batch 169\n",
      "mini_batch 170\n",
      "mini_batch 171\n",
      "mini_batch 172\n",
      "mini_batch 173\n",
      "mini_batch 174\n",
      "mini_batch 175\n",
      "mini_batch 176\n",
      "mini_batch 177\n",
      "mini_batch 178\n",
      "mini_batch 179\n",
      "mini_batch 180\n",
      "mini_batch 181\n",
      "mini_batch 182\n",
      "mini_batch 183\n",
      "mini_batch 184\n",
      "mini_batch 185\n",
      "mini_batch 186\n",
      "mini_batch 187\n",
      "mini_batch 188\n",
      "mini_batch 189\n",
      "mini_batch 190\n",
      "mini_batch 191\n",
      "mini_batch 192\n",
      "mini_batch 193\n",
      "mini_batch 194\n",
      "mini_batch 195\n",
      "mini_batch 196\n",
      "mini_batch 197\n",
      "mini_batch 198\n",
      "mini_batch 199\n",
      "Epoch 3\n",
      "average minibatch 200 loss: 1.821\n",
      "\n",
      "Labels:  tensor([ 37,  45,  35,  51, 141,  71,  66,  66,  21,  93,  24, 104,  60,  45,\n",
      "         78, 200, 160,  22, 128, 177,  78, 184,  27,  44, 200, 187,  89, 199,\n",
      "         50, 152, 191, 130, 126,  61, 184, 125, 151,  37, 102, 107,  21, 102,\n",
      "         48, 185,  81,  37,  23, 127, 129, 197, 132, 153,  43,  82, 119,  87,\n",
      "         63, 168, 186,  77,  46, 112, 109, 133], device='cuda:0')\n",
      "Output:  tensor([ 37,  45,  35,  93, 141, 149,  72, 199,  21,  23,  24, 104,  60,  45,\n",
      "         78, 200,  15, 159, 128, 177,  30, 184,  27,  44, 200, 187,  89, 199,\n",
      "        174, 152, 191, 130, 126,  17, 184, 125, 151, 122, 102, 107, 133,  92,\n",
      "          7, 185,  81,  37,  23, 128, 111,  97, 132, 153,  43,  82, 119,  87,\n",
      "        161, 168, 186,  77,  46, 112, 109, 133], device='cuda:0')\n",
      "True Positives:  [3. 0. 2. 0. 3. 2. 4. 0. 3. 0. 0. 0. 6. 0. 4. 0. 1. 1. 0. 0. 1. 2. 2. 6.\n",
      " 0. 0. 6. 2. 1. 2. 0. 1. 2. 3. 3. 4. 8. 0. 1. 0. 2. 1. 1. 3. 6. 5. 1. 2.\n",
      " 1. 0. 0. 0. 3. 1. 0. 2. 2. 5. 5. 3. 2. 7. 1. 5. 3. 5. 5. 5. 4. 0. 4. 4.\n",
      " 0. 1. 1. 1. 1. 2. 0. 1. 3. 5. 2. 1. 2. 2. 2. 0. 3. 2. 0. 1. 2. 1. 1. 0.\n",
      " 2. 2. 0. 6. 1. 2. 0. 1. 6. 2. 2. 2. 6. 1. 0. 2. 2. 2. 1. 0. 0. 1. 4. 0.\n",
      " 1. 3. 2. 2. 3. 4. 2. 6. 0. 2. 0. 8. 2. 4. 1. 2. 4. 0. 2. 1. 2. 0. 2. 0.\n",
      " 5. 4. 2. 1. 2. 0. 9. 2. 5. 1. 1. 0. 4. 0. 1. 0. 0. 0. 4. 0. 1. 0. 1. 3.\n",
      " 1. 0. 3. 2. 0. 0. 2. 0. 5. 0. 3. 3. 1. 2. 1. 8. 2. 2. 2. 1. 1. 2. 1. 1.\n",
      " 2. 2. 0. 0. 0. 2. 1. 4.]\n",
      "False Positives:  [29.  1.  3.  4.  4.  2.  8.  3.  4.  3.  1.  0. 13.  1.  3.  6.  4.  4.\n",
      "  0.  1. 12.  6.  8.  7.  1.  0.  4.  2. 13.  1.  0.  3.  9.  4.  9. 12.\n",
      " 16.  6.  1.  1.  1.  4.  2.  1.  2.  3.  1.  2.  1.  0.  1.  0.  1.  1.\n",
      "  1.  2.  0. 14. 10.  3.  0.  4.  2.  5.  4.  1. 11.  5.  5.  2.  3. 11.\n",
      "  0.  5.  7.  2.  0.  2.  0.  0.  3.  2.  0.  2.  0.  2.  3.  1.  4.  4.\n",
      "  0.  2.  4.  1.  7.  0.  2.  6.  3.  7.  4.  3.  3.  2. 38. 15.  4.  0.\n",
      " 11.  4.  3.  3.  3.  7.  3.  3.  1.  9.  0.  1.  2.  6.  4.  6.  6.  9.\n",
      "  4.  2.  0.  1.  1.  6.  1.  1.  1.  4. 12.  0.  3.  4.  4.  2.  3.  1.\n",
      "  2.  2.  5.  5. 10.  0.  5.  2.  6.  9.  6.  2.  2.  1.  3.  1.  2.  0.\n",
      "  3.  3.  1.  0.  0.  4. 13.  1.  5.  3.  9.  1.  4.  0.  3.  2.  0.  6.\n",
      "  2.  1.  0.  5.  1.  5.  1.  3.  1.  6.  3.  8.  2.  7.  0.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  3.  1.  3.  3.  3.  6.  3.  4.  3.  2.  3.  4.  5.  6.  2.\n",
      "  3.  9.  7.  7.  3.  6.  1.  0.  4.  0.  3.  3.  8.  3.  5.  7.  0.  1.\n",
      " 12.  8.  2.  4.  3.  4.  2.  3.  1.  4.  2.  6.  6.  5.  4.  5.  4.  6.\n",
      "  0.  2.  0.  3.  3.  5.  5.  3.  6.  4.  4.  4.  5.  2.  0.  6.  8.  1.\n",
      "  1.  2.  4.  4.  2.  3.  4.  0.  4.  2.  3.  2.  4.  3.  4.  3.  4.  2.\n",
      "  2.  4.  6.  5.  4.  2.  3.  1.  7.  4.  5.  8.  3.  5.  3.  4.  3.  1.\n",
      "  4. 10.  6.  4.  7.  6.  4.  6.  3.  1.  0.  2.  3.  6.  7.  2.  3.  3.\n",
      " 10.  3.  5.  1.  7.  6.  1.  2.  1.  1.  1.  0.  0.  4.  2.  7.  3.  3.\n",
      "  5.  4.  0.  3.  1.  2.  4.  5.  6.  3.  6.  1.  3.  5.  8.  5.  6.  3.\n",
      "  8.  7.  1.  4.  2.  1.  1.  6.  3.  8.  8.  4.  4.  4.  2.  2. 14.  4.\n",
      "  3.  2.  2.  3.  5. 10.  4.  4.  3.  4.  7.  7.  5.  4.  4.  1.  4.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.046875 0.       0.03125  0.       0.046875 0.03125  0.0625   0.\n",
      " 0.046875 0.       0.       0.       0.09375  0.       0.0625   0.\n",
      " 0.015625 0.015625 0.       0.       0.015625 0.03125  0.03125  0.09375\n",
      " 0.       0.       0.09375  0.03125  0.015625 0.03125  0.       0.015625\n",
      " 0.03125  0.046875 0.046875 0.0625   0.125    0.       0.015625 0.\n",
      " 0.03125  0.015625 0.015625 0.046875 0.09375  0.078125 0.015625 0.03125\n",
      " 0.015625 0.       0.       0.       0.046875 0.015625 0.       0.03125\n",
      " 0.03125  0.078125 0.078125 0.046875 0.03125  0.109375 0.015625 0.078125\n",
      " 0.046875 0.078125 0.078125 0.078125 0.0625   0.       0.0625   0.0625\n",
      " 0.       0.015625 0.015625 0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.046875 0.078125 0.03125  0.015625 0.03125  0.03125  0.03125  0.\n",
      " 0.046875 0.03125  0.       0.015625 0.03125  0.015625 0.015625 0.\n",
      " 0.03125  0.03125  0.       0.09375  0.015625 0.03125  0.       0.015625\n",
      " 0.09375  0.03125  0.03125  0.03125  0.09375  0.015625 0.       0.03125\n",
      " 0.03125  0.03125  0.015625 0.       0.       0.015625 0.0625   0.\n",
      " 0.015625 0.046875 0.03125  0.03125  0.046875 0.0625   0.03125  0.09375\n",
      " 0.       0.03125  0.       0.125    0.03125  0.0625   0.015625 0.03125\n",
      " 0.0625   0.       0.03125  0.015625 0.03125  0.       0.03125  0.\n",
      " 0.078125 0.0625   0.03125  0.015625 0.03125  0.       0.140625 0.03125\n",
      " 0.078125 0.015625 0.015625 0.       0.0625   0.       0.015625 0.\n",
      " 0.       0.       0.0625   0.       0.015625 0.       0.015625 0.046875\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.03125  0.\n",
      " 0.078125 0.       0.046875 0.046875 0.015625 0.03125  0.015625 0.125\n",
      " 0.03125  0.03125  0.03125  0.015625 0.015625 0.03125  0.015625 0.015625\n",
      " 0.03125  0.03125  0.       0.       0.       0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.09375    0.         0.4        0.         0.42857143 0.5\n",
      " 0.33333333 0.         0.42857143 0.         0.         0.\n",
      " 0.31578947 0.         0.57142857 0.         0.2        0.2\n",
      " 0.         0.         0.07692308 0.25       0.2        0.46153846\n",
      " 0.         0.         0.6        0.5        0.07142857 0.66666667\n",
      " 0.         0.25       0.18181818 0.42857143 0.25       0.25\n",
      " 0.33333333 0.         0.5        0.         0.66666667 0.2\n",
      " 0.33333333 0.75       0.75       0.625      0.5        0.5\n",
      " 0.5        0.         0.         0.         0.75       0.5\n",
      " 0.         0.5        1.         0.26315789 0.33333333 0.5\n",
      " 1.         0.63636364 0.33333333 0.5        0.42857143 0.83333333\n",
      " 0.3125     0.5        0.44444444 0.         0.57142857 0.26666667\n",
      " 0.         0.16666667 0.125      0.33333333 1.         0.5\n",
      " 0.         1.         0.5        0.71428571 1.         0.33333333\n",
      " 1.         0.5        0.4        0.         0.42857143 0.33333333\n",
      " 0.         0.33333333 0.33333333 0.5        0.125      0.\n",
      " 0.5        0.25       0.         0.46153846 0.2        0.4\n",
      " 0.         0.33333333 0.13636364 0.11764706 0.33333333 1.\n",
      " 0.35294118 0.2        0.         0.4        0.4        0.22222222\n",
      " 0.25       0.         0.         0.1        1.         0.\n",
      " 0.33333333 0.33333333 0.33333333 0.25       0.33333333 0.30769231\n",
      " 0.33333333 0.75       0.         0.66666667 0.         0.57142857\n",
      " 0.66666667 0.8        0.5        0.33333333 0.25       0.\n",
      " 0.4        0.2        0.33333333 0.         0.4        0.\n",
      " 0.71428571 0.66666667 0.28571429 0.16666667 0.16666667 0.\n",
      " 0.64285714 0.5        0.45454545 0.1        0.14285714 0.\n",
      " 0.66666667 0.         0.25       0.         0.         0.\n",
      " 0.57142857 0.         0.5        0.         1.         0.42857143\n",
      " 0.07142857 0.         0.375      0.4        0.         0.\n",
      " 0.33333333 0.         0.625      0.         1.         0.33333333\n",
      " 0.33333333 0.66666667 1.         0.61538462 0.66666667 0.28571429\n",
      " 0.66666667 0.25       0.5        0.25       0.25       0.11111111\n",
      " 0.5        0.22222222 0.         0.         0.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.25       0.         0.5        0.         0.75       0.4\n",
      " 0.57142857 0.         0.33333333 0.         0.         0.\n",
      " 0.75       0.         0.5        0.         0.14285714 0.33333333\n",
      " 0.         0.         0.125      0.22222222 0.4        0.5\n",
      " 0.         0.         0.6        1.         0.25       0.4\n",
      " 0.         0.25       0.28571429 0.3        1.         0.8\n",
      " 0.4        0.         0.33333333 0.         0.4        0.2\n",
      " 0.33333333 0.5        0.85714286 0.55555556 0.33333333 0.25\n",
      " 0.14285714 0.         0.         0.         0.42857143 0.14285714\n",
      " 0.         0.5        1.         0.625      0.625      0.375\n",
      " 0.28571429 0.7        0.14285714 0.55555556 0.42857143 0.55555556\n",
      " 0.5        0.71428571 1.         0.         0.33333333 0.8\n",
      " 0.         0.33333333 0.2        0.2        0.33333333 0.4\n",
      " 0.         1.         0.42857143 0.71428571 0.4        0.33333333\n",
      " 0.33333333 0.4        0.33333333 0.         0.42857143 0.5\n",
      " 0.         0.2        0.25       0.16666667 0.2        0.\n",
      " 0.4        0.66666667 0.         0.6        0.16666667 0.2\n",
      " 0.         0.16666667 0.66666667 0.33333333 0.4        0.66666667\n",
      " 0.6        0.09090909 0.         0.33333333 0.22222222 0.25\n",
      " 0.2        0.         0.         0.5        1.         0.\n",
      " 0.25       0.33333333 0.22222222 0.5        0.5        0.57142857\n",
      " 0.16666667 0.66666667 0.         0.66666667 0.         0.57142857\n",
      " 0.66666667 0.66666667 0.5        0.66666667 0.8        0.\n",
      " 1.         0.2        0.5        0.         0.4        0.\n",
      " 0.5        0.5        1.         0.25       0.66666667 0.\n",
      " 0.69230769 0.28571429 0.45454545 0.25       0.14285714 0.\n",
      " 0.57142857 0.         0.11111111 0.         0.         0.\n",
      " 0.33333333 0.         0.5        0.         0.33333333 0.75\n",
      " 0.5        0.         0.5        0.2        0.         0.\n",
      " 0.33333333 0.         0.71428571 0.         0.17647059 0.42857143\n",
      " 0.25       0.5        0.33333333 0.72727273 0.28571429 0.16666667\n",
      " 0.33333333 0.2        0.25       0.33333333 0.125      0.125\n",
      " 0.28571429 0.33333333 0.         0.         0.         0.4\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.171875   0.         0.45       0.         0.58928571 0.45\n",
      " 0.45238095 0.         0.38095238 0.         0.         0.\n",
      " 0.53289474 0.         0.53571429 0.         0.17142857 0.26666667\n",
      " 0.         0.         0.10096154 0.23611111 0.3        0.48076923\n",
      " 0.         0.         0.6        0.75       0.16071429 0.53333333\n",
      " 0.         0.25       0.23376623 0.36428571 0.625      0.525\n",
      " 0.36666667 0.         0.41666667 0.         0.53333333 0.2\n",
      " 0.33333333 0.625      0.80357143 0.59027778 0.41666667 0.375\n",
      " 0.32142857 0.         0.         0.         0.58928571 0.32142857\n",
      " 0.         0.5        1.         0.44407895 0.47916667 0.4375\n",
      " 0.64285714 0.66818182 0.23809524 0.52777778 0.42857143 0.69444444\n",
      " 0.40625    0.60714286 0.72222222 0.         0.45238095 0.53333333\n",
      " 0.         0.25       0.1625     0.26666667 0.66666667 0.45\n",
      " 0.         1.         0.46428571 0.71428571 0.7        0.33333333\n",
      " 0.66666667 0.45       0.36666667 0.         0.42857143 0.41666667\n",
      " 0.         0.26666667 0.29166667 0.33333333 0.1625     0.\n",
      " 0.45       0.45833333 0.         0.53076923 0.18333333 0.3\n",
      " 0.         0.25       0.40151515 0.2254902  0.36666667 0.83333333\n",
      " 0.47647059 0.14545455 0.         0.36666667 0.31111111 0.23611111\n",
      " 0.225      0.         0.         0.3        1.         0.\n",
      " 0.29166667 0.33333333 0.27777778 0.375      0.41666667 0.43956044\n",
      " 0.25       0.70833333 0.         0.66666667 0.         0.57142857\n",
      " 0.66666667 0.73333333 0.5        0.5        0.525      0.\n",
      " 0.7        0.2        0.41666667 0.         0.4        0.\n",
      " 0.60714286 0.58333333 0.64285714 0.20833333 0.41666667 0.\n",
      " 0.66758242 0.39285714 0.45454545 0.175      0.14285714 0.\n",
      " 0.61904762 0.         0.18055556 0.         0.         0.\n",
      " 0.45238095 0.         0.5        0.         0.66666667 0.58928571\n",
      " 0.28571429 0.         0.4375     0.3        0.         0.\n",
      " 0.33333333 0.         0.66964286 0.         0.58823529 0.38095238\n",
      " 0.29166667 0.58333333 0.66666667 0.67132867 0.47619048 0.22619048\n",
      " 0.5        0.225      0.375      0.29166667 0.1875     0.11805556\n",
      " 0.39285714 0.27777778 0.         0.         0.         0.34285714\n",
      " 0.75       0.68571429]\n",
      "mini_batch 200\n",
      "mini_batch 201\n",
      "mini_batch 202\n",
      "mini_batch 203\n",
      "mini_batch 204\n",
      "mini_batch 205\n",
      "mini_batch 206\n",
      "mini_batch 207\n",
      "mini_batch 208\n",
      "mini_batch 209\n",
      "mini_batch 210\n",
      "mini_batch 211\n",
      "mini_batch 212\n",
      "mini_batch 213\n",
      "mini_batch 214\n",
      "mini_batch 215\n",
      "mini_batch 216\n",
      "mini_batch 217\n",
      "mini_batch 218\n",
      "mini_batch 219\n",
      "mini_batch 220\n",
      "mini_batch 221\n",
      "mini_batch 222\n",
      "mini_batch 223\n",
      "mini_batch 224\n",
      "mini_batch 225\n",
      "mini_batch 226\n",
      "mini_batch 227\n",
      "mini_batch 228\n",
      "mini_batch 229\n",
      "mini_batch 230\n",
      "mini_batch 231\n",
      "mini_batch 232\n",
      "mini_batch 233\n",
      "mini_batch 234\n",
      "mini_batch 235\n",
      "mini_batch 236\n",
      "mini_batch 237\n",
      "mini_batch 238\n",
      "mini_batch 239\n",
      "mini_batch 240\n",
      "mini_batch 241\n",
      "mini_batch 242\n",
      "mini_batch 243\n",
      "mini_batch 244\n",
      "mini_batch 245\n",
      "mini_batch 246\n",
      "mini_batch 247\n",
      "mini_batch 248\n",
      "mini_batch 249\n",
      "Epoch 3\n",
      "average minibatch 250 loss: 1.739\n",
      "\n",
      "Labels:  tensor([102,  21,  58, 161,  37,  16,   5,  91,  76, 132,  35,  17, 135, 144,\n",
      "        128, 186,  21, 132,  12,   5,  40,  68,  55, 171, 146,  39,   1, 160,\n",
      "        184,  29, 120, 173,  71, 123, 130, 155, 102,  64, 158,  58,  32, 113,\n",
      "        145,  81,  85,  68,  75,  56, 180,  77, 189,  85, 118, 119,  84,  67,\n",
      "        147,  29,  91,  28, 131, 180,  88, 186], device='cuda:0')\n",
      "Output:  tensor([173,  21, 130, 191, 164,  16, 148,  82,  15, 110,  35,  17, 135,  16,\n",
      "        149, 186,  21, 132,  12,   5, 149,  68, 190, 195, 146,  39,   1, 160,\n",
      "        184,  92,  18, 181,  71, 123, 130, 119, 154,  64,  86,  58,  32, 113,\n",
      "        191,  81,  74, 130,  75,  56, 180,   5, 189,  85, 118,   4, 149,  67,\n",
      "        147, 181,  91,  28, 128, 180,  65,  21], device='cuda:0')\n",
      "True Positives:  [4. 0. 2. 0. 4. 2. 4. 0. 3. 0. 0. 1. 6. 0. 4. 1. 2. 1. 0. 0. 3. 2. 2. 6.\n",
      " 0. 0. 6. 3. 1. 2. 0. 2. 2. 3. 4. 4. 8. 0. 2. 0. 2. 1. 1. 3. 6. 5. 1. 2.\n",
      " 1. 0. 0. 0. 3. 1. 0. 3. 2. 6. 5. 3. 2. 7. 1. 6. 3. 5. 6. 6. 4. 0. 5. 4.\n",
      " 0. 1. 2. 1. 1. 2. 0. 1. 4. 5. 2. 1. 3. 2. 2. 0. 3. 2. 1. 1. 2. 1. 1. 0.\n",
      " 2. 2. 0. 6. 1. 2. 0. 1. 6. 2. 2. 2. 6. 1. 0. 2. 3. 2. 1. 0. 0. 2. 4. 0.\n",
      " 1. 3. 3. 2. 3. 4. 2. 6. 0. 3. 0. 9. 2. 4. 2. 2. 4. 0. 2. 1. 2. 0. 2. 0.\n",
      " 5. 5. 3. 1. 2. 0. 9. 2. 5. 1. 1. 0. 4. 0. 1. 1. 0. 0. 4. 0. 1. 0. 1. 3.\n",
      " 1. 0. 3. 2. 0. 0. 2. 0. 5. 0. 3. 5. 1. 2. 1. 9. 2. 3. 2. 1. 2. 2. 1. 1.\n",
      " 2. 2. 0. 0. 0. 2. 1. 4.]\n",
      "False Positives:  [29.  1.  3.  5.  5.  2.  8.  3.  4.  3.  1.  0. 13.  1.  4.  7.  4.  5.\n",
      "  0.  1. 13.  6.  8.  7.  1.  0.  4.  2. 13.  1.  0.  3.  9.  4.  9. 12.\n",
      " 16.  6.  1.  1.  1.  4.  2.  1.  2.  3.  1.  2.  1.  0.  1.  0.  1.  1.\n",
      "  1.  2.  0. 14. 10.  3.  0.  4.  2.  5.  5.  1. 11.  5.  5.  2.  3. 11.\n",
      "  0.  6.  7.  2.  0.  2.  0.  0.  3.  3.  0.  2.  0.  3.  3.  1.  4.  4.\n",
      "  0.  3.  4.  1.  7.  0.  2.  6.  3.  7.  4.  3.  3.  2. 38. 15.  4.  0.\n",
      " 11.  5.  3.  3.  3.  7.  3.  3.  1.  9.  1.  1.  2.  6.  4.  6.  6.  9.\n",
      "  4.  3.  0.  3.  1.  6.  1.  1.  1.  4. 12.  0.  3.  4.  4.  2.  3.  1.\n",
      "  2.  2.  5.  6. 13.  0.  5.  2.  6. 10.  6.  2.  2.  1.  3.  1.  2.  0.\n",
      "  3.  4.  1.  0.  0.  4. 13.  1.  5.  3. 10.  1.  4.  0.  3.  2.  0.  6.\n",
      "  4.  1.  0.  5.  1.  5.  1.  3.  1.  7.  5.  8.  2.  7.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  3.  2.  3.  3.  3.  6.  3.  4.  3.  2.  3.  4.  5.  6.  2.\n",
      "  3.  9.  7.  7.  3.  6.  1.  0.  4.  0.  5.  3.  8.  3.  5.  7.  0.  1.\n",
      " 13.  8.  2.  5.  3.  4.  2.  3.  1.  4.  2.  6.  6.  5.  4.  5.  4.  6.\n",
      "  1.  2.  0.  4.  3.  5.  5.  3.  6.  4.  4.  4.  5.  3.  0.  6.  8.  1.\n",
      "  1.  2.  4.  5.  3.  3.  4.  0.  4.  2.  3.  3.  5.  3.  4.  4.  4.  2.\n",
      "  3.  4.  6.  5.  4.  2.  3.  1.  7.  4.  5. 10.  3.  5.  3.  4.  3.  1.\n",
      "  4. 10.  6.  4.  7.  6.  4.  6.  3.  1.  1.  3.  3.  6.  7.  2.  3.  3.\n",
      " 10.  4.  5.  1.  8.  7.  1.  2.  1.  1.  1.  0.  0.  4.  2.  7.  3.  4.\n",
      "  6.  4.  0.  3.  1.  2.  4.  5.  6.  3.  7.  1.  3.  6.  8.  5.  7.  3.\n",
      "  8.  7.  1.  4.  2.  1.  1.  6.  4.  8.  9.  4.  4.  4.  2.  2. 14.  4.\n",
      "  3.  2.  2.  3.  5. 11.  4.  4.  3.  4.  7.  7.  5.  4.  4.  1.  4.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.0625   0.       0.03125  0.       0.0625   0.03125  0.0625   0.\n",
      " 0.046875 0.       0.       0.015625 0.09375  0.       0.0625   0.015625\n",
      " 0.03125  0.015625 0.       0.       0.046875 0.03125  0.03125  0.09375\n",
      " 0.       0.       0.09375  0.046875 0.015625 0.03125  0.       0.03125\n",
      " 0.03125  0.046875 0.0625   0.0625   0.125    0.       0.03125  0.\n",
      " 0.03125  0.015625 0.015625 0.046875 0.09375  0.078125 0.015625 0.03125\n",
      " 0.015625 0.       0.       0.       0.046875 0.015625 0.       0.046875\n",
      " 0.03125  0.09375  0.078125 0.046875 0.03125  0.109375 0.015625 0.09375\n",
      " 0.046875 0.078125 0.09375  0.09375  0.0625   0.       0.078125 0.0625\n",
      " 0.       0.015625 0.03125  0.015625 0.015625 0.03125  0.       0.015625\n",
      " 0.0625   0.078125 0.03125  0.015625 0.046875 0.03125  0.03125  0.\n",
      " 0.046875 0.03125  0.015625 0.015625 0.03125  0.015625 0.015625 0.\n",
      " 0.03125  0.03125  0.       0.09375  0.015625 0.03125  0.       0.015625\n",
      " 0.09375  0.03125  0.03125  0.03125  0.09375  0.015625 0.       0.03125\n",
      " 0.046875 0.03125  0.015625 0.       0.       0.03125  0.0625   0.\n",
      " 0.015625 0.046875 0.046875 0.03125  0.046875 0.0625   0.03125  0.09375\n",
      " 0.       0.046875 0.       0.140625 0.03125  0.0625   0.03125  0.03125\n",
      " 0.0625   0.       0.03125  0.015625 0.03125  0.       0.03125  0.\n",
      " 0.078125 0.078125 0.046875 0.015625 0.03125  0.       0.140625 0.03125\n",
      " 0.078125 0.015625 0.015625 0.       0.0625   0.       0.015625 0.015625\n",
      " 0.       0.       0.0625   0.       0.015625 0.       0.015625 0.046875\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.03125  0.\n",
      " 0.078125 0.       0.046875 0.078125 0.015625 0.03125  0.015625 0.140625\n",
      " 0.03125  0.046875 0.03125  0.015625 0.03125  0.03125  0.015625 0.015625\n",
      " 0.03125  0.03125  0.       0.       0.       0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.12121212 0.         0.4        0.         0.44444444 0.5\n",
      " 0.33333333 0.         0.42857143 0.         0.         1.\n",
      " 0.31578947 0.         0.5        0.125      0.33333333 0.16666667\n",
      " 0.         0.         0.1875     0.25       0.2        0.46153846\n",
      " 0.         0.         0.6        0.6        0.07142857 0.66666667\n",
      " 0.         0.4        0.18181818 0.42857143 0.30769231 0.25\n",
      " 0.33333333 0.         0.66666667 0.         0.66666667 0.2\n",
      " 0.33333333 0.75       0.75       0.625      0.5        0.5\n",
      " 0.5        0.         0.         0.         0.75       0.5\n",
      " 0.         0.6        1.         0.3        0.33333333 0.5\n",
      " 1.         0.63636364 0.33333333 0.54545455 0.375      0.83333333\n",
      " 0.35294118 0.54545455 0.44444444 0.         0.625      0.26666667\n",
      " 0.         0.14285714 0.22222222 0.33333333 1.         0.5\n",
      " 0.         1.         0.57142857 0.625      1.         0.33333333\n",
      " 1.         0.4        0.4        0.         0.42857143 0.33333333\n",
      " 1.         0.25       0.33333333 0.5        0.125      0.\n",
      " 0.5        0.25       0.         0.46153846 0.2        0.4\n",
      " 0.         0.33333333 0.13636364 0.11764706 0.33333333 1.\n",
      " 0.35294118 0.16666667 0.         0.4        0.5        0.22222222\n",
      " 0.25       0.         0.         0.18181818 0.8        0.\n",
      " 0.33333333 0.33333333 0.42857143 0.25       0.33333333 0.30769231\n",
      " 0.33333333 0.66666667 0.         0.5        0.         0.6\n",
      " 0.66666667 0.8        0.66666667 0.33333333 0.25       0.\n",
      " 0.4        0.2        0.33333333 0.         0.4        0.\n",
      " 0.71428571 0.71428571 0.375      0.14285714 0.13333333 0.\n",
      " 0.64285714 0.5        0.45454545 0.09090909 0.14285714 0.\n",
      " 0.66666667 0.         0.25       0.5        0.         0.\n",
      " 0.57142857 0.         0.5        0.         1.         0.42857143\n",
      " 0.07142857 0.         0.375      0.4        0.         0.\n",
      " 0.33333333 0.         0.625      0.         1.         0.45454545\n",
      " 0.2        0.66666667 1.         0.64285714 0.66666667 0.375\n",
      " 0.66666667 0.25       0.66666667 0.22222222 0.16666667 0.11111111\n",
      " 0.5        0.22222222 0.         0.         0.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.30769231 0.         0.5        0.         0.66666667 0.4\n",
      " 0.57142857 0.         0.33333333 0.         0.         0.25\n",
      " 0.75       0.         0.5        0.16666667 0.25       0.33333333\n",
      " 0.         0.         0.3        0.22222222 0.4        0.5\n",
      " 0.         0.         0.6        1.         0.16666667 0.4\n",
      " 0.         0.4        0.28571429 0.3        1.         0.8\n",
      " 0.38095238 0.         0.5        0.         0.4        0.2\n",
      " 0.33333333 0.5        0.85714286 0.55555556 0.33333333 0.25\n",
      " 0.14285714 0.         0.         0.         0.42857143 0.14285714\n",
      " 0.         0.6        1.         0.6        0.625      0.375\n",
      " 0.28571429 0.7        0.14285714 0.6        0.42857143 0.55555556\n",
      " 0.54545455 0.66666667 1.         0.         0.38461538 0.8\n",
      " 0.         0.33333333 0.33333333 0.16666667 0.25       0.4\n",
      " 0.         1.         0.5        0.71428571 0.4        0.25\n",
      " 0.375      0.4        0.33333333 0.         0.42857143 0.5\n",
      " 0.25       0.2        0.25       0.16666667 0.2        0.\n",
      " 0.4        0.66666667 0.         0.6        0.16666667 0.16666667\n",
      " 0.         0.16666667 0.66666667 0.33333333 0.4        0.66666667\n",
      " 0.6        0.09090909 0.         0.33333333 0.3        0.25\n",
      " 0.2        0.         0.         0.66666667 0.8        0.\n",
      " 0.25       0.33333333 0.3        0.5        0.5        0.57142857\n",
      " 0.16666667 0.6        0.         0.75       0.         0.5625\n",
      " 0.66666667 0.66666667 0.66666667 0.66666667 0.8        0.\n",
      " 1.         0.2        0.5        0.         0.4        0.\n",
      " 0.45454545 0.55555556 1.         0.25       0.66666667 0.\n",
      " 0.69230769 0.28571429 0.45454545 0.25       0.125      0.\n",
      " 0.57142857 0.         0.11111111 0.16666667 0.         0.\n",
      " 0.33333333 0.         0.5        0.         0.33333333 0.75\n",
      " 0.5        0.         0.42857143 0.2        0.         0.\n",
      " 0.33333333 0.         0.71428571 0.         0.17647059 0.55555556\n",
      " 0.25       0.5        0.33333333 0.75       0.28571429 0.21428571\n",
      " 0.33333333 0.2        0.4        0.33333333 0.125      0.125\n",
      " 0.28571429 0.33333333 0.         0.         0.         0.4\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.21445221 0.         0.45       0.         0.55555556 0.45\n",
      " 0.45238095 0.         0.38095238 0.         0.         0.625\n",
      " 0.53289474 0.         0.5        0.14583333 0.29166667 0.25\n",
      " 0.         0.         0.24375    0.23611111 0.3        0.48076923\n",
      " 0.         0.         0.6        0.8        0.11904762 0.53333333\n",
      " 0.         0.4        0.23376623 0.36428571 0.65384615 0.525\n",
      " 0.35714286 0.         0.58333333 0.         0.53333333 0.2\n",
      " 0.33333333 0.625      0.80357143 0.59027778 0.41666667 0.375\n",
      " 0.32142857 0.         0.         0.         0.58928571 0.32142857\n",
      " 0.         0.6        1.         0.45       0.47916667 0.4375\n",
      " 0.64285714 0.66818182 0.23809524 0.57272727 0.40178571 0.69444444\n",
      " 0.44919786 0.60606061 0.72222222 0.         0.50480769 0.53333333\n",
      " 0.         0.23809524 0.27777778 0.25       0.625      0.45\n",
      " 0.         1.         0.53571429 0.66964286 0.7        0.29166667\n",
      " 0.6875     0.4        0.36666667 0.         0.42857143 0.41666667\n",
      " 0.625      0.225      0.29166667 0.33333333 0.1625     0.\n",
      " 0.45       0.45833333 0.         0.53076923 0.18333333 0.28333333\n",
      " 0.         0.25       0.40151515 0.2254902  0.36666667 0.83333333\n",
      " 0.47647059 0.12878788 0.         0.36666667 0.4        0.23611111\n",
      " 0.225      0.         0.         0.42424242 0.8        0.\n",
      " 0.29166667 0.33333333 0.36428571 0.375      0.41666667 0.43956044\n",
      " 0.25       0.63333333 0.         0.625      0.         0.58125\n",
      " 0.66666667 0.73333333 0.66666667 0.5        0.525      0.\n",
      " 0.7        0.2        0.41666667 0.         0.4        0.\n",
      " 0.58441558 0.63492063 0.6875     0.19642857 0.4        0.\n",
      " 0.66758242 0.39285714 0.45454545 0.17045455 0.13392857 0.\n",
      " 0.61904762 0.         0.18055556 0.33333333 0.         0.\n",
      " 0.45238095 0.         0.5        0.         0.66666667 0.58928571\n",
      " 0.28571429 0.         0.40178571 0.3        0.         0.\n",
      " 0.33333333 0.         0.66964286 0.         0.58823529 0.50505051\n",
      " 0.225      0.58333333 0.66666667 0.69642857 0.47619048 0.29464286\n",
      " 0.5        0.225      0.53333333 0.27777778 0.14583333 0.11805556\n",
      " 0.39285714 0.27777778 0.         0.         0.         0.34285714\n",
      " 0.75       0.68571429]\n",
      "mini_batch 250\n",
      "mini_batch 251\n",
      "mini_batch 252\n",
      "mini_batch 253\n",
      "mini_batch 254\n",
      "mini_batch 255\n",
      "mini_batch 256\n",
      "mini_batch 257\n",
      "mini_batch 258\n",
      "mini_batch 259\n",
      "mini_batch 260\n",
      "mini_batch 261\n",
      "mini_batch 262\n",
      "mini_batch 263\n",
      "mini_batch 264\n",
      "mini_batch 265\n",
      "mini_batch 266\n",
      "mini_batch 267\n",
      "mini_batch 268\n",
      "mini_batch 269\n",
      "mini_batch 270\n",
      "mini_batch 271\n",
      "mini_batch 272\n",
      "mini_batch 273\n",
      "mini_batch 274\n",
      "mini_batch 275\n",
      "mini_batch 276\n",
      "mini_batch 277\n",
      "mini_batch 278\n",
      "mini_batch 279\n",
      "mini_batch 280\n",
      "mini_batch 281\n",
      "mini_batch 282\n",
      "mini_batch 283\n",
      "mini_batch 284\n",
      "mini_batch 285\n",
      "mini_batch 286\n",
      "mini_batch 287\n",
      "mini_batch 288\n",
      "mini_batch 289\n",
      "mini_batch 290\n",
      "mini_batch 291\n",
      "mini_batch 292\n",
      "mini_batch 293\n",
      "mini_batch 294\n",
      "mini_batch 295\n",
      "mini_batch 296\n",
      "mini_batch 297\n",
      "mini_batch 298\n",
      "mini_batch 299\n",
      "Epoch 3\n",
      "average minibatch 300 loss: 1.784\n",
      "\n",
      "Labels:  tensor([ 22, 157,  44, 115,  29, 164, 115, 136,  53, 111,  78, 192,  20, 163,\n",
      "        191, 193, 132,  33, 173,  82,  27,   4, 139,   5, 160, 122, 127,  11,\n",
      "         15, 171, 193,  93,  56, 109,  39,  41, 177,  53,  95, 197, 102, 179,\n",
      "        141,   9, 113,  63, 109,  46, 136,  58, 126, 121, 189,  65,  24, 116,\n",
      "        172, 102,  78, 172,  58,  89,  90, 154], device='cuda:0')\n",
      "Output:  tensor([ 22, 157,   6, 115,  29, 192, 136, 136,  53, 111,  78, 192,  20, 163,\n",
      "        191, 144, 132, 152,  76,  82,  27,   4, 139, 139, 160, 148, 127,  45,\n",
      "         15,  88,  12,  22,  76, 109,  39,  41, 110,  53, 101, 197, 102, 179,\n",
      "        137,   9, 113,  63, 189,  46, 107,  58, 126, 121, 173,  51,  24, 116,\n",
      "         30, 102, 194,  29,  58,  66,  90, 154], device='cuda:0')\n",
      "True Positives:  [ 4.  0.  2.  1.  4.  2.  4.  0.  4.  0.  0.  1.  6.  0.  5.  1.  2.  1.\n",
      "  0.  1.  3.  3.  2.  7.  0.  0.  7.  3.  2.  2.  0.  2.  2.  3.  4.  4.\n",
      "  8.  0.  3.  0.  3.  1.  1.  3.  6.  6.  1.  2.  1.  0.  0.  0.  5.  1.\n",
      "  0.  3.  2.  8.  5.  3.  2.  7.  2.  6.  3.  5.  6.  6.  4.  0.  5.  4.\n",
      "  0.  1.  2.  1.  1.  3.  0.  1.  4.  6.  2.  1.  3.  2.  2.  0.  3.  3.\n",
      "  1.  1.  2.  1.  1.  0.  2.  2.  0.  6.  1.  4.  0.  1.  6.  2.  2.  2.\n",
      "  7.  1.  1.  2.  4.  2.  2.  1.  0.  2.  4.  0.  2.  3.  3.  2.  3.  5.\n",
      "  3.  6.  0.  3.  0. 10.  2.  4.  2.  3.  4.  0.  3.  1.  2.  0.  2.  0.\n",
      "  5.  5.  3.  1.  2.  0.  9.  2.  5.  2.  1.  0.  5.  0.  1.  2.  0.  0.\n",
      "  5.  0.  1.  0.  1.  3.  1.  0.  3.  2.  0.  0.  2.  0.  5.  0.  4.  5.\n",
      "  1.  2.  1.  9.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  0.  0.  1.  2.\n",
      "  1.  4.]\n",
      "False Positives:  [29.  1.  3.  5.  5.  3.  8.  3.  4.  3.  1.  1. 13.  1.  4.  7.  4.  5.\n",
      "  0.  1. 13.  7.  8.  7.  1.  0.  4.  2. 14.  2.  0.  3.  9.  4.  9. 12.\n",
      " 16.  6.  1.  1.  1.  4.  2.  1.  3.  3.  1.  2.  1.  0.  2.  0.  1.  1.\n",
      "  1.  2.  0. 14. 10.  3.  0.  4.  2.  5.  5.  2. 11.  5.  5.  2.  3. 11.\n",
      "  0.  6.  7.  4.  0.  2.  0.  0.  3.  3.  0.  2.  0.  3.  3.  2.  4.  4.\n",
      "  0.  3.  4.  1.  7.  0.  2.  6.  3.  7.  5.  3.  3.  2. 38. 15.  5.  0.\n",
      " 11.  6.  3.  3.  3.  7.  3.  3.  1.  9.  1.  1.  2.  6.  4.  6.  6.  9.\n",
      "  4.  3.  0.  3.  1.  6.  1.  1.  1.  5. 13.  0.  4.  4.  4.  2.  3.  2.\n",
      "  2.  2.  5.  7. 13.  0.  5.  3.  6. 10.  6.  2.  2.  1.  3.  1.  2.  0.\n",
      "  3.  4.  1.  0.  0.  4. 13.  1.  5.  3. 11.  1.  4.  0.  3.  2.  0.  6.\n",
      "  4.  1.  0.  5.  1.  5.  1.  3.  2.  7.  5.  9.  2.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  2.  3.  3.  3.  3.  3.  6.  3.  5.  3.  2.  3.  4.  5.  6.  2.\n",
      "  3.  9.  7.  7.  3.  6.  1.  0.  4.  0.  5.  3.  8.  3.  6.  7.  0.  1.\n",
      " 13.  8.  2.  5.  3.  4.  2.  4.  1.  4.  2.  6.  6.  5.  4.  5.  4.  6.\n",
      "  1.  3.  0.  4.  3.  5.  5.  3.  6.  4.  5.  4.  5.  3.  0.  6.  8.  1.\n",
      "  1.  2.  4.  5.  3.  4.  4.  0.  4.  2.  3.  3.  5.  3.  4.  4.  5.  2.\n",
      "  3.  4.  7.  5.  5.  2.  3.  1.  7.  4.  5. 10.  3.  5.  3.  4.  3.  1.\n",
      "  5. 10.  6.  4.  7.  6.  5.  6.  3.  1.  1.  3.  3.  7.  7.  2.  3.  3.\n",
      " 10.  4.  5.  1.  8.  7.  1.  2.  1.  2.  1.  0.  0.  4.  3.  7.  3.  4.\n",
      "  6.  4.  0.  3.  1.  2.  4.  5.  6.  3.  7.  1.  3.  6.  8.  5.  7.  3.\n",
      "  8.  8.  1.  4.  2.  1.  1.  6.  5. 10. 10.  4.  4.  4.  3.  2. 14.  4.\n",
      "  3.  2.  2.  3.  5. 11.  4.  4.  4.  4.  7.  7.  7.  4.  4.  1.  4.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.0625   0.       0.03125  0.015625 0.0625   0.03125  0.0625   0.\n",
      " 0.0625   0.       0.       0.015625 0.09375  0.       0.078125 0.015625\n",
      " 0.03125  0.015625 0.       0.015625 0.046875 0.046875 0.03125  0.109375\n",
      " 0.       0.       0.109375 0.046875 0.03125  0.03125  0.       0.03125\n",
      " 0.03125  0.046875 0.0625   0.0625   0.125    0.       0.046875 0.\n",
      " 0.046875 0.015625 0.015625 0.046875 0.09375  0.09375  0.015625 0.03125\n",
      " 0.015625 0.       0.       0.       0.078125 0.015625 0.       0.046875\n",
      " 0.03125  0.125    0.078125 0.046875 0.03125  0.109375 0.03125  0.09375\n",
      " 0.046875 0.078125 0.09375  0.09375  0.0625   0.       0.078125 0.0625\n",
      " 0.       0.015625 0.03125  0.015625 0.015625 0.046875 0.       0.015625\n",
      " 0.0625   0.09375  0.03125  0.015625 0.046875 0.03125  0.03125  0.\n",
      " 0.046875 0.046875 0.015625 0.015625 0.03125  0.015625 0.015625 0.\n",
      " 0.03125  0.03125  0.       0.09375  0.015625 0.0625   0.       0.015625\n",
      " 0.09375  0.03125  0.03125  0.03125  0.109375 0.015625 0.015625 0.03125\n",
      " 0.0625   0.03125  0.03125  0.015625 0.       0.03125  0.0625   0.\n",
      " 0.03125  0.046875 0.046875 0.03125  0.046875 0.078125 0.046875 0.09375\n",
      " 0.       0.046875 0.       0.15625  0.03125  0.0625   0.03125  0.046875\n",
      " 0.0625   0.       0.046875 0.015625 0.03125  0.       0.03125  0.\n",
      " 0.078125 0.078125 0.046875 0.015625 0.03125  0.       0.140625 0.03125\n",
      " 0.078125 0.03125  0.015625 0.       0.078125 0.       0.015625 0.03125\n",
      " 0.       0.       0.078125 0.       0.015625 0.       0.015625 0.046875\n",
      " 0.015625 0.       0.046875 0.03125  0.       0.       0.03125  0.\n",
      " 0.078125 0.       0.0625   0.078125 0.015625 0.03125  0.015625 0.140625\n",
      " 0.03125  0.046875 0.03125  0.015625 0.03125  0.03125  0.03125  0.03125\n",
      " 0.03125  0.03125  0.       0.       0.015625 0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.12121212 0.         0.4        0.16666667 0.44444444 0.4\n",
      " 0.33333333 0.         0.5        0.         0.         0.5\n",
      " 0.31578947 0.         0.55555556 0.125      0.33333333 0.16666667\n",
      " 0.         0.5        0.1875     0.3        0.2        0.5\n",
      " 0.         0.         0.63636364 0.6        0.125      0.5\n",
      " 0.         0.4        0.18181818 0.42857143 0.30769231 0.25\n",
      " 0.33333333 0.         0.75       0.         0.75       0.2\n",
      " 0.33333333 0.75       0.66666667 0.66666667 0.5        0.5\n",
      " 0.5        0.         0.         0.         0.83333333 0.5\n",
      " 0.         0.6        1.         0.36363636 0.33333333 0.5\n",
      " 1.         0.63636364 0.5        0.54545455 0.375      0.71428571\n",
      " 0.35294118 0.54545455 0.44444444 0.         0.625      0.26666667\n",
      " 0.         0.14285714 0.22222222 0.2        1.         0.6\n",
      " 0.         1.         0.57142857 0.66666667 1.         0.33333333\n",
      " 1.         0.4        0.4        0.         0.42857143 0.42857143\n",
      " 1.         0.25       0.33333333 0.5        0.125      0.\n",
      " 0.5        0.25       0.         0.46153846 0.16666667 0.57142857\n",
      " 0.         0.33333333 0.13636364 0.11764706 0.28571429 1.\n",
      " 0.38888889 0.14285714 0.25       0.4        0.57142857 0.22222222\n",
      " 0.4        0.25       0.         0.18181818 0.8        0.\n",
      " 0.5        0.33333333 0.42857143 0.25       0.33333333 0.35714286\n",
      " 0.42857143 0.66666667 0.         0.5        0.         0.625\n",
      " 0.66666667 0.8        0.66666667 0.375      0.23529412 0.\n",
      " 0.42857143 0.2        0.33333333 0.         0.4        0.\n",
      " 0.71428571 0.71428571 0.375      0.125      0.13333333 0.\n",
      " 0.64285714 0.4        0.45454545 0.16666667 0.14285714 0.\n",
      " 0.71428571 0.         0.25       0.66666667 0.         0.\n",
      " 0.625      0.         0.5        0.         1.         0.42857143\n",
      " 0.07142857 0.         0.375      0.4        0.         0.\n",
      " 0.33333333 0.         0.625      0.         1.         0.45454545\n",
      " 0.2        0.66666667 1.         0.64285714 0.66666667 0.375\n",
      " 0.66666667 0.25       0.5        0.22222222 0.28571429 0.18181818\n",
      " 0.5        0.2        0.         0.         1.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.30769231 0.         0.5        0.25       0.57142857 0.4\n",
      " 0.57142857 0.         0.4        0.         0.         0.25\n",
      " 0.75       0.         0.55555556 0.16666667 0.25       0.33333333\n",
      " 0.         0.1        0.3        0.3        0.4        0.53846154\n",
      " 0.         0.         0.63636364 1.         0.28571429 0.4\n",
      " 0.         0.4        0.25       0.3        1.         0.8\n",
      " 0.38095238 0.         0.6        0.         0.5        0.2\n",
      " 0.33333333 0.42857143 0.85714286 0.6        0.33333333 0.25\n",
      " 0.14285714 0.         0.         0.         0.55555556 0.14285714\n",
      " 0.         0.5        1.         0.66666667 0.625      0.375\n",
      " 0.28571429 0.7        0.25       0.6        0.375      0.55555556\n",
      " 0.54545455 0.66666667 1.         0.         0.38461538 0.8\n",
      " 0.         0.33333333 0.33333333 0.16666667 0.25       0.42857143\n",
      " 0.         1.         0.5        0.75       0.4        0.25\n",
      " 0.375      0.4        0.33333333 0.         0.375      0.6\n",
      " 0.25       0.2        0.22222222 0.16666667 0.16666667 0.\n",
      " 0.4        0.66666667 0.         0.6        0.16666667 0.28571429\n",
      " 0.         0.16666667 0.66666667 0.33333333 0.4        0.66666667\n",
      " 0.58333333 0.09090909 0.14285714 0.33333333 0.36363636 0.25\n",
      " 0.28571429 0.14285714 0.         0.66666667 0.8        0.\n",
      " 0.4        0.3        0.3        0.5        0.5        0.625\n",
      " 0.23076923 0.6        0.         0.75       0.         0.58823529\n",
      " 0.66666667 0.66666667 0.66666667 0.6        0.8        0.\n",
      " 1.         0.2        0.4        0.         0.4        0.\n",
      " 0.45454545 0.55555556 1.         0.25       0.66666667 0.\n",
      " 0.69230769 0.28571429 0.45454545 0.4        0.125      0.\n",
      " 0.625      0.         0.11111111 0.28571429 0.         0.\n",
      " 0.38461538 0.         0.5        0.         0.33333333 0.75\n",
      " 0.5        0.         0.375      0.16666667 0.         0.\n",
      " 0.33333333 0.         0.625      0.         0.22222222 0.55555556\n",
      " 0.25       0.5        0.33333333 0.75       0.28571429 0.21428571\n",
      " 0.33333333 0.2        0.33333333 0.33333333 0.22222222 0.22222222\n",
      " 0.22222222 0.33333333 0.         0.         0.2        0.4\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.21445221 0.         0.45       0.20833333 0.50793651 0.4\n",
      " 0.45238095 0.         0.45       0.         0.         0.375\n",
      " 0.53289474 0.         0.55555556 0.14583333 0.29166667 0.25\n",
      " 0.         0.3        0.24375    0.3        0.3        0.51923077\n",
      " 0.         0.         0.63636364 0.8        0.20535714 0.45\n",
      " 0.         0.4        0.21590909 0.36428571 0.65384615 0.525\n",
      " 0.35714286 0.         0.675      0.         0.625      0.2\n",
      " 0.33333333 0.58928571 0.76190476 0.63333333 0.41666667 0.375\n",
      " 0.32142857 0.         0.         0.         0.69444444 0.32142857\n",
      " 0.         0.55       1.         0.51515152 0.47916667 0.4375\n",
      " 0.64285714 0.66818182 0.375      0.57272727 0.375      0.63492063\n",
      " 0.44919786 0.60606061 0.72222222 0.         0.50480769 0.53333333\n",
      " 0.         0.23809524 0.27777778 0.18333333 0.625      0.51428571\n",
      " 0.         1.         0.53571429 0.70833333 0.7        0.29166667\n",
      " 0.6875     0.4        0.36666667 0.         0.40178571 0.51428571\n",
      " 0.625      0.225      0.27777778 0.33333333 0.14583333 0.\n",
      " 0.45       0.45833333 0.         0.53076923 0.16666667 0.42857143\n",
      " 0.         0.25       0.40151515 0.2254902  0.34285714 0.83333333\n",
      " 0.48611111 0.11688312 0.19642857 0.36666667 0.46753247 0.23611111\n",
      " 0.34285714 0.19642857 0.         0.42424242 0.8        0.\n",
      " 0.45       0.31666667 0.36428571 0.375      0.41666667 0.49107143\n",
      " 0.32967033 0.63333333 0.         0.625      0.         0.60661765\n",
      " 0.66666667 0.73333333 0.66666667 0.4875     0.51764706 0.\n",
      " 0.71428571 0.2        0.36666667 0.         0.4        0.\n",
      " 0.58441558 0.63492063 0.6875     0.1875     0.4        0.\n",
      " 0.66758242 0.34285714 0.45454545 0.28333333 0.13392857 0.\n",
      " 0.66964286 0.         0.18055556 0.47619048 0.         0.\n",
      " 0.50480769 0.         0.5        0.         0.66666667 0.58928571\n",
      " 0.28571429 0.         0.375      0.28333333 0.         0.\n",
      " 0.33333333 0.         0.625      0.         0.61111111 0.50505051\n",
      " 0.225      0.58333333 0.66666667 0.69642857 0.47619048 0.29464286\n",
      " 0.5        0.225      0.41666667 0.27777778 0.25396825 0.2020202\n",
      " 0.36111111 0.26666667 0.         0.         0.6        0.34285714\n",
      " 0.75       0.68571429]\n",
      "mini_batch 300\n",
      "mini_batch 301\n",
      "mini_batch 302\n",
      "mini_batch 303\n",
      "mini_batch 304\n",
      "mini_batch 305\n",
      "mini_batch 306\n",
      "mini_batch 307\n",
      "mini_batch 308\n",
      "mini_batch 309\n",
      "mini_batch 310\n",
      "mini_batch 311\n",
      "mini_batch 312\n",
      "mini_batch 313\n",
      "mini_batch 314\n",
      "mini_batch 315\n",
      "mini_batch 316\n",
      "mini_batch 317\n",
      "mini_batch 318\n",
      "mini_batch 319\n",
      "mini_batch 320\n",
      "mini_batch 321\n",
      "mini_batch 322\n",
      "mini_batch 323\n",
      "mini_batch 324\n",
      "mini_batch 325\n",
      "mini_batch 326\n",
      "mini_batch 327\n",
      "mini_batch 328\n",
      "mini_batch 329\n",
      "mini_batch 330\n",
      "mini_batch 331\n",
      "mini_batch 332\n",
      "mini_batch 333\n",
      "mini_batch 334\n",
      "mini_batch 335\n",
      "mini_batch 336\n",
      "mini_batch 337\n",
      "mini_batch 338\n",
      "mini_batch 339\n",
      "mini_batch 340\n",
      "mini_batch 341\n",
      "mini_batch 342\n",
      "mini_batch 343\n",
      "mini_batch 344\n",
      "mini_batch 345\n",
      "mini_batch 346\n",
      "mini_batch 347\n",
      "mini_batch 348\n",
      "mini_batch 349\n",
      "Epoch 3\n",
      "average minibatch 350 loss: 1.792\n",
      "\n",
      "Labels:  tensor([ 14,  71,  98,  36, 177, 130,  69, 147,  93,  43, 132,  92, 127, 135,\n",
      "        164,  74,   3,  45,  58, 194, 111,  47, 190, 169, 179,  22, 117,  77,\n",
      "         68, 114,  55,  49,  30, 170,  67, 169,  71, 180,  69, 197, 146,  32,\n",
      "        153,  27,  18,  49, 112, 113, 173,  23,  63, 152, 142,   4, 128,  41,\n",
      "         43,  89,  38, 105,  53,  87,  48, 103], device='cuda:0')\n",
      "Output:  tensor([ 14,  71,  48,  36, 177, 130,  69, 147,  89,  43, 132,  92, 127, 135,\n",
      "        164,  74,  59,  50, 112, 147, 111,  47, 190, 169, 179, 109,  53,  58,\n",
      "         68, 172,  99,  49, 179, 170,  67, 169,  71,  87,  69, 197, 146,  32,\n",
      "        153, 129,  18,  49, 112, 113, 109, 126,  63, 152,  59,  83,  27,  17,\n",
      "        134, 132,  29, 105,  53,  87,  48,   6], device='cuda:0')\n",
      "True Positives:  [ 4.  0.  2.  1.  4.  2.  4.  0.  4.  0.  0.  1.  6.  1.  5.  1.  2.  2.\n",
      "  0.  1.  3.  3.  2.  7.  0.  0.  7.  3.  2.  2.  0.  3.  2.  3.  4.  5.\n",
      "  8.  0.  3.  0.  3.  1.  2.  3.  6.  6.  2.  3.  3.  0.  0.  0.  6.  1.\n",
      "  0.  3.  2.  8.  5.  3.  2.  7.  3.  6.  3.  5.  7.  7.  6.  0.  7.  4.\n",
      "  0.  2.  2.  1.  1.  3.  0.  1.  4.  6.  2.  1.  3.  2.  3.  0.  3.  3.\n",
      "  1.  2.  2.  1.  1.  0.  2.  2.  0.  6.  1.  4.  0.  1.  7.  2.  2.  2.\n",
      "  7.  1.  2.  3.  5.  2.  2.  1.  0.  2.  4.  0.  2.  3.  3.  2.  3.  5.\n",
      "  4.  6.  0.  4.  0. 11.  2.  4.  3.  3.  4.  0.  3.  1.  2.  0.  2.  0.\n",
      "  5.  6.  4.  1.  2.  0.  9.  3.  6.  2.  1.  0.  5.  0.  1.  2.  0.  0.\n",
      "  5.  1.  1.  0.  1.  3.  3.  1.  3.  2.  0.  0.  2.  0.  6.  0.  5.  5.\n",
      "  1.  2.  1.  9.  2.  3.  2.  1.  2.  3.  2.  2.  2.  2.  0.  0.  2.  2.\n",
      "  1.  4.]\n",
      "False Positives:  [29.  1.  3.  5.  5.  4.  8.  3.  4.  3.  1.  1. 13.  1.  4.  7.  5.  5.\n",
      "  0.  1. 13.  7.  8.  7.  1.  0.  5.  2. 15.  2.  0.  3.  9.  4.  9. 12.\n",
      " 16.  6.  1.  1.  1.  4.  2.  1.  3.  3.  1.  3.  1.  1.  2.  0.  2.  1.\n",
      "  1.  2.  0. 15. 12.  3.  0.  4.  2.  5.  5.  2. 11.  5.  5.  2.  3. 11.\n",
      "  0.  6.  7.  4.  0.  2.  0.  0.  3.  3.  1.  2.  0.  3.  4.  2.  5.  4.\n",
      "  0.  3.  4.  1.  7.  0.  2.  6.  4.  7.  5.  3.  3.  2. 38. 15.  5.  0.\n",
      " 13.  6.  3.  4.  3.  7.  3.  3.  1.  9.  1.  1.  2.  6.  4.  6.  6. 10.\n",
      "  4.  3.  1.  3.  1.  7.  1.  2.  1.  5. 13.  0.  4.  4.  4.  2.  3.  2.\n",
      "  2.  2.  6.  7. 13.  0.  5.  3.  6. 10.  6.  2.  2.  1.  3.  1.  2.  0.\n",
      "  3.  4.  1.  0.  0.  4. 13.  1.  5.  4. 11.  1.  4.  0.  3.  2.  1.  6.\n",
      "  4.  1.  0.  5.  1.  5.  1.  3.  2.  7.  5.  9.  2.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  3.  4.  3.  3.  3.  3.  6.  3.  5.  3.  2.  3.  4.  5.  6.  2.\n",
      "  3.  9.  7.  8.  4.  6.  1.  0.  5.  0.  5.  4.  8.  3.  6.  7.  0.  1.\n",
      " 13.  9.  2.  5.  4.  4.  3.  4.  2.  4.  2.  6.  6.  5.  4.  5.  4.  6.\n",
      "  2.  3.  0.  5.  3.  5.  5.  3.  6.  4.  5.  4.  5.  3.  0.  6.  8.  1.\n",
      "  1.  2.  4.  5.  4.  4.  4.  0.  4.  2.  3.  3.  5.  3.  4.  4.  6.  2.\n",
      "  3.  4.  8.  5.  5.  2.  3.  2.  7.  4.  5. 10.  4.  5.  3.  4.  3.  1.\n",
      "  5. 10.  6.  4.  7.  7.  5.  6.  4.  1.  1.  3.  3.  7.  7.  2.  3.  3.\n",
      " 10.  5.  5.  1.  8.  7.  1.  2.  1.  2.  1.  0.  0.  4.  3.  8.  3.  4.\n",
      "  6.  4.  0.  3.  1.  2.  4.  5.  6.  3.  7.  1.  3.  6.  8.  5.  7.  3.\n",
      "  8.  8.  1.  4.  2.  1.  1.  6.  5. 10. 11.  4.  4.  4.  3.  2. 14.  5.\n",
      "  3.  2.  2.  3.  5. 11.  4.  4.  4.  4.  7.  7.  7.  5.  4.  1.  4.  3.\n",
      "  0.  1.]\n",
      "Accuracy:  [0.0625   0.       0.03125  0.015625 0.0625   0.03125  0.0625   0.\n",
      " 0.0625   0.       0.       0.015625 0.09375  0.015625 0.078125 0.015625\n",
      " 0.03125  0.03125  0.       0.015625 0.046875 0.046875 0.03125  0.109375\n",
      " 0.       0.       0.109375 0.046875 0.03125  0.03125  0.       0.046875\n",
      " 0.03125  0.046875 0.0625   0.078125 0.125    0.       0.046875 0.\n",
      " 0.046875 0.015625 0.03125  0.046875 0.09375  0.09375  0.03125  0.046875\n",
      " 0.046875 0.       0.       0.       0.09375  0.015625 0.       0.046875\n",
      " 0.03125  0.125    0.078125 0.046875 0.03125  0.109375 0.046875 0.09375\n",
      " 0.046875 0.078125 0.109375 0.109375 0.09375  0.       0.109375 0.0625\n",
      " 0.       0.03125  0.03125  0.015625 0.015625 0.046875 0.       0.015625\n",
      " 0.0625   0.09375  0.03125  0.015625 0.046875 0.03125  0.046875 0.\n",
      " 0.046875 0.046875 0.015625 0.03125  0.03125  0.015625 0.015625 0.\n",
      " 0.03125  0.03125  0.       0.09375  0.015625 0.0625   0.       0.015625\n",
      " 0.109375 0.03125  0.03125  0.03125  0.109375 0.015625 0.03125  0.046875\n",
      " 0.078125 0.03125  0.03125  0.015625 0.       0.03125  0.0625   0.\n",
      " 0.03125  0.046875 0.046875 0.03125  0.046875 0.078125 0.0625   0.09375\n",
      " 0.       0.0625   0.       0.171875 0.03125  0.0625   0.046875 0.046875\n",
      " 0.0625   0.       0.046875 0.015625 0.03125  0.       0.03125  0.\n",
      " 0.078125 0.09375  0.0625   0.015625 0.03125  0.       0.140625 0.046875\n",
      " 0.09375  0.03125  0.015625 0.       0.078125 0.       0.015625 0.03125\n",
      " 0.       0.       0.078125 0.015625 0.015625 0.       0.015625 0.046875\n",
      " 0.046875 0.015625 0.046875 0.03125  0.       0.       0.03125  0.\n",
      " 0.09375  0.       0.078125 0.078125 0.015625 0.03125  0.015625 0.140625\n",
      " 0.03125  0.046875 0.03125  0.015625 0.03125  0.046875 0.03125  0.03125\n",
      " 0.03125  0.03125  0.       0.       0.03125  0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.12121212 0.         0.4        0.16666667 0.44444444 0.33333333\n",
      " 0.33333333 0.         0.5        0.         0.         0.5\n",
      " 0.31578947 0.5        0.55555556 0.125      0.28571429 0.28571429\n",
      " 0.         0.5        0.1875     0.3        0.2        0.5\n",
      " 0.         0.         0.58333333 0.6        0.11764706 0.5\n",
      " 0.         0.5        0.18181818 0.42857143 0.30769231 0.29411765\n",
      " 0.33333333 0.         0.75       0.         0.75       0.2\n",
      " 0.5        0.75       0.66666667 0.66666667 0.66666667 0.5\n",
      " 0.75       0.         0.         0.         0.75       0.5\n",
      " 0.         0.6        1.         0.34782609 0.29411765 0.5\n",
      " 1.         0.63636364 0.6        0.54545455 0.375      0.71428571\n",
      " 0.38888889 0.58333333 0.54545455 0.         0.7        0.26666667\n",
      " 0.         0.25       0.22222222 0.2        1.         0.6\n",
      " 0.         1.         0.57142857 0.66666667 0.66666667 0.33333333\n",
      " 1.         0.4        0.42857143 0.         0.375      0.42857143\n",
      " 1.         0.4        0.33333333 0.5        0.125      0.\n",
      " 0.5        0.25       0.         0.46153846 0.16666667 0.57142857\n",
      " 0.         0.33333333 0.15555556 0.11764706 0.28571429 1.\n",
      " 0.35       0.14285714 0.4        0.42857143 0.625      0.22222222\n",
      " 0.4        0.25       0.         0.18181818 0.8        0.\n",
      " 0.5        0.33333333 0.42857143 0.25       0.33333333 0.33333333\n",
      " 0.5        0.66666667 0.         0.57142857 0.         0.61111111\n",
      " 0.66666667 0.66666667 0.75       0.375      0.23529412 0.\n",
      " 0.42857143 0.2        0.33333333 0.         0.4        0.\n",
      " 0.71428571 0.75       0.4        0.125      0.13333333 0.\n",
      " 0.64285714 0.5        0.5        0.16666667 0.14285714 0.\n",
      " 0.71428571 0.         0.25       0.66666667 0.         0.\n",
      " 0.625      0.2        0.5        0.         1.         0.42857143\n",
      " 0.1875     0.5        0.375      0.33333333 0.         0.\n",
      " 0.33333333 0.         0.66666667 0.         0.83333333 0.45454545\n",
      " 0.2        0.66666667 1.         0.64285714 0.66666667 0.375\n",
      " 0.66666667 0.25       0.5        0.3        0.28571429 0.18181818\n",
      " 0.5        0.2        0.         0.         1.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.30769231 0.         0.4        0.2        0.57142857 0.4\n",
      " 0.57142857 0.         0.4        0.         0.         0.25\n",
      " 0.75       0.25       0.55555556 0.16666667 0.25       0.5\n",
      " 0.         0.1        0.3        0.27272727 0.33333333 0.53846154\n",
      " 0.         0.         0.58333333 1.         0.28571429 0.33333333\n",
      " 0.         0.5        0.25       0.3        1.         0.83333333\n",
      " 0.38095238 0.         0.6        0.         0.42857143 0.2\n",
      " 0.4        0.42857143 0.75       0.6        0.5        0.33333333\n",
      " 0.33333333 0.         0.         0.         0.6        0.14285714\n",
      " 0.         0.5        1.         0.61538462 0.625      0.375\n",
      " 0.28571429 0.7        0.33333333 0.6        0.375      0.55555556\n",
      " 0.58333333 0.7        1.         0.         0.46666667 0.8\n",
      " 0.         0.5        0.33333333 0.16666667 0.2        0.42857143\n",
      " 0.         1.         0.5        0.75       0.4        0.25\n",
      " 0.375      0.4        0.42857143 0.         0.33333333 0.6\n",
      " 0.25       0.33333333 0.2        0.16666667 0.16666667 0.\n",
      " 0.4        0.5        0.         0.6        0.16666667 0.28571429\n",
      " 0.         0.16666667 0.7        0.33333333 0.4        0.66666667\n",
      " 0.58333333 0.09090909 0.25       0.42857143 0.41666667 0.22222222\n",
      " 0.28571429 0.14285714 0.         0.66666667 0.8        0.\n",
      " 0.4        0.3        0.3        0.5        0.5        0.625\n",
      " 0.28571429 0.54545455 0.         0.8        0.         0.61111111\n",
      " 0.66666667 0.66666667 0.75       0.6        0.8        0.\n",
      " 1.         0.2        0.4        0.         0.4        0.\n",
      " 0.45454545 0.6        1.         0.25       0.66666667 0.\n",
      " 0.69230769 0.375      0.5        0.4        0.125      0.\n",
      " 0.625      0.         0.11111111 0.28571429 0.         0.\n",
      " 0.38461538 0.11111111 0.5        0.         0.33333333 0.75\n",
      " 0.75       0.14285714 0.375      0.16666667 0.         0.\n",
      " 0.33333333 0.         0.66666667 0.         0.26315789 0.5\n",
      " 0.25       0.5        0.33333333 0.75       0.28571429 0.21428571\n",
      " 0.33333333 0.2        0.33333333 0.42857143 0.22222222 0.22222222\n",
      " 0.22222222 0.28571429 0.         0.         0.33333333 0.4\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.21445221 0.         0.4        0.18333333 0.50793651 0.36666667\n",
      " 0.45238095 0.         0.45       0.         0.         0.375\n",
      " 0.53289474 0.375      0.55555556 0.14583333 0.26785714 0.39285714\n",
      " 0.         0.3        0.24375    0.28636364 0.26666667 0.51923077\n",
      " 0.         0.         0.58333333 0.8        0.20168067 0.41666667\n",
      " 0.         0.5        0.21590909 0.36428571 0.65384615 0.56372549\n",
      " 0.35714286 0.         0.675      0.         0.58928571 0.2\n",
      " 0.45       0.58928571 0.70833333 0.63333333 0.58333333 0.41666667\n",
      " 0.54166667 0.         0.         0.         0.675      0.32142857\n",
      " 0.         0.55       1.         0.48160535 0.45955882 0.4375\n",
      " 0.64285714 0.66818182 0.46666667 0.57272727 0.375      0.63492063\n",
      " 0.48611111 0.64166667 0.77272727 0.         0.58333333 0.53333333\n",
      " 0.         0.375      0.27777778 0.18333333 0.6        0.51428571\n",
      " 0.         1.         0.53571429 0.70833333 0.53333333 0.29166667\n",
      " 0.6875     0.4        0.42857143 0.         0.35416667 0.51428571\n",
      " 0.625      0.36666667 0.26666667 0.33333333 0.14583333 0.\n",
      " 0.45       0.375      0.         0.53076923 0.16666667 0.42857143\n",
      " 0.         0.25       0.42777778 0.2254902  0.34285714 0.83333333\n",
      " 0.46666667 0.11688312 0.325      0.42857143 0.52083333 0.22222222\n",
      " 0.34285714 0.19642857 0.         0.42424242 0.8        0.\n",
      " 0.45       0.31666667 0.36428571 0.375      0.41666667 0.47916667\n",
      " 0.39285714 0.60606061 0.         0.68571429 0.         0.61111111\n",
      " 0.66666667 0.66666667 0.75       0.4875     0.51764706 0.\n",
      " 0.71428571 0.2        0.36666667 0.         0.4        0.\n",
      " 0.58441558 0.675      0.7        0.1875     0.4        0.\n",
      " 0.66758242 0.4375     0.5        0.28333333 0.13392857 0.\n",
      " 0.66964286 0.         0.18055556 0.47619048 0.         0.\n",
      " 0.50480769 0.15555556 0.5        0.         0.66666667 0.58928571\n",
      " 0.46875    0.32142857 0.375      0.25       0.         0.\n",
      " 0.33333333 0.         0.66666667 0.         0.54824561 0.47727273\n",
      " 0.225      0.58333333 0.66666667 0.69642857 0.47619048 0.29464286\n",
      " 0.5        0.225      0.41666667 0.36428571 0.25396825 0.2020202\n",
      " 0.36111111 0.24285714 0.         0.         0.66666667 0.34285714\n",
      " 0.75       0.68571429]\n",
      "mini_batch 350\n",
      "mini_batch 351\n",
      "mini_batch 352\n",
      "mini_batch 353\n",
      "mini_batch 354\n",
      "mini_batch 355\n",
      "mini_batch 356\n",
      "mini_batch 357\n",
      "mini_batch 358\n",
      "mini_batch 359\n",
      "mini_batch 360\n",
      "mini_batch 361\n",
      "mini_batch 362\n",
      "mini_batch 363\n",
      "mini_batch 364\n",
      "mini_batch 365\n",
      "mini_batch 366\n",
      "mini_batch 367\n",
      "mini_batch 368\n",
      "mini_batch 369\n",
      "mini_batch 370\n",
      "mini_batch 371\n",
      "mini_batch 372\n",
      "mini_batch 373\n",
      "mini_batch 374\n",
      "mini_batch 375\n",
      "Finished 3 epochs of training\n",
      "mini_batch 0\n",
      "mini_batch 1\n",
      "mini_batch 2\n",
      "mini_batch 3\n",
      "mini_batch 4\n",
      "mini_batch 5\n",
      "mini_batch 6\n",
      "mini_batch 7\n",
      "mini_batch 8\n",
      "mini_batch 9\n",
      "mini_batch 10\n",
      "mini_batch 11\n",
      "mini_batch 12\n",
      "mini_batch 13\n",
      "mini_batch 14\n",
      "mini_batch 15\n",
      "mini_batch 16\n",
      "mini_batch 17\n",
      "mini_batch 18\n",
      "mini_batch 19\n",
      "mini_batch 20\n",
      "mini_batch 21\n",
      "mini_batch 22\n",
      "mini_batch 23\n",
      "mini_batch 24\n",
      "mini_batch 25\n",
      "mini_batch 26\n",
      "mini_batch 27\n",
      "mini_batch 28\n",
      "mini_batch 29\n",
      "mini_batch 30\n",
      "mini_batch 31\n",
      "mini_batch 32\n",
      "mini_batch 33\n",
      "mini_batch 34\n",
      "mini_batch 35\n",
      "mini_batch 36\n",
      "mini_batch 37\n",
      "mini_batch 38\n",
      "mini_batch 39\n",
      "mini_batch 40\n",
      "mini_batch 41\n",
      "mini_batch 42\n",
      "mini_batch 43\n",
      "mini_batch 44\n",
      "mini_batch 45\n",
      "mini_batch 46\n",
      "mini_batch 47\n",
      "mini_batch 48\n",
      "mini_batch 49\n",
      "Epoch 4\n",
      "average minibatch 50 loss: 1.352\n",
      "\n",
      "Labels:  tensor([193, 198, 173,  16, 108, 106, 100, 159, 154, 200, 163,   7, 130,   9,\n",
      "        122,  88,   1,  30, 105,  17,  33,  55, 110,  31,  60,  39, 170, 151,\n",
      "        194,  35, 171,  24,  82, 112,  11, 152,  97, 130, 121, 114,  29, 139,\n",
      "         21, 119, 146, 192, 194,  22, 165, 121,  79, 185,  16, 106, 132,  64,\n",
      "         36, 103,  83,  64,  40,  29, 189, 101], device='cuda:0')\n",
      "Output:  tensor([ 92, 131, 173,  16, 108, 106, 100, 159, 154, 109, 163,  65, 130,  86,\n",
      "        122,  88,   1,  30, 105,  17, 189,  37,  85, 104,  60,  39, 170, 151,\n",
      "        194,  13, 171,  67,  82,  81,  11, 175,  97, 130, 121, 116,  29, 175,\n",
      "         74, 119, 146,  28, 175,  22, 192, 121, 109, 132, 182, 106, 132,  64,\n",
      "         36, 103,   4,  64,  40,  29, 189,  37], device='cuda:0')\n",
      "True Positives:  [ 5.  0.  2.  1.  4.  2.  4.  0.  4.  0.  1.  1.  6.  1.  5.  2.  3.  2.\n",
      "  0.  1.  3.  4.  2.  7.  0.  0.  7.  3.  4.  3.  0.  3.  2.  3.  4.  6.\n",
      "  8.  0.  4.  1.  3.  1.  2.  3.  6.  6.  2.  3.  3.  0.  0.  0.  6.  1.\n",
      "  0.  3.  2.  8.  5.  4.  2.  7.  3.  8.  3.  5.  7.  7.  6.  0.  7.  4.\n",
      "  0.  2.  2.  1.  1.  3.  0.  1.  4.  7.  2.  1.  3.  2.  3.  1.  3.  3.\n",
      "  1.  2.  2.  1.  1.  0.  3.  2.  0.  7.  1.  4.  1.  1.  8.  4.  2.  3.\n",
      "  7.  1.  2.  3.  5.  2.  2.  1.  0.  2.  5.  0.  4.  4.  3.  2.  3.  5.\n",
      "  4.  6.  0.  6.  0. 12.  2.  4.  3.  3.  4.  0.  3.  1.  2.  0.  2.  0.\n",
      "  5.  7.  4.  1.  2.  0. 10.  3.  6.  3.  1.  0.  5.  0.  2.  2.  0.  0.\n",
      "  6.  1.  1.  0.  1.  3.  3.  2.  4.  2.  1.  0.  2.  0.  6.  0.  5.  5.\n",
      "  1.  2.  1.  9.  2.  3.  2.  1.  3.  3.  2.  2.  2.  3.  0.  0.  2.  2.\n",
      "  1.  4.]\n",
      "False Positives:  [29.  1.  3.  6.  5.  4.  8.  3.  4.  3.  1.  1. 14.  1.  4.  7.  5.  5.\n",
      "  0.  1. 13.  7.  8.  7.  1.  0.  5.  3. 15.  2.  0.  3.  9.  4.  9. 12.\n",
      " 18.  6.  1.  1.  1.  4.  2.  1.  3.  3.  1.  3.  1.  1.  2.  0.  2.  1.\n",
      "  1.  2.  0. 15. 12.  3.  0.  4.  2.  5.  6.  2. 12.  5.  5.  2.  3. 11.\n",
      "  0.  7.  7.  4.  0.  2.  0.  0.  4.  3.  1.  2.  1.  4.  4.  2.  5.  4.\n",
      "  0.  4.  4.  1.  7.  0.  2.  6.  4.  7.  5.  3.  3.  3. 38. 15.  5.  0.\n",
      " 15.  6.  3.  4.  3.  7.  3.  4.  1.  9.  1.  1.  2.  6.  4.  6.  6. 10.\n",
      "  4.  3.  1.  3.  2.  8.  1.  2.  1.  5. 13.  0.  4.  4.  4.  2.  3.  2.\n",
      "  2.  2.  6.  7. 13.  0.  5.  3.  6. 10.  6.  2.  2.  1.  3.  1.  2.  0.\n",
      "  3.  4.  1.  0.  0.  4. 13.  1.  5.  4. 11.  1.  7.  0.  3.  2.  1.  6.\n",
      "  4.  2.  0.  5.  1.  5.  1.  3.  3.  7.  5. 10.  2.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  3.  4.  3.  3.  4.  3.  7.  3.  5.  3.  2.  3.  4.  6.  6.  2.\n",
      "  3.  9.  8.  8.  4.  7.  1.  0.  5.  0.  5.  4.  9.  3.  7.  7.  1.  1.\n",
      " 13.  9.  2.  5.  4.  4.  3.  4.  2.  4.  2.  6.  6.  5.  4.  5.  4.  6.\n",
      "  3.  3.  0.  5.  3.  5.  5.  3.  6.  4.  5.  4.  5.  3.  0.  6.  8.  1.\n",
      "  1.  2.  4.  5.  4.  4.  5.  0.  4.  2.  4.  3.  5.  3.  4.  4.  6.  2.\n",
      "  3.  4.  8.  5.  5.  2.  3.  2.  7.  4.  6. 10.  4.  5.  3.  4.  3.  1.\n",
      "  5. 11.  6.  5.  7.  8.  5.  6.  4.  1.  1.  3.  3.  7.  7.  2.  3.  3.\n",
      " 10.  5.  5.  1.  8.  7.  1.  2.  1.  2.  1.  0.  1.  4.  3.  8.  3.  4.\n",
      "  6.  4.  0.  3.  1.  2.  4.  6.  6.  3.  7.  1.  3.  6.  8.  5.  7.  3.\n",
      "  8.  8.  2.  4.  2.  1.  1.  6.  5. 10. 11.  4.  4.  4.  3.  2. 14.  5.\n",
      "  3.  2.  2.  3.  6. 11.  4.  4.  4.  4.  7.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.078125 0.       0.03125  0.015625 0.0625   0.03125  0.0625   0.\n",
      " 0.0625   0.       0.015625 0.015625 0.09375  0.015625 0.078125 0.03125\n",
      " 0.046875 0.03125  0.       0.015625 0.046875 0.0625   0.03125  0.109375\n",
      " 0.       0.       0.109375 0.046875 0.0625   0.046875 0.       0.046875\n",
      " 0.03125  0.046875 0.0625   0.09375  0.125    0.       0.0625   0.015625\n",
      " 0.046875 0.015625 0.03125  0.046875 0.09375  0.09375  0.03125  0.046875\n",
      " 0.046875 0.       0.       0.       0.09375  0.015625 0.       0.046875\n",
      " 0.03125  0.125    0.078125 0.0625   0.03125  0.109375 0.046875 0.125\n",
      " 0.046875 0.078125 0.109375 0.109375 0.09375  0.       0.109375 0.0625\n",
      " 0.       0.03125  0.03125  0.015625 0.015625 0.046875 0.       0.015625\n",
      " 0.0625   0.109375 0.03125  0.015625 0.046875 0.03125  0.046875 0.015625\n",
      " 0.046875 0.046875 0.015625 0.03125  0.03125  0.015625 0.015625 0.\n",
      " 0.046875 0.03125  0.       0.109375 0.015625 0.0625   0.015625 0.015625\n",
      " 0.125    0.0625   0.03125  0.046875 0.109375 0.015625 0.03125  0.046875\n",
      " 0.078125 0.03125  0.03125  0.015625 0.       0.03125  0.078125 0.\n",
      " 0.0625   0.0625   0.046875 0.03125  0.046875 0.078125 0.0625   0.09375\n",
      " 0.       0.09375  0.       0.1875   0.03125  0.0625   0.046875 0.046875\n",
      " 0.0625   0.       0.046875 0.015625 0.03125  0.       0.03125  0.\n",
      " 0.078125 0.109375 0.0625   0.015625 0.03125  0.       0.15625  0.046875\n",
      " 0.09375  0.046875 0.015625 0.       0.078125 0.       0.03125  0.03125\n",
      " 0.       0.       0.09375  0.015625 0.015625 0.       0.015625 0.046875\n",
      " 0.046875 0.03125  0.0625   0.03125  0.015625 0.       0.03125  0.\n",
      " 0.09375  0.       0.078125 0.078125 0.015625 0.03125  0.015625 0.140625\n",
      " 0.03125  0.046875 0.03125  0.015625 0.046875 0.046875 0.03125  0.03125\n",
      " 0.03125  0.046875 0.       0.       0.03125  0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.14705882 0.         0.4        0.14285714 0.44444444 0.33333333\n",
      " 0.33333333 0.         0.5        0.         0.5        0.5\n",
      " 0.3        0.5        0.55555556 0.22222222 0.375      0.28571429\n",
      " 0.         0.5        0.1875     0.36363636 0.2        0.5\n",
      " 0.         0.         0.58333333 0.5        0.21052632 0.6\n",
      " 0.         0.5        0.18181818 0.42857143 0.30769231 0.33333333\n",
      " 0.30769231 0.         0.8        0.5        0.75       0.2\n",
      " 0.5        0.75       0.66666667 0.66666667 0.66666667 0.5\n",
      " 0.75       0.         0.         0.         0.75       0.5\n",
      " 0.         0.6        1.         0.34782609 0.29411765 0.57142857\n",
      " 1.         0.63636364 0.6        0.61538462 0.33333333 0.71428571\n",
      " 0.36842105 0.58333333 0.54545455 0.         0.7        0.26666667\n",
      " 0.         0.22222222 0.22222222 0.2        1.         0.6\n",
      " 0.         1.         0.5        0.7        0.66666667 0.33333333\n",
      " 0.75       0.33333333 0.42857143 0.33333333 0.375      0.42857143\n",
      " 1.         0.33333333 0.33333333 0.5        0.125      0.\n",
      " 0.6        0.25       0.         0.5        0.16666667 0.57142857\n",
      " 0.25       0.25       0.17391304 0.21052632 0.28571429 1.\n",
      " 0.31818182 0.14285714 0.4        0.42857143 0.625      0.22222222\n",
      " 0.4        0.2        0.         0.18181818 0.83333333 0.\n",
      " 0.66666667 0.4        0.42857143 0.25       0.33333333 0.33333333\n",
      " 0.5        0.66666667 0.         0.66666667 0.         0.6\n",
      " 0.66666667 0.66666667 0.75       0.375      0.23529412 0.\n",
      " 0.42857143 0.2        0.33333333 0.         0.4        0.\n",
      " 0.71428571 0.77777778 0.4        0.125      0.13333333 0.\n",
      " 0.66666667 0.5        0.5        0.23076923 0.14285714 0.\n",
      " 0.71428571 0.         0.4        0.66666667 0.         0.\n",
      " 0.66666667 0.2        0.5        0.         1.         0.42857143\n",
      " 0.1875     0.66666667 0.44444444 0.33333333 0.08333333 0.\n",
      " 0.22222222 0.         0.66666667 0.         0.83333333 0.45454545\n",
      " 0.2        0.5        1.         0.64285714 0.66666667 0.375\n",
      " 0.66666667 0.25       0.5        0.3        0.28571429 0.16666667\n",
      " 0.5        0.27272727 0.         0.         1.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.35714286 0.         0.4        0.2        0.57142857 0.4\n",
      " 0.5        0.         0.36363636 0.         0.16666667 0.25\n",
      " 0.75       0.25       0.55555556 0.25       0.33333333 0.5\n",
      " 0.         0.1        0.27272727 0.33333333 0.33333333 0.5\n",
      " 0.         0.         0.58333333 1.         0.44444444 0.42857143\n",
      " 0.         0.5        0.22222222 0.3        0.8        0.85714286\n",
      " 0.38095238 0.         0.66666667 0.16666667 0.42857143 0.2\n",
      " 0.4        0.42857143 0.75       0.6        0.5        0.33333333\n",
      " 0.33333333 0.         0.         0.         0.6        0.14285714\n",
      " 0.         0.5        1.         0.61538462 0.625      0.44444444\n",
      " 0.28571429 0.7        0.33333333 0.66666667 0.375      0.55555556\n",
      " 0.58333333 0.7        1.         0.         0.46666667 0.8\n",
      " 0.         0.5        0.33333333 0.16666667 0.2        0.42857143\n",
      " 0.         1.         0.5        0.77777778 0.33333333 0.25\n",
      " 0.375      0.4        0.42857143 0.2        0.33333333 0.6\n",
      " 0.25       0.33333333 0.2        0.16666667 0.16666667 0.\n",
      " 0.5        0.5        0.         0.63636364 0.14285714 0.28571429\n",
      " 0.2        0.16666667 0.72727273 0.5        0.4        0.75\n",
      " 0.58333333 0.08333333 0.25       0.375      0.41666667 0.2\n",
      " 0.28571429 0.14285714 0.         0.66666667 0.83333333 0.\n",
      " 0.57142857 0.36363636 0.3        0.5        0.5        0.625\n",
      " 0.28571429 0.54545455 0.         0.85714286 0.         0.63157895\n",
      " 0.66666667 0.66666667 0.75       0.6        0.8        0.\n",
      " 0.75       0.2        0.4        0.         0.4        0.\n",
      " 0.45454545 0.63636364 1.         0.25       0.66666667 0.\n",
      " 0.71428571 0.33333333 0.5        0.5        0.125      0.\n",
      " 0.625      0.         0.2        0.28571429 0.         0.\n",
      " 0.42857143 0.11111111 0.33333333 0.         0.33333333 0.75\n",
      " 0.75       0.25       0.44444444 0.16666667 0.08333333 0.\n",
      " 0.33333333 0.         0.66666667 0.         0.26315789 0.5\n",
      " 0.25       0.5        0.33333333 0.75       0.25       0.21428571\n",
      " 0.33333333 0.2        0.42857143 0.42857143 0.22222222 0.2\n",
      " 0.2        0.33333333 0.         0.         0.33333333 0.33333333\n",
      " 1.         0.66666667]\n",
      "Balanced Classification Rate:  [0.25210084 0.         0.4        0.17142857 0.50793651 0.36666667\n",
      " 0.41666667 0.         0.43181818 0.         0.33333333 0.375\n",
      " 0.525      0.375      0.55555556 0.23611111 0.35416667 0.39285714\n",
      " 0.         0.3        0.23011364 0.34848485 0.26666667 0.5\n",
      " 0.         0.         0.58333333 0.75       0.32748538 0.51428571\n",
      " 0.         0.5        0.2020202  0.36428571 0.55384615 0.5952381\n",
      " 0.34432234 0.         0.73333333 0.33333333 0.58928571 0.2\n",
      " 0.45       0.58928571 0.70833333 0.63333333 0.58333333 0.41666667\n",
      " 0.54166667 0.         0.         0.         0.675      0.32142857\n",
      " 0.         0.55       1.         0.48160535 0.45955882 0.50793651\n",
      " 0.64285714 0.66818182 0.46666667 0.64102564 0.35416667 0.63492063\n",
      " 0.47587719 0.64166667 0.77272727 0.         0.58333333 0.53333333\n",
      " 0.         0.36111111 0.27777778 0.18333333 0.6        0.51428571\n",
      " 0.         1.         0.5        0.73888889 0.5        0.29166667\n",
      " 0.5625     0.36666667 0.42857143 0.26666667 0.35416667 0.51428571\n",
      " 0.625      0.33333333 0.26666667 0.33333333 0.14583333 0.\n",
      " 0.55       0.375      0.         0.56818182 0.1547619  0.42857143\n",
      " 0.225      0.20833333 0.45059289 0.35526316 0.34285714 0.875\n",
      " 0.45075758 0.11309524 0.325      0.40178571 0.52083333 0.21111111\n",
      " 0.34285714 0.17142857 0.         0.42424242 0.83333333 0.\n",
      " 0.61904762 0.38181818 0.36428571 0.375      0.41666667 0.47916667\n",
      " 0.39285714 0.60606061 0.         0.76190476 0.         0.61578947\n",
      " 0.66666667 0.66666667 0.75       0.4875     0.51764706 0.\n",
      " 0.58928571 0.2        0.36666667 0.         0.4        0.\n",
      " 0.58441558 0.70707071 0.7        0.1875     0.4        0.\n",
      " 0.69047619 0.41666667 0.5        0.36538462 0.13392857 0.\n",
      " 0.66964286 0.         0.3        0.47619048 0.         0.\n",
      " 0.54761905 0.15555556 0.41666667 0.         0.66666667 0.58928571\n",
      " 0.46875    0.45833333 0.44444444 0.25       0.08333333 0.\n",
      " 0.27777778 0.         0.66666667 0.         0.54824561 0.47727273\n",
      " 0.225      0.5        0.66666667 0.69642857 0.45833333 0.29464286\n",
      " 0.5        0.225      0.46428571 0.36428571 0.25396825 0.18333333\n",
      " 0.35       0.3030303  0.         0.         0.66666667 0.30952381\n",
      " 0.75       0.61904762]\n",
      "mini_batch 50\n",
      "mini_batch 51\n",
      "mini_batch 52\n",
      "mini_batch 53\n",
      "mini_batch 54\n",
      "mini_batch 55\n",
      "mini_batch 56\n",
      "mini_batch 57\n",
      "mini_batch 58\n",
      "mini_batch 59\n",
      "mini_batch 60\n",
      "mini_batch 61\n",
      "mini_batch 62\n",
      "mini_batch 63\n",
      "mini_batch 64\n",
      "mini_batch 65\n",
      "mini_batch 66\n",
      "mini_batch 67\n",
      "mini_batch 68\n",
      "mini_batch 69\n",
      "mini_batch 70\n",
      "mini_batch 71\n",
      "mini_batch 72\n",
      "mini_batch 73\n",
      "mini_batch 74\n",
      "mini_batch 75\n",
      "mini_batch 76\n",
      "mini_batch 77\n",
      "mini_batch 78\n",
      "mini_batch 79\n",
      "mini_batch 80\n",
      "mini_batch 81\n",
      "mini_batch 82\n",
      "mini_batch 83\n",
      "mini_batch 84\n",
      "mini_batch 85\n",
      "mini_batch 86\n",
      "mini_batch 87\n",
      "mini_batch 88\n",
      "mini_batch 89\n",
      "mini_batch 90\n",
      "mini_batch 91\n",
      "mini_batch 92\n",
      "mini_batch 93\n",
      "mini_batch 94\n",
      "mini_batch 95\n",
      "mini_batch 96\n",
      "mini_batch 97\n",
      "mini_batch 98\n",
      "mini_batch 99\n",
      "Epoch 4\n",
      "average minibatch 100 loss: 1.381\n",
      "\n",
      "Labels:  tensor([ 21,  82, 114,  12,  20, 109,  63, 107,  69, 105, 128,   1, 109, 108,\n",
      "        106,   7, 142,  64,  44, 159, 139,   9,  80, 158,  60, 197,  64, 119,\n",
      "        191, 160, 128,   1, 130, 190, 189, 144, 118,  62,  35,  74, 184,  60,\n",
      "         71,  86, 168,  65, 186,  85,  21, 104, 164, 196,  28,  15,  75,  22,\n",
      "        184,  65, 188, 119, 146,  21,  45,  53], device='cuda:0')\n",
      "Output:  tensor([158,  82, 114, 192,  20,   1,  63, 107, 186,  85, 174,   1, 120, 108,\n",
      "        106,   7,  71,  64,  44, 131, 139,   9, 165, 158, 183, 197, 160, 142,\n",
      "         13,  38,  98,   1, 130, 190, 189, 144, 118,  62,  35,  74, 184, 173,\n",
      "         71,  86, 168,  65, 186,  85, 107,  40,  86, 196,  28,  15, 106,  22,\n",
      "        184,  13,  24, 119, 146,  21,  45,  53], device='cuda:0')\n",
      "True Positives:  [ 7.  0.  2.  1.  4.  2.  5.  0.  5.  0.  1.  1.  6.  1.  6.  2.  3.  2.\n",
      "  0.  2.  4.  5.  2.  7.  0.  0.  7.  4.  4.  3.  0.  3.  2.  3.  5.  6.\n",
      "  8.  0.  4.  1.  3.  1.  2.  4.  7.  6.  2.  3.  3.  0.  0.  0.  7.  1.\n",
      "  0.  3.  2.  8.  5.  4.  2.  8.  4.  9.  4.  5.  7.  7.  6.  0.  8.  4.\n",
      "  0.  3.  2.  1.  1.  3.  0.  1.  4.  8.  2.  1.  4.  3.  3.  1.  3.  3.\n",
      "  1.  2.  2.  1.  1.  0.  3.  2.  0.  7.  1.  4.  1.  1.  8.  5.  3.  4.\n",
      "  7.  1.  2.  3.  5.  3.  2.  1.  0.  3.  6.  0.  4.  4.  3.  2.  3.  5.\n",
      "  4.  6.  0.  7.  0. 12.  2.  4.  3.  3.  4.  0.  4.  1.  2.  0.  2.  1.\n",
      "  5.  8.  4.  1.  2.  0. 10.  3.  6.  3.  1.  0.  5.  1.  2.  2.  0.  0.\n",
      "  6.  1.  1.  0.  1.  4.  3.  2.  4.  2.  1.  0.  2.  0.  6.  0.  5.  5.\n",
      "  1.  2.  1. 11.  2.  4.  2.  1.  4.  4.  2.  2.  2.  3.  0.  1.  3.  2.\n",
      "  1.  4.]\n",
      "False Positives:  [30.  1.  3.  6.  5.  4.  8.  3.  4.  3.  1.  1. 16.  1.  4.  7.  5.  5.\n",
      "  0.  1. 13.  7.  8.  8.  1.  0.  5.  3. 15.  2.  0.  3.  9.  4.  9. 12.\n",
      " 18.  7.  1.  2.  1.  4.  2.  1.  3.  3.  1.  3.  1.  1.  2.  0.  2.  1.\n",
      "  1.  2.  0. 15. 12.  3.  0.  4.  2.  5.  6.  2. 12.  5.  5.  2.  4. 11.\n",
      "  0.  7.  7.  4.  0.  2.  0.  0.  4.  3.  1.  2.  2.  5.  4.  2.  5.  4.\n",
      "  0.  4.  4.  1.  7.  0.  2.  7.  4.  7.  5.  3.  3.  3. 38. 16.  6.  0.\n",
      " 15.  6.  3.  4.  3.  7.  3.  4.  1.  9.  1.  2.  2.  6.  4.  6.  6. 10.\n",
      "  4.  3.  1.  3.  3.  8.  1.  2.  1.  5. 13.  0.  4.  4.  4.  3.  3.  2.\n",
      "  2.  2.  6.  7. 13.  0.  5.  3.  6. 10.  6.  2.  2.  2.  3.  2.  2.  0.\n",
      "  3.  4.  2.  0.  0.  4. 13.  1.  5.  4. 12.  2.  7.  0.  3.  2.  1.  6.\n",
      "  4.  2.  1.  5.  1.  6.  1.  3.  3.  7.  5. 11.  2.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  3.  4.  3.  3.  4.  3.  7.  3.  5.  4.  2.  3.  4.  6.  6.  2.\n",
      "  3.  9. 10.  8.  4.  7.  1.  0.  5.  0.  5.  4.  9.  3.  7.  7.  1.  1.\n",
      " 13.  9.  2.  5.  4.  4.  3.  4.  2.  4.  2.  6.  6.  5.  4.  5.  4.  6.\n",
      "  3.  3.  0.  5.  3.  7.  5.  3.  6.  5.  6.  4.  5.  3.  1.  6.  8.  1.\n",
      "  1.  2.  5.  5.  4.  4.  5.  1.  4.  2.  4.  3.  5.  3.  4.  4.  6.  2.\n",
      "  3.  4.  8.  5.  5.  2.  3.  2.  7.  4.  6. 10.  4.  6.  4.  4.  3.  1.\n",
      "  7. 11.  6.  5.  7.  8.  5.  6.  4.  1.  2.  3.  3.  7.  7.  2.  3.  3.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  1.  2.  1.  0.  1.  4.  3.  9.  3.  4.\n",
      "  6.  4.  0.  3.  1.  2.  4.  6.  6.  3.  7.  1.  3.  6.  9.  6.  7.  3.\n",
      "  8.  9.  2.  4.  2.  1.  1.  6.  5. 10. 11.  4.  4.  4.  3.  2. 14.  5.\n",
      "  3.  2.  2.  3.  6. 11.  4.  5.  4.  4.  8.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.109375 0.       0.03125  0.015625 0.0625   0.03125  0.078125 0.\n",
      " 0.078125 0.       0.015625 0.015625 0.09375  0.015625 0.09375  0.03125\n",
      " 0.046875 0.03125  0.       0.03125  0.0625   0.078125 0.03125  0.109375\n",
      " 0.       0.       0.109375 0.0625   0.0625   0.046875 0.       0.046875\n",
      " 0.03125  0.046875 0.078125 0.09375  0.125    0.       0.0625   0.015625\n",
      " 0.046875 0.015625 0.03125  0.0625   0.109375 0.09375  0.03125  0.046875\n",
      " 0.046875 0.       0.       0.       0.109375 0.015625 0.       0.046875\n",
      " 0.03125  0.125    0.078125 0.0625   0.03125  0.125    0.0625   0.140625\n",
      " 0.0625   0.078125 0.109375 0.109375 0.09375  0.       0.125    0.0625\n",
      " 0.       0.046875 0.03125  0.015625 0.015625 0.046875 0.       0.015625\n",
      " 0.0625   0.125    0.03125  0.015625 0.0625   0.046875 0.046875 0.015625\n",
      " 0.046875 0.046875 0.015625 0.03125  0.03125  0.015625 0.015625 0.\n",
      " 0.046875 0.03125  0.       0.109375 0.015625 0.0625   0.015625 0.015625\n",
      " 0.125    0.078125 0.046875 0.0625   0.109375 0.015625 0.03125  0.046875\n",
      " 0.078125 0.046875 0.03125  0.015625 0.       0.046875 0.09375  0.\n",
      " 0.0625   0.0625   0.046875 0.03125  0.046875 0.078125 0.0625   0.09375\n",
      " 0.       0.109375 0.       0.1875   0.03125  0.0625   0.046875 0.046875\n",
      " 0.0625   0.       0.0625   0.015625 0.03125  0.       0.03125  0.015625\n",
      " 0.078125 0.125    0.0625   0.015625 0.03125  0.       0.15625  0.046875\n",
      " 0.09375  0.046875 0.015625 0.       0.078125 0.015625 0.03125  0.03125\n",
      " 0.       0.       0.09375  0.015625 0.015625 0.       0.015625 0.0625\n",
      " 0.046875 0.03125  0.0625   0.03125  0.015625 0.       0.03125  0.\n",
      " 0.09375  0.       0.078125 0.078125 0.015625 0.03125  0.015625 0.171875\n",
      " 0.03125  0.0625   0.03125  0.015625 0.0625   0.0625   0.03125  0.03125\n",
      " 0.03125  0.046875 0.       0.015625 0.046875 0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.18918919 0.         0.4        0.14285714 0.44444444 0.33333333\n",
      " 0.38461538 0.         0.55555556 0.         0.5        0.5\n",
      " 0.27272727 0.5        0.6        0.22222222 0.375      0.28571429\n",
      " 0.         0.66666667 0.23529412 0.41666667 0.2        0.46666667\n",
      " 0.         0.         0.58333333 0.57142857 0.21052632 0.6\n",
      " 0.         0.5        0.18181818 0.42857143 0.35714286 0.33333333\n",
      " 0.30769231 0.         0.8        0.33333333 0.75       0.2\n",
      " 0.5        0.8        0.7        0.66666667 0.66666667 0.5\n",
      " 0.75       0.         0.         0.         0.77777778 0.5\n",
      " 0.         0.6        1.         0.34782609 0.29411765 0.57142857\n",
      " 1.         0.66666667 0.66666667 0.64285714 0.4        0.71428571\n",
      " 0.36842105 0.58333333 0.54545455 0.         0.66666667 0.26666667\n",
      " 0.         0.3        0.22222222 0.2        1.         0.6\n",
      " 0.         1.         0.5        0.72727273 0.66666667 0.33333333\n",
      " 0.66666667 0.375      0.42857143 0.33333333 0.375      0.42857143\n",
      " 1.         0.33333333 0.33333333 0.5        0.125      0.\n",
      " 0.6        0.22222222 0.         0.5        0.16666667 0.57142857\n",
      " 0.25       0.25       0.17391304 0.23809524 0.33333333 1.\n",
      " 0.31818182 0.14285714 0.4        0.42857143 0.625      0.3\n",
      " 0.4        0.2        0.         0.25       0.85714286 0.\n",
      " 0.66666667 0.4        0.42857143 0.25       0.33333333 0.33333333\n",
      " 0.5        0.66666667 0.         0.7        0.         0.6\n",
      " 0.66666667 0.66666667 0.75       0.375      0.23529412 0.\n",
      " 0.5        0.2        0.33333333 0.         0.4        0.33333333\n",
      " 0.71428571 0.8        0.4        0.125      0.13333333 0.\n",
      " 0.66666667 0.5        0.5        0.23076923 0.14285714 0.\n",
      " 0.71428571 0.33333333 0.4        0.5        0.         0.\n",
      " 0.66666667 0.2        0.33333333 0.         1.         0.5\n",
      " 0.1875     0.66666667 0.44444444 0.33333333 0.07692308 0.\n",
      " 0.22222222 0.         0.66666667 0.         0.83333333 0.45454545\n",
      " 0.2        0.5        0.5        0.6875     0.66666667 0.4\n",
      " 0.66666667 0.25       0.57142857 0.36363636 0.28571429 0.15384615\n",
      " 0.5        0.27272727 0.         0.25       1.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.4375     0.         0.4        0.2        0.57142857 0.4\n",
      " 0.55555556 0.         0.41666667 0.         0.16666667 0.2\n",
      " 0.75       0.25       0.6        0.25       0.33333333 0.5\n",
      " 0.         0.18181818 0.28571429 0.38461538 0.33333333 0.5\n",
      " 0.         0.         0.58333333 1.         0.44444444 0.42857143\n",
      " 0.         0.5        0.22222222 0.3        0.83333333 0.85714286\n",
      " 0.38095238 0.         0.66666667 0.16666667 0.42857143 0.2\n",
      " 0.4        0.5        0.77777778 0.6        0.5        0.33333333\n",
      " 0.33333333 0.         0.         0.         0.63636364 0.14285714\n",
      " 0.         0.5        1.         0.61538462 0.625      0.36363636\n",
      " 0.28571429 0.72727273 0.4        0.64285714 0.4        0.55555556\n",
      " 0.58333333 0.7        0.85714286 0.         0.5        0.8\n",
      " 0.         0.6        0.28571429 0.16666667 0.2        0.42857143\n",
      " 0.         0.5        0.5        0.8        0.33333333 0.25\n",
      " 0.44444444 0.5        0.42857143 0.2        0.33333333 0.6\n",
      " 0.25       0.33333333 0.2        0.16666667 0.16666667 0.\n",
      " 0.5        0.5        0.         0.63636364 0.14285714 0.28571429\n",
      " 0.2        0.14285714 0.66666667 0.55555556 0.5        0.8\n",
      " 0.5        0.08333333 0.25       0.375      0.41666667 0.27272727\n",
      " 0.28571429 0.14285714 0.         0.75       0.75       0.\n",
      " 0.57142857 0.36363636 0.3        0.5        0.5        0.625\n",
      " 0.28571429 0.46153846 0.         0.875      0.         0.63157895\n",
      " 0.66666667 0.66666667 0.75       0.6        0.8        0.\n",
      " 0.8        0.2        0.4        0.         0.4        0.2\n",
      " 0.45454545 0.66666667 1.         0.25       0.66666667 0.\n",
      " 0.71428571 0.33333333 0.5        0.5        0.125      0.\n",
      " 0.625      0.14285714 0.18181818 0.25       0.         0.\n",
      " 0.42857143 0.1        0.33333333 0.         0.33333333 0.8\n",
      " 0.75       0.25       0.44444444 0.16666667 0.08333333 0.\n",
      " 0.33333333 0.         0.66666667 0.         0.26315789 0.5\n",
      " 0.25       0.5        0.33333333 0.78571429 0.25       0.26666667\n",
      " 0.33333333 0.16666667 0.5        0.5        0.2        0.2\n",
      " 0.2        0.33333333 0.         0.5        0.42857143 0.33333333\n",
      " 1.         0.66666667]\n",
      "Balanced Classification Rate:  [0.31334459 0.         0.4        0.17142857 0.50793651 0.36666667\n",
      " 0.47008547 0.         0.48611111 0.         0.33333333 0.35\n",
      " 0.51136364 0.375      0.6        0.23611111 0.35416667 0.39285714\n",
      " 0.         0.42424242 0.2605042  0.40064103 0.26666667 0.48333333\n",
      " 0.         0.         0.58333333 0.78571429 0.32748538 0.51428571\n",
      " 0.         0.5        0.2020202  0.36428571 0.5952381  0.5952381\n",
      " 0.34432234 0.         0.73333333 0.25       0.58928571 0.2\n",
      " 0.45       0.65       0.73888889 0.63333333 0.58333333 0.41666667\n",
      " 0.54166667 0.         0.         0.         0.70707071 0.32142857\n",
      " 0.         0.55       1.         0.48160535 0.45955882 0.46753247\n",
      " 0.64285714 0.6969697  0.53333333 0.64285714 0.4        0.63492063\n",
      " 0.47587719 0.64166667 0.7012987  0.         0.58333333 0.53333333\n",
      " 0.         0.45       0.25396825 0.18333333 0.6        0.51428571\n",
      " 0.         0.75       0.5        0.76363636 0.5        0.29166667\n",
      " 0.55555556 0.4375     0.42857143 0.26666667 0.35416667 0.51428571\n",
      " 0.625      0.33333333 0.26666667 0.33333333 0.14583333 0.\n",
      " 0.55       0.36111111 0.         0.56818182 0.1547619  0.42857143\n",
      " 0.225      0.19642857 0.42028986 0.3968254  0.41666667 0.9\n",
      " 0.40909091 0.11309524 0.325      0.40178571 0.52083333 0.28636364\n",
      " 0.34285714 0.17142857 0.         0.5        0.80357143 0.\n",
      " 0.61904762 0.38181818 0.36428571 0.375      0.41666667 0.47916667\n",
      " 0.39285714 0.56410256 0.         0.7875     0.         0.61578947\n",
      " 0.66666667 0.66666667 0.75       0.4875     0.51764706 0.\n",
      " 0.65       0.2        0.36666667 0.         0.4        0.26666667\n",
      " 0.58441558 0.73333333 0.7        0.1875     0.4        0.\n",
      " 0.69047619 0.41666667 0.5        0.36538462 0.13392857 0.\n",
      " 0.66964286 0.23809524 0.29090909 0.375      0.         0.\n",
      " 0.54761905 0.15       0.33333333 0.         0.66666667 0.65\n",
      " 0.46875    0.45833333 0.44444444 0.25       0.08012821 0.\n",
      " 0.27777778 0.         0.66666667 0.         0.54824561 0.47727273\n",
      " 0.225      0.5        0.41666667 0.73660714 0.45833333 0.33333333\n",
      " 0.5        0.20833333 0.53571429 0.43181818 0.24285714 0.17692308\n",
      " 0.35       0.3030303  0.         0.375      0.71428571 0.30952381\n",
      " 0.75       0.61904762]\n",
      "mini_batch 100\n",
      "mini_batch 101\n",
      "mini_batch 102\n",
      "mini_batch 103\n",
      "mini_batch 104\n",
      "mini_batch 105\n",
      "mini_batch 106\n",
      "mini_batch 107\n",
      "mini_batch 108\n",
      "mini_batch 109\n",
      "mini_batch 110\n",
      "mini_batch 111\n",
      "mini_batch 112\n",
      "mini_batch 113\n",
      "mini_batch 114\n",
      "mini_batch 115\n",
      "mini_batch 116\n",
      "mini_batch 117\n",
      "mini_batch 118\n",
      "mini_batch 119\n",
      "mini_batch 120\n",
      "mini_batch 121\n",
      "mini_batch 122\n",
      "mini_batch 123\n",
      "mini_batch 124\n",
      "mini_batch 125\n",
      "mini_batch 126\n",
      "mini_batch 127\n",
      "mini_batch 128\n",
      "mini_batch 129\n",
      "mini_batch 130\n",
      "mini_batch 131\n",
      "mini_batch 132\n",
      "mini_batch 133\n",
      "mini_batch 134\n",
      "mini_batch 135\n",
      "mini_batch 136\n",
      "mini_batch 137\n",
      "mini_batch 138\n",
      "mini_batch 139\n",
      "mini_batch 140\n",
      "mini_batch 141\n",
      "mini_batch 142\n",
      "mini_batch 143\n",
      "mini_batch 144\n",
      "mini_batch 145\n",
      "mini_batch 146\n",
      "mini_batch 147\n",
      "mini_batch 148\n",
      "mini_batch 149\n",
      "Epoch 4\n",
      "average minibatch 150 loss: 1.401\n",
      "\n",
      "Labels:  tensor([121,  93,  44, 132,   9,   9,  71,  48, 141,   5, 100, 151,  95, 113,\n",
      "        146, 163, 123, 119, 173,  81,   1, 168, 185, 126,  36,  36,  64, 109,\n",
      "         22,  93,  15,  69, 126,  71, 154, 103, 143,  12,  66,  74, 162, 157,\n",
      "         32, 153,   5, 169, 104,  14, 166, 169,  65,  22, 118,  51, 175,  56,\n",
      "         90,  83, 106, 168,  23, 114, 191,  88], device='cuda:0')\n",
      "Output:  tensor([121,  63,  44, 132,  57,   9,  71, 159,  78,   5, 100, 132,  95, 113,\n",
      "        146, 163,  15, 119, 173,  81,   1, 168, 185, 126,  36, 147, 125,  51,\n",
      "         22,  74,   9,  69, 192,  57, 154, 103, 141,  12,  67,  74,  63, 157,\n",
      "        138, 153,  56,  12, 104,  30, 166,  35,  65, 125, 118,  80, 175,  56,\n",
      "         90,  83,  34, 168, 141, 114,  80,  74], device='cuda:0')\n",
      "True Positives:  [ 8.  0.  2.  1.  5.  2.  5.  0.  6.  0.  1.  2.  6.  1.  6.  2.  3.  2.\n",
      "  0.  2.  4.  6.  2.  7.  0.  0.  7.  4.  4.  3.  0.  3.  2.  3.  5.  7.\n",
      "  8.  0.  4.  1.  3.  1.  2.  5.  7.  6.  2.  3.  3.  0.  0.  0.  7.  1.\n",
      "  0.  4.  2.  8.  5.  4.  2.  8.  4.  9.  5.  5.  7.  7.  7.  0.  9.  4.\n",
      "  0.  4.  2.  1.  1.  3.  0.  1.  5.  8.  3.  1.  4.  3.  3.  1.  3.  4.\n",
      "  1.  2.  2.  1.  2.  0.  3.  2.  0.  8.  1.  4.  2.  2.  8.  5.  3.  4.\n",
      "  7.  1.  2.  3.  6.  4.  2.  1.  0.  4.  7.  0.  5.  4.  3.  2.  3.  6.\n",
      "  4.  6.  0.  7.  0. 13.  2.  4.  3.  3.  4.  0.  4.  1.  2.  0.  2.  1.\n",
      "  5.  9.  4.  1.  2.  0. 10.  3.  7.  4.  1.  0.  6.  1.  2.  2.  0.  0.\n",
      "  7.  1.  1.  1.  1.  6.  3.  2.  4.  2.  2.  0.  3.  0.  6.  0.  5.  5.\n",
      "  1.  2.  1. 11.  3.  4.  2.  1.  4.  4.  2.  2.  2.  3.  0.  1.  3.  2.\n",
      "  1.  4.]\n",
      "False Positives:  [30.  1.  3.  6.  5.  4.  8.  3.  5.  3.  1.  2. 16.  1.  5.  7.  5.  5.\n",
      "  0.  1. 13.  7.  8.  8.  1.  0.  5.  3. 15.  3.  0.  3.  9.  5. 10. 12.\n",
      " 18.  7.  1.  2.  1.  4.  2.  1.  3.  3.  1.  3.  1.  1.  3.  0.  2.  1.\n",
      "  1.  3.  2. 15. 12.  3.  0.  4.  4.  5.  6.  2. 13.  5.  5.  2.  4. 11.\n",
      "  0.  9.  7.  4.  0.  3.  0.  2.  4.  3.  1.  2.  2.  5.  4.  2.  5.  4.\n",
      "  0.  4.  4.  1.  7.  0.  2.  7.  4.  7.  5.  3.  3.  3. 38. 16.  6.  0.\n",
      " 15.  6.  3.  4.  3.  7.  3.  4.  1.  9.  1.  2.  2.  6.  4.  6.  8. 10.\n",
      "  4.  3.  1.  3.  3.  9.  1.  2.  1.  5. 13.  1.  4.  4.  6.  3.  3.  2.\n",
      "  2.  2.  7.  7. 13.  0.  5.  3.  6. 10.  6.  2.  2.  2.  4.  2.  2.  0.\n",
      "  3.  4.  2.  0.  0.  4. 13.  1.  5.  4. 12.  2.  7.  0.  3.  2.  1.  6.\n",
      "  4.  2.  1.  5.  1.  6.  1.  3.  3.  7.  5. 12.  2.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  3.  4.  4.  3.  4.  3.  8.  3.  5.  4.  2.  4.  5.  6.  6.  2.\n",
      "  3.  9. 10.  9.  5.  7.  1.  0.  5.  0.  5.  4.  9.  4.  7.  7.  1.  2.\n",
      " 13.  9.  2.  5.  4.  4.  3.  4.  2.  4.  2.  7.  6.  5.  5.  5.  4.  6.\n",
      "  3.  3.  0.  5.  3.  7.  5.  3.  6.  6.  6.  5.  5.  3.  1.  6.  9.  1.\n",
      "  1.  2.  5.  5.  4.  4.  5.  1.  4.  2.  4.  3.  5.  3.  4.  5.  6.  2.\n",
      "  3.  4. 10.  5.  5.  2.  3.  2.  7.  4.  6. 10.  4.  6.  4.  5.  3.  1.\n",
      "  8. 11.  6.  5.  7.  8.  5.  6.  4.  1.  2.  3.  3.  7.  8.  2.  3.  4.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  1.  2.  1.  0.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  0.  3.  1.  2.  5.  6.  6.  3.  7.  1.  3.  6.  9.  6.  7.  4.\n",
      "  8.  9.  2.  4.  2.  1.  3.  6.  5. 10. 11.  4.  4.  4.  3.  2. 14.  5.\n",
      "  3.  2.  2.  3.  6. 11.  4.  5.  4.  4.  9.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.125    0.       0.03125  0.015625 0.078125 0.03125  0.078125 0.\n",
      " 0.09375  0.       0.015625 0.03125  0.09375  0.015625 0.09375  0.03125\n",
      " 0.046875 0.03125  0.       0.03125  0.0625   0.09375  0.03125  0.109375\n",
      " 0.       0.       0.109375 0.0625   0.0625   0.046875 0.       0.046875\n",
      " 0.03125  0.046875 0.078125 0.109375 0.125    0.       0.0625   0.015625\n",
      " 0.046875 0.015625 0.03125  0.078125 0.109375 0.09375  0.03125  0.046875\n",
      " 0.046875 0.       0.       0.       0.109375 0.015625 0.       0.0625\n",
      " 0.03125  0.125    0.078125 0.0625   0.03125  0.125    0.0625   0.140625\n",
      " 0.078125 0.078125 0.109375 0.109375 0.109375 0.       0.140625 0.0625\n",
      " 0.       0.0625   0.03125  0.015625 0.015625 0.046875 0.       0.015625\n",
      " 0.078125 0.125    0.046875 0.015625 0.0625   0.046875 0.046875 0.015625\n",
      " 0.046875 0.0625   0.015625 0.03125  0.03125  0.015625 0.03125  0.\n",
      " 0.046875 0.03125  0.       0.125    0.015625 0.0625   0.03125  0.03125\n",
      " 0.125    0.078125 0.046875 0.0625   0.109375 0.015625 0.03125  0.046875\n",
      " 0.09375  0.0625   0.03125  0.015625 0.       0.0625   0.109375 0.\n",
      " 0.078125 0.0625   0.046875 0.03125  0.046875 0.09375  0.0625   0.09375\n",
      " 0.       0.109375 0.       0.203125 0.03125  0.0625   0.046875 0.046875\n",
      " 0.0625   0.       0.0625   0.015625 0.03125  0.       0.03125  0.015625\n",
      " 0.078125 0.140625 0.0625   0.015625 0.03125  0.       0.15625  0.046875\n",
      " 0.109375 0.0625   0.015625 0.       0.09375  0.015625 0.03125  0.03125\n",
      " 0.       0.       0.109375 0.015625 0.015625 0.015625 0.015625 0.09375\n",
      " 0.046875 0.03125  0.0625   0.03125  0.03125  0.       0.046875 0.\n",
      " 0.09375  0.       0.078125 0.078125 0.015625 0.03125  0.015625 0.171875\n",
      " 0.046875 0.0625   0.03125  0.015625 0.0625   0.0625   0.03125  0.03125\n",
      " 0.03125  0.046875 0.       0.015625 0.046875 0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.21052632 0.         0.4        0.14285714 0.5        0.33333333\n",
      " 0.38461538 0.         0.54545455 0.         0.5        0.5\n",
      " 0.27272727 0.5        0.54545455 0.22222222 0.375      0.28571429\n",
      " 0.         0.66666667 0.23529412 0.46153846 0.2        0.46666667\n",
      " 0.         0.         0.58333333 0.57142857 0.21052632 0.5\n",
      " 0.         0.5        0.18181818 0.375      0.33333333 0.36842105\n",
      " 0.30769231 0.         0.8        0.33333333 0.75       0.2\n",
      " 0.5        0.83333333 0.7        0.66666667 0.66666667 0.5\n",
      " 0.75       0.         0.         0.         0.77777778 0.5\n",
      " 0.         0.57142857 0.5        0.34782609 0.29411765 0.57142857\n",
      " 1.         0.66666667 0.5        0.64285714 0.45454545 0.71428571\n",
      " 0.35       0.58333333 0.58333333 0.         0.69230769 0.26666667\n",
      " 0.         0.30769231 0.22222222 0.2        1.         0.5\n",
      " 0.         0.33333333 0.55555556 0.72727273 0.75       0.33333333\n",
      " 0.66666667 0.375      0.42857143 0.33333333 0.375      0.5\n",
      " 1.         0.33333333 0.33333333 0.5        0.22222222 0.\n",
      " 0.6        0.22222222 0.         0.53333333 0.16666667 0.57142857\n",
      " 0.4        0.4        0.17391304 0.23809524 0.33333333 1.\n",
      " 0.31818182 0.14285714 0.4        0.42857143 0.66666667 0.36363636\n",
      " 0.4        0.2        0.         0.30769231 0.875      0.\n",
      " 0.71428571 0.4        0.42857143 0.25       0.27272727 0.375\n",
      " 0.5        0.66666667 0.         0.7        0.         0.59090909\n",
      " 0.66666667 0.66666667 0.75       0.375      0.23529412 0.\n",
      " 0.5        0.2        0.25       0.         0.4        0.33333333\n",
      " 0.71428571 0.81818182 0.36363636 0.125      0.13333333 0.\n",
      " 0.66666667 0.5        0.53846154 0.28571429 0.14285714 0.\n",
      " 0.75       0.33333333 0.33333333 0.5        0.         0.\n",
      " 0.7        0.2        0.33333333 1.         1.         0.6\n",
      " 0.1875     0.66666667 0.44444444 0.33333333 0.14285714 0.\n",
      " 0.3        0.         0.66666667 0.         0.83333333 0.45454545\n",
      " 0.2        0.5        0.5        0.6875     0.75       0.4\n",
      " 0.66666667 0.25       0.57142857 0.36363636 0.28571429 0.14285714\n",
      " 0.5        0.27272727 0.         0.25       1.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.47058824 0.         0.4        0.2        0.55555556 0.4\n",
      " 0.55555556 0.         0.42857143 0.         0.16666667 0.33333333\n",
      " 0.75       0.2        0.54545455 0.25       0.33333333 0.5\n",
      " 0.         0.18181818 0.28571429 0.4        0.28571429 0.5\n",
      " 0.         0.         0.58333333 1.         0.44444444 0.42857143\n",
      " 0.         0.42857143 0.22222222 0.3        0.83333333 0.77777778\n",
      " 0.38095238 0.         0.66666667 0.16666667 0.42857143 0.2\n",
      " 0.4        0.55555556 0.77777778 0.6        0.5        0.3\n",
      " 0.33333333 0.         0.         0.         0.63636364 0.14285714\n",
      " 0.         0.57142857 1.         0.61538462 0.625      0.36363636\n",
      " 0.28571429 0.72727273 0.4        0.6        0.45454545 0.5\n",
      " 0.58333333 0.7        0.875      0.         0.5        0.8\n",
      " 0.         0.66666667 0.28571429 0.16666667 0.2        0.42857143\n",
      " 0.         0.5        0.55555556 0.8        0.42857143 0.25\n",
      " 0.44444444 0.5        0.42857143 0.16666667 0.33333333 0.66666667\n",
      " 0.25       0.33333333 0.16666667 0.16666667 0.28571429 0.\n",
      " 0.5        0.5        0.         0.66666667 0.14285714 0.28571429\n",
      " 0.33333333 0.25       0.66666667 0.5        0.5        0.8\n",
      " 0.46666667 0.08333333 0.25       0.375      0.46153846 0.33333333\n",
      " 0.28571429 0.14285714 0.         0.8        0.77777778 0.\n",
      " 0.625      0.36363636 0.27272727 0.5        0.5        0.6\n",
      " 0.28571429 0.46153846 0.         0.875      0.         0.65\n",
      " 0.66666667 0.66666667 0.75       0.6        0.8        0.\n",
      " 0.8        0.2        0.33333333 0.         0.33333333 0.2\n",
      " 0.45454545 0.69230769 1.         0.25       0.66666667 0.\n",
      " 0.66666667 0.33333333 0.53846154 0.57142857 0.125      0.\n",
      " 0.66666667 0.14285714 0.18181818 0.25       0.         0.\n",
      " 0.46666667 0.1        0.33333333 0.2        0.33333333 0.85714286\n",
      " 0.5        0.25       0.44444444 0.16666667 0.15384615 0.\n",
      " 0.42857143 0.         0.66666667 0.         0.26315789 0.5\n",
      " 0.25       0.5        0.33333333 0.78571429 0.33333333 0.26666667\n",
      " 0.33333333 0.16666667 0.5        0.5        0.18181818 0.2\n",
      " 0.2        0.33333333 0.         0.5        0.42857143 0.33333333\n",
      " 1.         0.66666667]\n",
      "Balanced Classification Rate:  [0.34055728 0.         0.4        0.17142857 0.52777778 0.36666667\n",
      " 0.47008547 0.         0.48701299 0.         0.33333333 0.41666667\n",
      " 0.51136364 0.35       0.54545455 0.23611111 0.35416667 0.39285714\n",
      " 0.         0.42424242 0.2605042  0.43076923 0.24285714 0.48333333\n",
      " 0.         0.         0.58333333 0.78571429 0.32748538 0.46428571\n",
      " 0.         0.46428571 0.2020202  0.3375     0.58333333 0.57309942\n",
      " 0.34432234 0.         0.73333333 0.25       0.58928571 0.2\n",
      " 0.45       0.69444444 0.73888889 0.63333333 0.58333333 0.4\n",
      " 0.54166667 0.         0.         0.         0.70707071 0.32142857\n",
      " 0.         0.57142857 0.75       0.48160535 0.45955882 0.46753247\n",
      " 0.64285714 0.6969697  0.45       0.62142857 0.45454545 0.60714286\n",
      " 0.46666667 0.64166667 0.72916667 0.         0.59615385 0.53333333\n",
      " 0.         0.48717949 0.25396825 0.18333333 0.6        0.46428571\n",
      " 0.         0.41666667 0.55555556 0.76363636 0.58928571 0.29166667\n",
      " 0.55555556 0.4375     0.42857143 0.25       0.35416667 0.58333333\n",
      " 0.625      0.33333333 0.25       0.33333333 0.25396825 0.\n",
      " 0.55       0.36111111 0.         0.6        0.1547619  0.42857143\n",
      " 0.36666667 0.325      0.42028986 0.36904762 0.41666667 0.9\n",
      " 0.39242424 0.11309524 0.325      0.40178571 0.56410256 0.34848485\n",
      " 0.34285714 0.17142857 0.         0.55384615 0.82638889 0.\n",
      " 0.66964286 0.38181818 0.35064935 0.375      0.38636364 0.4875\n",
      " 0.39285714 0.56410256 0.         0.7875     0.         0.62045455\n",
      " 0.66666667 0.66666667 0.75       0.4875     0.51764706 0.\n",
      " 0.65       0.2        0.29166667 0.         0.36666667 0.26666667\n",
      " 0.58441558 0.75524476 0.68181818 0.1875     0.4        0.\n",
      " 0.66666667 0.41666667 0.53846154 0.42857143 0.13392857 0.\n",
      " 0.70833333 0.23809524 0.25757576 0.375      0.         0.\n",
      " 0.58333333 0.15       0.33333333 0.6        0.66666667 0.72857143\n",
      " 0.34375    0.45833333 0.44444444 0.25       0.14835165 0.\n",
      " 0.36428571 0.         0.66666667 0.         0.54824561 0.47727273\n",
      " 0.225      0.5        0.41666667 0.73660714 0.54166667 0.33333333\n",
      " 0.5        0.20833333 0.53571429 0.43181818 0.23376623 0.17142857\n",
      " 0.35       0.3030303  0.         0.375      0.71428571 0.30952381\n",
      " 0.75       0.61904762]\n",
      "mini_batch 150\n",
      "mini_batch 151\n",
      "mini_batch 152\n",
      "mini_batch 153\n",
      "mini_batch 154\n",
      "mini_batch 155\n",
      "mini_batch 156\n",
      "mini_batch 157\n",
      "mini_batch 158\n",
      "mini_batch 159\n",
      "mini_batch 160\n",
      "mini_batch 161\n",
      "mini_batch 162\n",
      "mini_batch 163\n",
      "mini_batch 164\n",
      "mini_batch 165\n",
      "mini_batch 166\n",
      "mini_batch 167\n",
      "mini_batch 168\n",
      "mini_batch 169\n",
      "mini_batch 170\n",
      "mini_batch 171\n",
      "mini_batch 172\n",
      "mini_batch 173\n",
      "mini_batch 174\n",
      "mini_batch 175\n",
      "mini_batch 176\n",
      "mini_batch 177\n",
      "mini_batch 178\n",
      "mini_batch 179\n",
      "mini_batch 180\n",
      "mini_batch 181\n",
      "mini_batch 182\n",
      "mini_batch 183\n",
      "mini_batch 184\n",
      "mini_batch 185\n",
      "mini_batch 186\n",
      "mini_batch 187\n",
      "mini_batch 188\n",
      "mini_batch 189\n",
      "mini_batch 190\n",
      "mini_batch 191\n",
      "mini_batch 192\n",
      "mini_batch 193\n",
      "mini_batch 194\n",
      "mini_batch 195\n",
      "mini_batch 196\n",
      "mini_batch 197\n",
      "mini_batch 198\n",
      "mini_batch 199\n",
      "Epoch 4\n",
      "average minibatch 200 loss: 1.353\n",
      "\n",
      "Labels:  tensor([117, 125, 179,  63, 106, 184, 157, 129,   4, 186, 119, 138,  48,  61,\n",
      "         86,  87,   9,  11,  64, 102,  61,  64, 103,  85,   9, 103,  67, 101,\n",
      "        102, 136,  53,  36,  35,  59,  16, 119,  28, 106,  50,  62,  67, 141,\n",
      "        184,  50,  36, 136, 139,  60, 113, 196, 105, 173,  63, 194,  64, 105,\n",
      "        113, 186,  58,  64, 188,  14,  59,  48], device='cuda:0')\n",
      "Output:  tensor([117, 125, 179,  63, 106,  53, 157, 129,  17, 186, 119, 147,  48,  41,\n",
      "         86,  87,   9,  11,  64, 102,  61,  64, 103, 151,   9,  34,  67,  23,\n",
      "          7, 136,  29,  36,  35,  59,  16, 178,   9, 106,  50,  62,  67, 141,\n",
      "        152,  27,  69, 136, 139, 106, 113, 196, 105,  22,  63, 194,  64, 105,\n",
      "        113,  44,  58,  64, 188,  14,  59,  48], device='cuda:0')\n",
      "True Positives:  [ 8.  0.  2.  1.  5.  2.  5.  0.  8.  0.  2.  2.  6.  2.  6.  3.  3.  2.\n",
      "  0.  2.  4.  6.  2.  7.  0.  0.  7.  4.  4.  3.  0.  3.  2.  3.  6.  8.\n",
      "  8.  0.  4.  1.  3.  1.  2.  5.  7.  6.  2.  5.  3.  1.  0.  0.  7.  1.\n",
      "  0.  4.  2.  9.  7.  4.  3.  9.  6. 13.  5.  5.  9.  7.  7.  0.  9.  4.\n",
      "  0.  4.  2.  1.  1.  3.  0.  1.  5.  8.  3.  1.  4.  4.  4.  1.  3.  4.\n",
      "  1.  2.  2.  1.  2.  0.  3.  2.  0.  8.  1.  5.  3.  2. 10.  7.  3.  4.\n",
      "  7.  1.  2.  3.  8.  4.  2.  1.  1.  4.  8.  0.  5.  4.  3.  2.  4.  6.\n",
      "  4.  6.  1.  7.  0. 13.  2.  4.  3.  5.  4.  0.  5.  1.  3.  0.  2.  1.\n",
      "  5.  9.  4.  1.  2.  0. 10.  3.  7.  4.  1.  0.  7.  1.  2.  2.  0.  0.\n",
      "  7.  1.  1.  1.  1.  6.  3.  2.  4.  2.  2.  0.  3.  0.  6.  0.  6.  5.\n",
      "  1.  2.  1. 11.  3.  5.  2.  2.  4.  4.  2.  2.  2.  4.  0.  2.  3.  2.\n",
      "  1.  4.]\n",
      "False Positives:  [30.  1.  3.  6.  5.  4.  9.  3.  6.  3.  1.  2. 16.  1.  5.  7.  6.  5.\n",
      "  0.  1. 13.  8.  9.  8.  1.  0.  6.  3. 16.  3.  0.  3.  9.  6. 10. 12.\n",
      " 18.  7.  1.  2.  2.  4.  2.  2.  3.  3.  1.  3.  1.  1.  3.  0.  3.  1.\n",
      "  1.  3.  2. 15. 12.  3.  0.  4.  4.  5.  6.  2. 13.  5.  6.  2.  4. 11.\n",
      "  0.  9.  7.  4.  0.  3.  0.  2.  4.  3.  1.  2.  2.  5.  4.  2.  5.  4.\n",
      "  0.  4.  4.  1.  7.  0.  2.  7.  4.  7.  5.  3.  3.  3. 38. 17.  6.  0.\n",
      " 15.  6.  3.  4.  3.  7.  3.  4.  1.  9.  1.  2.  2.  6.  4.  6.  8. 10.\n",
      "  4.  3.  1.  3.  3.  9.  1.  2.  1.  5. 13.  1.  4.  4.  6.  3.  3.  2.\n",
      "  2.  2.  8.  7. 13.  0.  6.  4.  6. 10.  6.  2.  2.  2.  4.  2.  2.  0.\n",
      "  3.  4.  2.  0.  0.  4. 13.  1.  5.  4. 12.  2.  7.  0.  3.  3.  1.  6.\n",
      "  4.  2.  1.  5.  1.  6.  1.  3.  3.  7.  5. 12.  2.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  1.  3.  5.  4.  3.  4.  3.  8.  3.  5.  4.  2.  4.  5.  6.  6.  2.\n",
      "  3.  9. 10.  9.  5.  7.  1.  0.  5.  1.  5.  4.  9.  4.  7.  7.  1.  3.\n",
      " 13.  9.  2.  5.  4.  4.  3.  4.  2.  4.  2.  7.  6.  6.  5.  5.  5.  6.\n",
      "  3.  3.  0.  5.  3.  8.  6.  3.  6.  6.  6.  5.  5.  3.  1.  6.  9.  1.\n",
      "  1.  2.  5.  5.  4.  4.  5.  1.  4.  2.  4.  3.  6.  3.  4.  5.  6.  2.\n",
      "  3.  4. 10.  5.  5.  2.  3.  2.  7.  4.  7. 11.  5.  6.  4.  5.  3.  1.\n",
      "  8. 11.  6.  5.  7.  8.  5.  6.  4.  1.  3.  3.  3.  7.  8.  2.  3.  4.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  1.  2.  1.  1.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  0.  3.  1.  2.  5.  6.  6.  3.  7.  1.  3.  6.  9.  6.  7.  4.\n",
      "  8.  9.  2.  4.  2.  1.  3.  6.  5. 10. 12.  4.  4.  4.  3.  2. 14.  5.\n",
      "  3.  2.  2.  5.  6. 12.  4.  5.  4.  4.  9.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.125    0.       0.03125  0.015625 0.078125 0.03125  0.078125 0.\n",
      " 0.125    0.       0.03125  0.03125  0.09375  0.03125  0.09375  0.046875\n",
      " 0.046875 0.03125  0.       0.03125  0.0625   0.09375  0.03125  0.109375\n",
      " 0.       0.       0.109375 0.0625   0.0625   0.046875 0.       0.046875\n",
      " 0.03125  0.046875 0.09375  0.125    0.125    0.       0.0625   0.015625\n",
      " 0.046875 0.015625 0.03125  0.078125 0.109375 0.09375  0.03125  0.078125\n",
      " 0.046875 0.015625 0.       0.       0.109375 0.015625 0.       0.0625\n",
      " 0.03125  0.140625 0.109375 0.0625   0.046875 0.140625 0.09375  0.203125\n",
      " 0.078125 0.078125 0.140625 0.109375 0.109375 0.       0.140625 0.0625\n",
      " 0.       0.0625   0.03125  0.015625 0.015625 0.046875 0.       0.015625\n",
      " 0.078125 0.125    0.046875 0.015625 0.0625   0.0625   0.0625   0.015625\n",
      " 0.046875 0.0625   0.015625 0.03125  0.03125  0.015625 0.03125  0.\n",
      " 0.046875 0.03125  0.       0.125    0.015625 0.078125 0.046875 0.03125\n",
      " 0.15625  0.109375 0.046875 0.0625   0.109375 0.015625 0.03125  0.046875\n",
      " 0.125    0.0625   0.03125  0.015625 0.015625 0.0625   0.125    0.\n",
      " 0.078125 0.0625   0.046875 0.03125  0.0625   0.09375  0.0625   0.09375\n",
      " 0.015625 0.109375 0.       0.203125 0.03125  0.0625   0.046875 0.078125\n",
      " 0.0625   0.       0.078125 0.015625 0.046875 0.       0.03125  0.015625\n",
      " 0.078125 0.140625 0.0625   0.015625 0.03125  0.       0.15625  0.046875\n",
      " 0.109375 0.0625   0.015625 0.       0.109375 0.015625 0.03125  0.03125\n",
      " 0.       0.       0.109375 0.015625 0.015625 0.015625 0.015625 0.09375\n",
      " 0.046875 0.03125  0.0625   0.03125  0.03125  0.       0.046875 0.\n",
      " 0.09375  0.       0.09375  0.078125 0.015625 0.03125  0.015625 0.171875\n",
      " 0.046875 0.078125 0.03125  0.03125  0.0625   0.0625   0.03125  0.03125\n",
      " 0.03125  0.0625   0.       0.03125  0.046875 0.03125  0.015625 0.0625  ]\n",
      "Precision:  [0.21052632 0.         0.4        0.14285714 0.5        0.33333333\n",
      " 0.35714286 0.         0.57142857 0.         0.66666667 0.5\n",
      " 0.27272727 0.66666667 0.54545455 0.3        0.33333333 0.28571429\n",
      " 0.         0.66666667 0.23529412 0.42857143 0.18181818 0.46666667\n",
      " 0.         0.         0.53846154 0.57142857 0.2        0.5\n",
      " 0.         0.5        0.18181818 0.33333333 0.375      0.4\n",
      " 0.30769231 0.         0.8        0.33333333 0.6        0.2\n",
      " 0.5        0.71428571 0.7        0.66666667 0.66666667 0.625\n",
      " 0.75       0.5        0.         0.         0.7        0.5\n",
      " 0.         0.57142857 0.5        0.375      0.36842105 0.57142857\n",
      " 1.         0.69230769 0.6        0.72222222 0.45454545 0.71428571\n",
      " 0.40909091 0.58333333 0.53846154 0.         0.69230769 0.26666667\n",
      " 0.         0.30769231 0.22222222 0.2        1.         0.5\n",
      " 0.         0.33333333 0.55555556 0.72727273 0.75       0.33333333\n",
      " 0.66666667 0.44444444 0.5        0.33333333 0.375      0.5\n",
      " 1.         0.33333333 0.33333333 0.5        0.22222222 0.\n",
      " 0.6        0.22222222 0.         0.53333333 0.16666667 0.625\n",
      " 0.5        0.4        0.20833333 0.29166667 0.33333333 1.\n",
      " 0.31818182 0.14285714 0.4        0.42857143 0.72727273 0.36363636\n",
      " 0.4        0.2        0.5        0.30769231 0.88888889 0.\n",
      " 0.71428571 0.4        0.42857143 0.25       0.33333333 0.375\n",
      " 0.5        0.66666667 0.5        0.7        0.         0.59090909\n",
      " 0.66666667 0.66666667 0.75       0.5        0.23529412 0.\n",
      " 0.55555556 0.2        0.33333333 0.         0.4        0.33333333\n",
      " 0.71428571 0.81818182 0.33333333 0.125      0.13333333 0.\n",
      " 0.625      0.42857143 0.53846154 0.28571429 0.14285714 0.\n",
      " 0.77777778 0.33333333 0.33333333 0.5        0.         0.\n",
      " 0.7        0.2        0.33333333 1.         1.         0.6\n",
      " 0.1875     0.66666667 0.44444444 0.33333333 0.14285714 0.\n",
      " 0.3        0.         0.66666667 0.         0.85714286 0.45454545\n",
      " 0.2        0.5        0.5        0.6875     0.75       0.45454545\n",
      " 0.66666667 0.4        0.57142857 0.36363636 0.28571429 0.14285714\n",
      " 0.5        0.33333333 0.         0.4        1.         0.28571429\n",
      " 0.5        0.57142857]\n",
      "Recall:  [0.47058824 0.         0.4        0.16666667 0.55555556 0.4\n",
      " 0.55555556 0.         0.5        0.         0.28571429 0.33333333\n",
      " 0.75       0.33333333 0.54545455 0.33333333 0.33333333 0.5\n",
      " 0.         0.18181818 0.28571429 0.4        0.28571429 0.5\n",
      " 0.         0.         0.58333333 0.8        0.44444444 0.42857143\n",
      " 0.         0.42857143 0.22222222 0.3        0.85714286 0.72727273\n",
      " 0.38095238 0.         0.66666667 0.16666667 0.42857143 0.2\n",
      " 0.4        0.55555556 0.77777778 0.6        0.5        0.41666667\n",
      " 0.33333333 0.14285714 0.         0.         0.58333333 0.14285714\n",
      " 0.         0.57142857 1.         0.64285714 0.7        0.33333333\n",
      " 0.33333333 0.75       0.5        0.68421053 0.45454545 0.5\n",
      " 0.64285714 0.7        0.875      0.         0.5        0.8\n",
      " 0.         0.66666667 0.28571429 0.16666667 0.2        0.42857143\n",
      " 0.         0.5        0.55555556 0.8        0.42857143 0.25\n",
      " 0.4        0.57142857 0.5        0.16666667 0.33333333 0.66666667\n",
      " 0.25       0.33333333 0.16666667 0.16666667 0.28571429 0.\n",
      " 0.5        0.5        0.         0.66666667 0.125      0.3125\n",
      " 0.375      0.25       0.71428571 0.58333333 0.5        0.8\n",
      " 0.46666667 0.08333333 0.25       0.375      0.53333333 0.33333333\n",
      " 0.28571429 0.14285714 0.2        0.8        0.72727273 0.\n",
      " 0.625      0.36363636 0.27272727 0.5        0.57142857 0.6\n",
      " 0.28571429 0.46153846 0.16666667 0.875      0.         0.65\n",
      " 0.66666667 0.66666667 0.75       0.71428571 0.8        0.\n",
      " 0.83333333 0.2        0.42857143 0.         0.33333333 0.2\n",
      " 0.45454545 0.69230769 1.         0.25       0.66666667 0.\n",
      " 0.66666667 0.33333333 0.53846154 0.57142857 0.125      0.\n",
      " 0.7        0.14285714 0.18181818 0.25       0.         0.\n",
      " 0.46666667 0.1        0.33333333 0.2        0.33333333 0.85714286\n",
      " 0.5        0.25       0.44444444 0.16666667 0.14285714 0.\n",
      " 0.42857143 0.         0.66666667 0.         0.3        0.5\n",
      " 0.25       0.5        0.33333333 0.6875     0.33333333 0.29411765\n",
      " 0.33333333 0.28571429 0.5        0.5        0.18181818 0.2\n",
      " 0.2        0.4        0.         0.66666667 0.42857143 0.33333333\n",
      " 1.         0.66666667]\n",
      "Balanced Classification Rate:  [0.34055728 0.         0.4        0.1547619  0.52777778 0.36666667\n",
      " 0.45634921 0.         0.53571429 0.         0.47619048 0.41666667\n",
      " 0.51136364 0.5        0.54545455 0.31666667 0.33333333 0.39285714\n",
      " 0.         0.42424242 0.2605042  0.41428571 0.23376623 0.48333333\n",
      " 0.         0.         0.56089744 0.68571429 0.32222222 0.46428571\n",
      " 0.         0.46428571 0.2020202  0.31666667 0.61607143 0.56363636\n",
      " 0.34432234 0.         0.73333333 0.25       0.51428571 0.2\n",
      " 0.45       0.63492063 0.73888889 0.63333333 0.58333333 0.52083333\n",
      " 0.54166667 0.32142857 0.         0.         0.64166667 0.32142857\n",
      " 0.         0.57142857 0.75       0.50892857 0.53421053 0.45238095\n",
      " 0.66666667 0.72115385 0.55       0.70321637 0.45454545 0.60714286\n",
      " 0.52597403 0.64166667 0.70673077 0.         0.59615385 0.53333333\n",
      " 0.         0.48717949 0.25396825 0.18333333 0.6        0.46428571\n",
      " 0.         0.41666667 0.55555556 0.76363636 0.58928571 0.29166667\n",
      " 0.53333333 0.50793651 0.5        0.25       0.35416667 0.58333333\n",
      " 0.625      0.33333333 0.25       0.33333333 0.25396825 0.\n",
      " 0.55       0.36111111 0.         0.6        0.14583333 0.46875\n",
      " 0.4375     0.325      0.46130952 0.4375     0.41666667 0.9\n",
      " 0.39242424 0.11309524 0.325      0.40178571 0.63030303 0.34848485\n",
      " 0.34285714 0.17142857 0.35       0.55384615 0.80808081 0.\n",
      " 0.66964286 0.38181818 0.35064935 0.375      0.45238095 0.4875\n",
      " 0.39285714 0.56410256 0.33333333 0.7875     0.         0.62045455\n",
      " 0.66666667 0.66666667 0.75       0.60714286 0.51764706 0.\n",
      " 0.69444444 0.2        0.38095238 0.         0.36666667 0.26666667\n",
      " 0.58441558 0.75524476 0.66666667 0.1875     0.4        0.\n",
      " 0.64583333 0.38095238 0.53846154 0.42857143 0.13392857 0.\n",
      " 0.73888889 0.23809524 0.25757576 0.375      0.         0.\n",
      " 0.58333333 0.15       0.33333333 0.6        0.66666667 0.72857143\n",
      " 0.34375    0.45833333 0.44444444 0.25       0.14285714 0.\n",
      " 0.36428571 0.         0.66666667 0.         0.57857143 0.47727273\n",
      " 0.225      0.5        0.41666667 0.6875     0.54166667 0.37433155\n",
      " 0.5        0.34285714 0.53571429 0.43181818 0.23376623 0.17142857\n",
      " 0.35       0.36666667 0.         0.53333333 0.71428571 0.30952381\n",
      " 0.75       0.61904762]\n",
      "mini_batch 200\n",
      "mini_batch 201\n",
      "mini_batch 202\n",
      "mini_batch 203\n",
      "mini_batch 204\n",
      "mini_batch 205\n",
      "mini_batch 206\n",
      "mini_batch 207\n",
      "mini_batch 208\n",
      "mini_batch 209\n",
      "mini_batch 210\n",
      "mini_batch 211\n",
      "mini_batch 212\n",
      "mini_batch 213\n",
      "mini_batch 214\n",
      "mini_batch 215\n",
      "mini_batch 216\n",
      "mini_batch 217\n",
      "mini_batch 218\n",
      "mini_batch 219\n",
      "mini_batch 220\n",
      "mini_batch 221\n",
      "mini_batch 222\n",
      "mini_batch 223\n",
      "mini_batch 224\n",
      "mini_batch 225\n",
      "mini_batch 226\n",
      "mini_batch 227\n",
      "mini_batch 228\n",
      "mini_batch 229\n",
      "mini_batch 230\n",
      "mini_batch 231\n",
      "mini_batch 232\n",
      "mini_batch 233\n",
      "mini_batch 234\n",
      "mini_batch 235\n",
      "mini_batch 236\n",
      "mini_batch 237\n",
      "mini_batch 238\n",
      "mini_batch 239\n",
      "mini_batch 240\n",
      "mini_batch 241\n",
      "mini_batch 242\n",
      "mini_batch 243\n",
      "mini_batch 244\n",
      "mini_batch 245\n",
      "mini_batch 246\n",
      "mini_batch 247\n",
      "mini_batch 248\n",
      "mini_batch 249\n",
      "Epoch 4\n",
      "average minibatch 250 loss: 1.360\n",
      "\n",
      "Labels:  tensor([ 19,  32,  64, 186,  58,  62,   2,  71,  39, 173,  41, 190, 176, 147,\n",
      "        173, 145,  12, 102,  19, 122, 186,  66, 157, 118, 110, 180,  95,  98,\n",
      "         61, 186, 118,  81,  33,  18,  37, 181,  50,  98,  68, 177,   9, 125,\n",
      "         78, 137,  82,   9, 200,  27, 175, 155, 121,  59,  37, 155, 184,  23,\n",
      "        135, 139, 168,  58, 172,  72, 157,  67], device='cuda:0')\n",
      "Output:  tensor([179,  47,  64, 186,  58,  62, 107,  71,  77, 173,  41, 190, 151, 139,\n",
      "        189, 145, 101, 102,  19, 122, 138,  66, 157, 118, 192, 180,  95, 171,\n",
      "         27, 186, 118,  81,  86, 120, 188, 181,  50,  98,  68, 177,  13, 125,\n",
      "         78, 137,  82,  13, 200,  27, 175,   7, 132,  59,  37, 132, 184,  23,\n",
      "         75, 139, 168,  58, 172, 193, 157,  67], device='cuda:0')\n",
      "True Positives:  [ 8.  0.  2.  1.  5.  2.  5.  0.  8.  0.  2.  2.  6.  2.  6.  3.  3.  2.\n",
      "  1.  2.  4.  6.  3.  7.  0.  0.  8.  4.  4.  3.  0.  3.  2.  3.  6.  8.\n",
      "  9.  0.  4.  1.  4.  1.  2.  5.  7.  6.  2.  5.  3.  2.  0.  0.  7.  1.\n",
      "  0.  4.  2. 11.  8.  4.  3. 10.  6. 14.  5.  6. 10.  8.  7.  0. 10.  4.\n",
      "  0.  4.  2.  1.  1.  4.  0.  1.  6.  9.  3.  1.  4.  4.  4.  1.  3.  4.\n",
      "  1.  2.  2.  1.  3.  0.  3.  3.  0.  8.  1.  6.  3.  2. 10.  7.  3.  4.\n",
      "  7.  1.  2.  3.  8.  4.  2.  1.  1.  6.  8.  0.  5.  5.  3.  2.  5.  6.\n",
      "  4.  6.  1.  7.  0. 13.  2.  4.  3.  5.  5.  0.  6.  1.  3.  0.  2.  1.\n",
      "  6.  9.  4.  1.  2.  0. 10.  3.  7.  4.  1.  0.  9.  1.  2.  2.  0.  0.\n",
      "  7.  1.  1.  1.  1.  7.  3.  2.  4.  3.  3.  0.  4.  0.  7.  0.  6.  6.\n",
      "  2.  2.  1. 12.  3.  7.  2.  2.  4.  5.  2.  2.  2.  4.  0.  2.  3.  2.\n",
      "  1.  5.]\n",
      "False Positives:  [30.  1.  3.  6.  5.  4. 10.  3.  6.  3.  1.  2. 18.  1.  5.  7.  6.  5.\n",
      "  0.  1. 13.  8.  9.  8.  1.  0.  7.  3. 16.  3.  0.  3.  9.  6. 10. 12.\n",
      " 18.  7.  1.  2.  2.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  3.  1.\n",
      "  1.  3.  2. 15. 12.  3.  0.  4.  4.  5.  6.  2. 13.  5.  6.  2.  4. 11.\n",
      "  0.  9.  8.  4.  1.  3.  0.  2.  4.  3.  1.  2.  2.  6.  4.  2.  5.  4.\n",
      "  0.  4.  4.  1.  7.  0.  2.  7.  4.  7.  6.  3.  3.  3. 38. 17.  7.  0.\n",
      " 15.  6.  3.  4.  3.  7.  3.  4.  1.  9.  1.  3.  2.  6.  4.  6.  8. 10.\n",
      "  4.  3.  1.  3.  3. 11.  1.  2.  1.  5. 13.  2.  5.  4.  6.  3.  3.  2.\n",
      "  2.  2.  8.  7. 13.  0.  7.  4.  6. 10.  6.  2.  2.  2.  4.  2.  2.  0.\n",
      "  3.  4.  2.  0.  0.  4. 13.  1.  6.  4. 12.  2.  7.  0.  3.  3.  2.  6.\n",
      "  4.  2.  1.  5.  1.  6.  1.  4.  4.  7.  5. 13.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  2.  3.  5.  4.  3.  4.  3. 10.  3.  5.  5.  2.  4.  5.  6.  6.  3.\n",
      "  4.  9. 10.  9.  5.  7.  1.  0.  5.  1.  5.  4.  9.  5.  8.  7.  1.  3.\n",
      " 14.  9.  3.  5.  4.  4.  3.  4.  2.  4.  2.  7.  6.  6.  5.  5.  5.  6.\n",
      "  3.  3.  0.  5.  3.  8.  7.  3.  6.  6.  6.  5.  5.  3.  1.  6.  9.  2.\n",
      "  1.  2.  5.  5.  4.  4.  5.  1.  4.  2.  4.  3.  6.  3.  4.  5.  6.  2.\n",
      "  3.  4. 10.  5.  5.  2.  3.  3.  7.  4.  7. 11.  5.  6.  4.  5.  3.  1.\n",
      "  8. 12.  6.  5.  7.  8.  5.  6.  4.  1.  3.  3.  4.  7.  8.  2.  3.  4.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  2.  2.  1.  1.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  1.  3.  1.  2.  5.  6.  6.  3.  9.  1.  3.  6.  9.  6.  7.  4.\n",
      "  8.  9.  2.  4.  2.  1.  3.  6.  5. 10. 13.  4.  4.  5.  3.  2. 14.  5.\n",
      "  3.  2.  2.  5.  6. 13.  4.  5.  4.  4.  9.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.125    0.       0.03125  0.015625 0.078125 0.03125  0.078125 0.\n",
      " 0.125    0.       0.03125  0.03125  0.09375  0.03125  0.09375  0.046875\n",
      " 0.046875 0.03125  0.015625 0.03125  0.0625   0.09375  0.046875 0.109375\n",
      " 0.       0.       0.125    0.0625   0.0625   0.046875 0.       0.046875\n",
      " 0.03125  0.046875 0.09375  0.125    0.140625 0.       0.0625   0.015625\n",
      " 0.0625   0.015625 0.03125  0.078125 0.109375 0.09375  0.03125  0.078125\n",
      " 0.046875 0.03125  0.       0.       0.109375 0.015625 0.       0.0625\n",
      " 0.03125  0.171875 0.125    0.0625   0.046875 0.15625  0.09375  0.21875\n",
      " 0.078125 0.09375  0.15625  0.125    0.109375 0.       0.15625  0.0625\n",
      " 0.       0.0625   0.03125  0.015625 0.015625 0.0625   0.       0.015625\n",
      " 0.09375  0.140625 0.046875 0.015625 0.0625   0.0625   0.0625   0.015625\n",
      " 0.046875 0.0625   0.015625 0.03125  0.03125  0.015625 0.046875 0.\n",
      " 0.046875 0.046875 0.       0.125    0.015625 0.09375  0.046875 0.03125\n",
      " 0.15625  0.109375 0.046875 0.0625   0.109375 0.015625 0.03125  0.046875\n",
      " 0.125    0.0625   0.03125  0.015625 0.015625 0.09375  0.125    0.\n",
      " 0.078125 0.078125 0.046875 0.03125  0.078125 0.09375  0.0625   0.09375\n",
      " 0.015625 0.109375 0.       0.203125 0.03125  0.0625   0.046875 0.078125\n",
      " 0.078125 0.       0.09375  0.015625 0.046875 0.       0.03125  0.015625\n",
      " 0.09375  0.140625 0.0625   0.015625 0.03125  0.       0.15625  0.046875\n",
      " 0.109375 0.0625   0.015625 0.       0.140625 0.015625 0.03125  0.03125\n",
      " 0.       0.       0.109375 0.015625 0.015625 0.015625 0.015625 0.109375\n",
      " 0.046875 0.03125  0.0625   0.046875 0.046875 0.       0.0625   0.\n",
      " 0.109375 0.       0.09375  0.09375  0.03125  0.03125  0.015625 0.1875\n",
      " 0.046875 0.109375 0.03125  0.03125  0.0625   0.078125 0.03125  0.03125\n",
      " 0.03125  0.0625   0.       0.03125  0.046875 0.03125  0.015625 0.078125]\n",
      "Precision:  [0.21052632 0.         0.4        0.14285714 0.5        0.33333333\n",
      " 0.33333333 0.         0.57142857 0.         0.66666667 0.5\n",
      " 0.25       0.66666667 0.54545455 0.3        0.33333333 0.28571429\n",
      " 1.         0.66666667 0.23529412 0.42857143 0.25       0.46666667\n",
      " 0.         0.         0.53333333 0.57142857 0.2        0.5\n",
      " 0.         0.5        0.18181818 0.33333333 0.375      0.4\n",
      " 0.33333333 0.         0.8        0.33333333 0.66666667 0.2\n",
      " 0.5        0.71428571 0.7        0.66666667 0.5        0.625\n",
      " 0.75       0.66666667 0.         0.         0.7        0.5\n",
      " 0.         0.57142857 0.5        0.42307692 0.4        0.57142857\n",
      " 1.         0.71428571 0.6        0.73684211 0.45454545 0.75\n",
      " 0.43478261 0.61538462 0.53846154 0.         0.71428571 0.26666667\n",
      " 0.         0.30769231 0.2        0.2        0.5        0.57142857\n",
      " 0.         0.33333333 0.6        0.75       0.75       0.33333333\n",
      " 0.66666667 0.4        0.5        0.33333333 0.375      0.5\n",
      " 1.         0.33333333 0.33333333 0.5        0.3        0.\n",
      " 0.6        0.3        0.         0.53333333 0.14285714 0.66666667\n",
      " 0.5        0.4        0.20833333 0.29166667 0.3        1.\n",
      " 0.31818182 0.14285714 0.4        0.42857143 0.72727273 0.36363636\n",
      " 0.4        0.2        0.5        0.4        0.88888889 0.\n",
      " 0.71428571 0.45454545 0.42857143 0.25       0.38461538 0.375\n",
      " 0.5        0.66666667 0.5        0.7        0.         0.54166667\n",
      " 0.66666667 0.66666667 0.75       0.5        0.27777778 0.\n",
      " 0.54545455 0.2        0.33333333 0.         0.4        0.33333333\n",
      " 0.75       0.81818182 0.33333333 0.125      0.13333333 0.\n",
      " 0.58823529 0.42857143 0.53846154 0.28571429 0.14285714 0.\n",
      " 0.81818182 0.33333333 0.33333333 0.5        0.         0.\n",
      " 0.7        0.2        0.33333333 1.         1.         0.63636364\n",
      " 0.1875     0.66666667 0.4        0.42857143 0.2        0.\n",
      " 0.36363636 0.         0.7        0.         0.75       0.5\n",
      " 0.33333333 0.5        0.5        0.70588235 0.75       0.53846154\n",
      " 0.66666667 0.33333333 0.5        0.41666667 0.28571429 0.13333333\n",
      " 0.4        0.33333333 0.         0.4        1.         0.28571429\n",
      " 0.5        0.625     ]\n",
      "Recall:  [0.47058824 0.         0.4        0.16666667 0.55555556 0.4\n",
      " 0.55555556 0.         0.44444444 0.         0.28571429 0.28571429\n",
      " 0.75       0.33333333 0.54545455 0.33333333 0.33333333 0.4\n",
      " 0.2        0.18181818 0.28571429 0.4        0.375      0.5\n",
      " 0.         0.         0.61538462 0.8        0.44444444 0.42857143\n",
      " 0.         0.375      0.2        0.3        0.85714286 0.72727273\n",
      " 0.39130435 0.         0.57142857 0.16666667 0.5        0.2\n",
      " 0.4        0.55555556 0.77777778 0.6        0.5        0.41666667\n",
      " 0.33333333 0.25       0.         0.         0.58333333 0.14285714\n",
      " 0.         0.57142857 1.         0.6875     0.72727273 0.33333333\n",
      " 0.3        0.76923077 0.5        0.7        0.45454545 0.54545455\n",
      " 0.66666667 0.72727273 0.875      0.         0.52631579 0.66666667\n",
      " 0.         0.66666667 0.28571429 0.16666667 0.2        0.5\n",
      " 0.         0.5        0.6        0.81818182 0.42857143 0.25\n",
      " 0.4        0.57142857 0.5        0.16666667 0.33333333 0.66666667\n",
      " 0.25       0.33333333 0.16666667 0.16666667 0.375      0.\n",
      " 0.5        0.5        0.         0.66666667 0.125      0.35294118\n",
      " 0.375      0.25       0.71428571 0.58333333 0.5        0.8\n",
      " 0.46666667 0.07692308 0.25       0.375      0.53333333 0.33333333\n",
      " 0.28571429 0.14285714 0.2        0.85714286 0.72727273 0.\n",
      " 0.55555556 0.41666667 0.27272727 0.5        0.625      0.6\n",
      " 0.28571429 0.46153846 0.16666667 0.875      0.         0.65\n",
      " 0.66666667 0.66666667 0.6        0.71428571 0.83333333 0.\n",
      " 0.85714286 0.2        0.42857143 0.         0.33333333 0.2\n",
      " 0.5        0.69230769 0.8        0.25       0.66666667 0.\n",
      " 0.66666667 0.33333333 0.53846154 0.57142857 0.1        0.\n",
      " 0.75       0.14285714 0.18181818 0.25       0.         0.\n",
      " 0.46666667 0.1        0.33333333 0.2        0.33333333 0.875\n",
      " 0.5        0.25       0.44444444 0.23076923 0.1875     0.\n",
      " 0.5        0.         0.7        0.         0.3        0.54545455\n",
      " 0.4        0.5        0.33333333 0.70588235 0.33333333 0.35\n",
      " 0.33333333 0.28571429 0.5        0.55555556 0.18181818 0.2\n",
      " 0.2        0.4        0.         0.66666667 0.42857143 0.33333333\n",
      " 1.         0.71428571]\n",
      "Balanced Classification Rate:  [0.34055728 0.         0.4        0.1547619  0.52777778 0.36666667\n",
      " 0.44444444 0.         0.50793651 0.         0.47619048 0.39285714\n",
      " 0.5        0.5        0.54545455 0.31666667 0.33333333 0.34285714\n",
      " 0.6        0.42424242 0.2605042  0.41428571 0.3125     0.48333333\n",
      " 0.         0.         0.57435897 0.68571429 0.32222222 0.46428571\n",
      " 0.         0.4375     0.19090909 0.31666667 0.61607143 0.56363636\n",
      " 0.36231884 0.         0.68571429 0.25       0.58333333 0.2\n",
      " 0.45       0.63492063 0.73888889 0.63333333 0.5        0.52083333\n",
      " 0.54166667 0.45833333 0.         0.         0.64166667 0.32142857\n",
      " 0.         0.57142857 0.75       0.55528846 0.56363636 0.45238095\n",
      " 0.65       0.74175824 0.55       0.71842105 0.45454545 0.64772727\n",
      " 0.55072464 0.67132867 0.70673077 0.         0.62030075 0.46666667\n",
      " 0.         0.48717949 0.24285714 0.18333333 0.35       0.53571429\n",
      " 0.         0.41666667 0.6        0.78409091 0.58928571 0.29166667\n",
      " 0.53333333 0.48571429 0.5        0.25       0.35416667 0.58333333\n",
      " 0.625      0.33333333 0.25       0.33333333 0.3375     0.\n",
      " 0.55       0.4        0.         0.6        0.13392857 0.50980392\n",
      " 0.4375     0.325      0.46130952 0.4375     0.4        0.9\n",
      " 0.39242424 0.10989011 0.325      0.40178571 0.63030303 0.34848485\n",
      " 0.34285714 0.17142857 0.35       0.62857143 0.80808081 0.\n",
      " 0.63492063 0.43560606 0.35064935 0.375      0.50480769 0.4875\n",
      " 0.39285714 0.56410256 0.33333333 0.7875     0.         0.59583333\n",
      " 0.66666667 0.66666667 0.675      0.60714286 0.55555556 0.\n",
      " 0.7012987  0.2        0.38095238 0.         0.36666667 0.26666667\n",
      " 0.625      0.75524476 0.56666667 0.1875     0.4        0.\n",
      " 0.62745098 0.38095238 0.53846154 0.42857143 0.12142857 0.\n",
      " 0.78409091 0.23809524 0.25757576 0.375      0.         0.\n",
      " 0.58333333 0.15       0.33333333 0.6        0.66666667 0.75568182\n",
      " 0.34375    0.45833333 0.42222222 0.32967033 0.19375    0.\n",
      " 0.43181818 0.         0.7        0.         0.525      0.52272727\n",
      " 0.36666667 0.5        0.41666667 0.70588235 0.54166667 0.44423077\n",
      " 0.5        0.30952381 0.5        0.48611111 0.23376623 0.16666667\n",
      " 0.3        0.36666667 0.         0.53333333 0.71428571 0.30952381\n",
      " 0.75       0.66964286]\n",
      "mini_batch 250\n",
      "mini_batch 251\n",
      "mini_batch 252\n",
      "mini_batch 253\n",
      "mini_batch 254\n",
      "mini_batch 255\n",
      "mini_batch 256\n",
      "mini_batch 257\n",
      "mini_batch 258\n",
      "mini_batch 259\n",
      "mini_batch 260\n",
      "mini_batch 261\n",
      "mini_batch 262\n",
      "mini_batch 263\n",
      "mini_batch 264\n",
      "mini_batch 265\n",
      "mini_batch 266\n",
      "mini_batch 267\n",
      "mini_batch 268\n",
      "mini_batch 269\n",
      "mini_batch 270\n",
      "mini_batch 271\n",
      "mini_batch 272\n",
      "mini_batch 273\n",
      "mini_batch 274\n",
      "mini_batch 275\n",
      "mini_batch 276\n",
      "mini_batch 277\n",
      "mini_batch 278\n",
      "mini_batch 279\n",
      "mini_batch 280\n",
      "mini_batch 281\n",
      "mini_batch 282\n",
      "mini_batch 283\n",
      "mini_batch 284\n",
      "mini_batch 285\n",
      "mini_batch 286\n",
      "mini_batch 287\n",
      "mini_batch 288\n",
      "mini_batch 289\n",
      "mini_batch 290\n",
      "mini_batch 291\n",
      "mini_batch 292\n",
      "mini_batch 293\n",
      "mini_batch 294\n",
      "mini_batch 295\n",
      "mini_batch 296\n",
      "mini_batch 297\n",
      "mini_batch 298\n",
      "mini_batch 299\n",
      "Epoch 4\n",
      "average minibatch 300 loss: 1.384\n",
      "\n",
      "Labels:  tensor([107,  35, 159,  59,  99, 100,  20,  48, 182,  93,   5,  23,  63, 109,\n",
      "         90, 177, 135, 125, 190, 118, 145, 153, 153,  32,  38, 190,  83, 118,\n",
      "        155, 154,  38, 106, 137,  13,  61,  17,  95, 178, 169,  63, 104,  81,\n",
      "        133,  84,  85,  27, 116, 161, 190,  37, 192,  47, 179, 101, 200, 114,\n",
      "        111, 189,  78,  30,  60,  30, 151,  65], device='cuda:0')\n",
      "Output:  tensor([107,  35, 159,  64,  99, 100,  20,  48, 182,  93,   5, 153,  73, 109,\n",
      "         90, 177, 135, 125, 190, 118, 145, 153, 153, 114,  38, 190,  83, 118,\n",
      "        155, 154,  38, 106, 137, 186,  81,  17, 123, 178, 164,  63,  15,  81,\n",
      "        133,  84,  85,  27, 116,  89,  96,  37, 192,  47, 179, 101, 200, 114,\n",
      "        111,  24,  78,  30,  31,  23, 105,  89], device='cuda:0')\n",
      "True Positives:  [ 8.  0.  2.  1.  6.  2.  5.  0.  8.  0.  2.  2.  6.  2.  6.  3.  4.  2.\n",
      "  1.  3.  4.  6.  3.  7.  0.  0.  9.  4.  4.  4.  0.  3.  2.  3.  7.  8.\n",
      " 10.  2.  4.  1.  4.  1.  2.  5.  7.  6.  3.  6.  3.  2.  0.  0.  7.  1.\n",
      "  0.  4.  2. 11.  8.  4.  3. 10.  7. 14.  5.  6. 10.  8.  7.  0. 10.  4.\n",
      "  0.  4.  2.  1.  1.  5.  0.  1.  7.  9.  4.  2.  5.  4.  4.  1.  3.  5.\n",
      "  1.  2.  3.  1.  3.  0.  3.  3.  1.  9.  2.  6.  3.  2. 10.  8.  4.  4.\n",
      "  8.  1.  3.  3.  8.  5.  2.  2.  1.  8.  8.  0.  5.  5.  3.  2.  6.  6.\n",
      "  4.  6.  1.  7.  0. 13.  3.  4.  4.  5.  6.  0.  6.  1.  3.  0.  2.  1.\n",
      "  7.  9.  4.  1.  2.  0. 10.  3.  9.  5.  2.  0.  9.  1.  3.  2.  0.  0.\n",
      "  7.  1.  1.  1.  1.  7.  3.  2.  4.  3.  3.  0.  4.  0.  8.  1.  7.  6.\n",
      "  2.  3.  1. 12.  3.  7.  2.  2.  4.  7.  2.  3.  2.  4.  0.  2.  3.  2.\n",
      "  1.  6.]\n",
      "False Positives:  [30.  1.  3.  6.  5.  4. 10.  3.  6.  3.  1.  2. 18.  1.  6.  7.  6.  5.\n",
      "  0.  1. 13.  8. 10.  9.  1.  0.  7.  3. 16.  3.  1.  3.  9.  6. 10. 12.\n",
      " 18.  7.  1.  2.  2.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  3.  1.\n",
      "  1.  3.  2. 15. 12.  3.  0.  4.  4.  6.  6.  2. 13.  5.  6.  2.  4. 11.\n",
      "  1.  9.  8.  4.  1.  3.  0.  2.  5.  3.  1.  2.  2.  6.  4.  2.  7.  4.\n",
      "  0.  4.  4.  1.  7.  1.  2.  7.  4.  7.  6.  3.  3.  3. 39. 17.  7.  0.\n",
      " 15.  6.  3.  4.  3.  8.  3.  4.  1.  9.  1.  3.  2.  6.  5.  6.  8. 10.\n",
      "  4.  3.  1.  3.  3. 11.  1.  2.  1.  5. 13.  2.  5.  4.  6.  3.  3.  2.\n",
      "  2.  2.  8.  7. 13.  0.  7.  4.  7. 10.  6.  2.  2.  2.  4.  2.  2.  0.\n",
      "  3.  5.  2.  0.  0.  4. 13.  1.  6.  4. 12.  2.  7.  0.  3.  3.  2.  6.\n",
      "  4.  2.  1.  5.  1.  7.  1.  4.  4.  7.  5. 13.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  2.  3.  5.  4.  3.  4.  3. 10.  3.  5.  5.  3.  4.  5.  6.  6.  3.\n",
      "  4.  9. 10.  9.  6.  7.  1.  0.  5.  1.  5.  5.  9.  6.  8.  7.  1.  3.\n",
      " 14.  9.  3.  5.  4.  4.  3.  4.  2.  4.  2.  7.  6.  6.  5.  5.  5.  6.\n",
      "  3.  3.  0.  5.  4.  9.  8.  3.  7.  6.  7.  5.  5.  3.  1.  6.  9.  2.\n",
      "  1.  2.  5.  5.  4.  4.  5.  1.  4.  2.  4.  3.  6.  3.  4.  5.  6.  2.\n",
      "  3.  4. 10.  5.  6.  2.  3.  3.  7.  4.  7. 11.  5.  7.  4.  5.  3.  1.\n",
      "  8. 12.  6.  5.  7.  8.  5.  6.  4.  1.  3.  3.  4.  7.  8.  2.  3.  4.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  2.  2.  1.  1.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  1.  3.  1.  2.  6.  6.  6.  3.  9.  1.  3.  6.  9.  6.  8.  4.\n",
      "  8.  9.  2.  4.  2.  1.  4.  6.  5. 10. 13.  4.  4.  5.  3.  2. 14.  5.\n",
      "  3.  2.  2.  5.  6. 13.  4.  5.  5.  5.  9.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.125    0.       0.03125  0.015625 0.09375  0.03125  0.078125 0.\n",
      " 0.125    0.       0.03125  0.03125  0.09375  0.03125  0.09375  0.046875\n",
      " 0.0625   0.03125  0.015625 0.046875 0.0625   0.09375  0.046875 0.109375\n",
      " 0.       0.       0.140625 0.0625   0.0625   0.0625   0.       0.046875\n",
      " 0.03125  0.046875 0.109375 0.125    0.15625  0.03125  0.0625   0.015625\n",
      " 0.0625   0.015625 0.03125  0.078125 0.109375 0.09375  0.046875 0.09375\n",
      " 0.046875 0.03125  0.       0.       0.109375 0.015625 0.       0.0625\n",
      " 0.03125  0.171875 0.125    0.0625   0.046875 0.15625  0.109375 0.21875\n",
      " 0.078125 0.09375  0.15625  0.125    0.109375 0.       0.15625  0.0625\n",
      " 0.       0.0625   0.03125  0.015625 0.015625 0.078125 0.       0.015625\n",
      " 0.109375 0.140625 0.0625   0.03125  0.078125 0.0625   0.0625   0.015625\n",
      " 0.046875 0.078125 0.015625 0.03125  0.046875 0.015625 0.046875 0.\n",
      " 0.046875 0.046875 0.015625 0.140625 0.03125  0.09375  0.046875 0.03125\n",
      " 0.15625  0.125    0.0625   0.0625   0.125    0.015625 0.046875 0.046875\n",
      " 0.125    0.078125 0.03125  0.03125  0.015625 0.125    0.125    0.\n",
      " 0.078125 0.078125 0.046875 0.03125  0.09375  0.09375  0.0625   0.09375\n",
      " 0.015625 0.109375 0.       0.203125 0.046875 0.0625   0.0625   0.078125\n",
      " 0.09375  0.       0.09375  0.015625 0.046875 0.       0.03125  0.015625\n",
      " 0.109375 0.140625 0.0625   0.015625 0.03125  0.       0.15625  0.046875\n",
      " 0.140625 0.078125 0.03125  0.       0.140625 0.015625 0.046875 0.03125\n",
      " 0.       0.       0.109375 0.015625 0.015625 0.015625 0.015625 0.109375\n",
      " 0.046875 0.03125  0.0625   0.046875 0.046875 0.       0.0625   0.\n",
      " 0.125    0.015625 0.109375 0.09375  0.03125  0.046875 0.015625 0.1875\n",
      " 0.046875 0.109375 0.03125  0.03125  0.0625   0.109375 0.03125  0.046875\n",
      " 0.03125  0.0625   0.       0.03125  0.046875 0.03125  0.015625 0.09375 ]\n",
      "Precision:  [0.21052632 0.         0.4        0.14285714 0.54545455 0.33333333\n",
      " 0.33333333 0.         0.57142857 0.         0.66666667 0.5\n",
      " 0.25       0.66666667 0.5        0.3        0.4        0.28571429\n",
      " 1.         0.75       0.23529412 0.42857143 0.23076923 0.4375\n",
      " 0.         0.         0.5625     0.57142857 0.2        0.57142857\n",
      " 0.         0.5        0.18181818 0.33333333 0.41176471 0.4\n",
      " 0.35714286 0.22222222 0.8        0.33333333 0.66666667 0.2\n",
      " 0.5        0.71428571 0.7        0.66666667 0.6        0.66666667\n",
      " 0.75       0.66666667 0.         0.         0.7        0.5\n",
      " 0.         0.57142857 0.5        0.42307692 0.4        0.57142857\n",
      " 1.         0.71428571 0.63636364 0.7        0.45454545 0.75\n",
      " 0.43478261 0.61538462 0.53846154 0.         0.71428571 0.26666667\n",
      " 0.         0.30769231 0.2        0.2        0.5        0.625\n",
      " 0.         0.33333333 0.58333333 0.75       0.8        0.5\n",
      " 0.71428571 0.4        0.5        0.33333333 0.3        0.55555556\n",
      " 1.         0.33333333 0.42857143 0.5        0.3        0.\n",
      " 0.6        0.3        0.2        0.5625     0.25       0.66666667\n",
      " 0.5        0.4        0.20408163 0.32       0.36363636 1.\n",
      " 0.34782609 0.14285714 0.5        0.42857143 0.72727273 0.38461538\n",
      " 0.4        0.33333333 0.5        0.47058824 0.88888889 0.\n",
      " 0.71428571 0.45454545 0.375      0.25       0.42857143 0.375\n",
      " 0.5        0.66666667 0.5        0.7        0.         0.54166667\n",
      " 0.75       0.66666667 0.8        0.5        0.31578947 0.\n",
      " 0.54545455 0.2        0.33333333 0.         0.4        0.33333333\n",
      " 0.77777778 0.81818182 0.33333333 0.125      0.13333333 0.\n",
      " 0.58823529 0.42857143 0.5625     0.33333333 0.25       0.\n",
      " 0.81818182 0.33333333 0.42857143 0.5        0.         0.\n",
      " 0.7        0.16666667 0.33333333 1.         1.         0.63636364\n",
      " 0.1875     0.66666667 0.4        0.42857143 0.2        0.\n",
      " 0.36363636 0.         0.72727273 0.25       0.77777778 0.5\n",
      " 0.33333333 0.6        0.5        0.70588235 0.75       0.5\n",
      " 0.66666667 0.33333333 0.5        0.5        0.28571429 0.1875\n",
      " 0.4        0.33333333 0.         0.4        1.         0.28571429\n",
      " 0.5        0.66666667]\n",
      "Recall:  [0.47058824 0.         0.4        0.16666667 0.6        0.4\n",
      " 0.55555556 0.         0.44444444 0.         0.28571429 0.28571429\n",
      " 0.66666667 0.33333333 0.54545455 0.33333333 0.4        0.4\n",
      " 0.2        0.25       0.28571429 0.4        0.33333333 0.5\n",
      " 0.         0.         0.64285714 0.8        0.44444444 0.44444444\n",
      " 0.         0.33333333 0.2        0.3        0.875      0.72727273\n",
      " 0.41666667 0.18181818 0.57142857 0.16666667 0.5        0.2\n",
      " 0.4        0.55555556 0.77777778 0.6        0.6        0.46153846\n",
      " 0.33333333 0.25       0.         0.         0.58333333 0.14285714\n",
      " 0.         0.57142857 1.         0.6875     0.66666667 0.30769231\n",
      " 0.27272727 0.76923077 0.5        0.7        0.41666667 0.54545455\n",
      " 0.66666667 0.72727273 0.875      0.         0.52631579 0.66666667\n",
      " 0.         0.66666667 0.28571429 0.16666667 0.2        0.55555556\n",
      " 0.         0.5        0.63636364 0.81818182 0.5        0.4\n",
      " 0.45454545 0.57142857 0.5        0.16666667 0.33333333 0.71428571\n",
      " 0.25       0.33333333 0.23076923 0.16666667 0.33333333 0.\n",
      " 0.5        0.5        0.125      0.69230769 0.22222222 0.35294118\n",
      " 0.375      0.22222222 0.71428571 0.61538462 0.57142857 0.8\n",
      " 0.5        0.07692308 0.33333333 0.375      0.53333333 0.38461538\n",
      " 0.28571429 0.25       0.2        0.88888889 0.72727273 0.\n",
      " 0.55555556 0.41666667 0.27272727 0.5        0.66666667 0.6\n",
      " 0.28571429 0.46153846 0.16666667 0.875      0.         0.65\n",
      " 0.75       0.66666667 0.66666667 0.71428571 0.85714286 0.\n",
      " 0.85714286 0.2        0.42857143 0.         0.33333333 0.2\n",
      " 0.53846154 0.69230769 0.8        0.25       0.66666667 0.\n",
      " 0.625      0.33333333 0.6        0.625      0.18181818 0.\n",
      " 0.75       0.14285714 0.25       0.25       0.         0.\n",
      " 0.46666667 0.1        0.33333333 0.2        0.33333333 0.875\n",
      " 0.42857143 0.25       0.44444444 0.23076923 0.1875     0.\n",
      " 0.5        0.         0.72727273 0.33333333 0.33333333 0.54545455\n",
      " 0.4        0.6        0.33333333 0.70588235 0.33333333 0.35\n",
      " 0.33333333 0.28571429 0.44444444 0.58333333 0.18181818 0.27272727\n",
      " 0.2        0.4        0.         0.66666667 0.42857143 0.33333333\n",
      " 1.         0.75      ]\n",
      "Balanced Classification Rate:  [0.34055728 0.         0.4        0.1547619  0.57272727 0.36666667\n",
      " 0.44444444 0.         0.50793651 0.         0.47619048 0.39285714\n",
      " 0.45833333 0.5        0.52272727 0.31666667 0.4        0.34285714\n",
      " 0.6        0.5        0.2605042  0.41428571 0.28205128 0.46875\n",
      " 0.         0.         0.60267857 0.68571429 0.32222222 0.50793651\n",
      " 0.         0.41666667 0.19090909 0.31666667 0.64338235 0.56363636\n",
      " 0.38690476 0.2020202  0.68571429 0.25       0.58333333 0.2\n",
      " 0.45       0.63492063 0.73888889 0.63333333 0.6        0.56410256\n",
      " 0.54166667 0.45833333 0.         0.         0.64166667 0.32142857\n",
      " 0.         0.57142857 0.75       0.55528846 0.53333333 0.43956044\n",
      " 0.63636364 0.74175824 0.56818182 0.7        0.43560606 0.64772727\n",
      " 0.55072464 0.67132867 0.70673077 0.         0.62030075 0.46666667\n",
      " 0.         0.48717949 0.24285714 0.18333333 0.35       0.59027778\n",
      " 0.         0.41666667 0.60984848 0.78409091 0.65       0.45\n",
      " 0.58441558 0.48571429 0.5        0.25       0.31666667 0.63492063\n",
      " 0.625      0.33333333 0.32967033 0.33333333 0.31666667 0.\n",
      " 0.55       0.4        0.1625     0.62740385 0.23611111 0.50980392\n",
      " 0.4375     0.31111111 0.45918367 0.46769231 0.46753247 0.9\n",
      " 0.42391304 0.10989011 0.41666667 0.40178571 0.63030303 0.38461538\n",
      " 0.34285714 0.29166667 0.35       0.67973856 0.80808081 0.\n",
      " 0.63492063 0.43560606 0.32386364 0.375      0.54761905 0.4875\n",
      " 0.39285714 0.56410256 0.33333333 0.7875     0.         0.59583333\n",
      " 0.75       0.66666667 0.73333333 0.60714286 0.58646617 0.\n",
      " 0.7012987  0.2        0.38095238 0.         0.36666667 0.26666667\n",
      " 0.65811966 0.75524476 0.56666667 0.1875     0.4        0.\n",
      " 0.60661765 0.38095238 0.58125    0.47916667 0.21590909 0.\n",
      " 0.78409091 0.23809524 0.33928571 0.375      0.         0.\n",
      " 0.58333333 0.13333333 0.33333333 0.6        0.66666667 0.75568182\n",
      " 0.30803571 0.45833333 0.42222222 0.32967033 0.19375    0.\n",
      " 0.43181818 0.         0.72727273 0.29166667 0.55555556 0.52272727\n",
      " 0.36666667 0.6        0.41666667 0.70588235 0.54166667 0.425\n",
      " 0.5        0.30952381 0.47222222 0.54166667 0.23376623 0.23011364\n",
      " 0.3        0.36666667 0.         0.53333333 0.71428571 0.30952381\n",
      " 0.75       0.70833333]\n",
      "mini_batch 300\n",
      "mini_batch 301\n",
      "mini_batch 302\n",
      "mini_batch 303\n",
      "mini_batch 304\n",
      "mini_batch 305\n",
      "mini_batch 306\n",
      "mini_batch 307\n",
      "mini_batch 308\n",
      "mini_batch 309\n",
      "mini_batch 310\n",
      "mini_batch 311\n",
      "mini_batch 312\n",
      "mini_batch 313\n",
      "mini_batch 314\n",
      "mini_batch 315\n",
      "mini_batch 316\n",
      "mini_batch 317\n",
      "mini_batch 318\n",
      "mini_batch 319\n",
      "mini_batch 320\n",
      "mini_batch 321\n",
      "mini_batch 322\n",
      "mini_batch 323\n",
      "mini_batch 324\n",
      "mini_batch 325\n",
      "mini_batch 326\n",
      "mini_batch 327\n",
      "mini_batch 328\n",
      "mini_batch 329\n",
      "mini_batch 330\n",
      "mini_batch 331\n",
      "mini_batch 332\n",
      "mini_batch 333\n",
      "mini_batch 334\n",
      "mini_batch 335\n",
      "mini_batch 336\n",
      "mini_batch 337\n",
      "mini_batch 338\n",
      "mini_batch 339\n",
      "mini_batch 340\n",
      "mini_batch 341\n",
      "mini_batch 342\n",
      "mini_batch 343\n",
      "mini_batch 344\n",
      "mini_batch 345\n",
      "mini_batch 346\n",
      "mini_batch 347\n",
      "mini_batch 348\n",
      "mini_batch 349\n",
      "Epoch 4\n",
      "average minibatch 350 loss: 1.395\n",
      "\n",
      "Labels:  tensor([198,  22,  47, 117, 125, 164, 142,  16, 147,   1,  89, 148,  32,  35,\n",
      "        169, 169, 155,  89, 105,  66, 163,  22,  13, 170, 145,  12,  21, 158,\n",
      "         40, 110, 179, 114, 122,  56,  48,  41, 107, 101, 137, 137,  56, 133,\n",
      "        108, 171, 163, 127, 161,  25, 200, 163,  50, 126, 151, 105, 191,  77,\n",
      "        189,  67, 169, 101, 140, 146,  22, 161], device='cuda:0')\n",
      "Output:  tensor([198, 164,  47, 117, 125, 164, 142,  16,  10,   1,  89, 148,  32,  13,\n",
      "        179, 169, 155,  65, 105,  22, 143,  22,  13, 170, 145,  37,  21, 169,\n",
      "        143,  65, 179, 114, 122,  56,  48,  41, 107, 173, 137, 137,  56, 133,\n",
      "        108, 171, 163, 127, 161,  25, 200, 163,  50, 155, 151, 110,  53,   5,\n",
      "        189,  67, 169, 192, 140, 146,  22, 161], device='cuda:0')\n",
      "True Positives:  [ 9.  0.  2.  1.  6.  2.  5.  0.  8.  0.  2.  2.  7.  2.  6.  4.  4.  2.\n",
      "  1.  3.  5.  8.  3.  7.  1.  0.  9.  4.  4.  4.  0.  4.  2.  3.  7.  8.\n",
      " 10.  2.  4.  1.  5.  1.  2.  5.  7.  6.  4.  7.  3.  3.  0.  0.  7.  1.\n",
      "  0.  6.  2. 11.  8.  4.  3. 10.  7. 14.  5.  6. 11.  8.  7.  0. 10.  4.\n",
      "  0.  4.  2.  1.  1.  5.  0.  1.  7.  9.  4.  2.  5.  4.  4.  1.  4.  5.\n",
      "  1.  2.  3.  1.  3.  0.  3.  3.  1.  9.  2.  6.  3.  2. 11.  8.  5.  5.\n",
      "  8.  1.  3.  3.  8.  6.  2.  2.  2.  8.  8.  0.  5.  6.  3.  2.  7.  6.\n",
      "  5.  6.  1.  7.  0. 13.  4.  4.  4.  5.  8.  0.  6.  2.  3.  1.  2.  1.\n",
      "  8. 10.  4.  2.  2.  0. 11.  3.  9.  5.  3.  0.  9.  1.  3.  2.  2.  0.\n",
      "  9.  2.  1.  1.  1.  7.  5.  3.  5.  3.  3.  0.  4.  0.  8.  1.  8.  6.\n",
      "  2.  3.  1. 12.  3.  7.  2.  2.  5.  7.  2.  3.  2.  4.  0.  2.  3.  3.\n",
      "  1.  7.]\n",
      "False Positives:  [30.  1.  3.  6.  6.  4. 10.  3.  6.  4.  1.  2. 19.  1.  6.  7.  6.  5.\n",
      "  0.  1. 13.  9. 10.  9.  1.  0.  7.  3. 16.  3.  1.  3.  9.  6. 10. 12.\n",
      " 19.  7.  1.  2.  2.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  4.  1.\n",
      "  1.  3.  2. 15. 12.  3.  0.  4.  4.  6.  8.  2. 13.  5.  6.  2.  4. 11.\n",
      "  1.  9.  8.  4.  1.  3.  0.  2.  5.  3.  1.  2.  2.  6.  4.  2.  7.  4.\n",
      "  0.  4.  4.  1.  7.  1.  2.  7.  4.  7.  6.  3.  3.  3. 39. 17.  7.  0.\n",
      " 15.  7.  3.  4.  3.  8.  3.  4.  1.  9.  1.  3.  2.  6.  5.  6.  8. 10.\n",
      "  4.  3.  1.  3.  3. 11.  1.  2.  1.  5. 13.  2.  5.  4.  6.  3.  5.  2.\n",
      "  2.  2.  8.  7. 13.  0.  7.  4.  7. 10.  7.  2.  2.  2.  4.  2.  2.  0.\n",
      "  3.  6.  2.  0.  0.  4. 14.  1.  6.  4. 13.  2.  7.  0.  3.  3.  3.  6.\n",
      "  4.  2.  1.  5.  1.  7.  1.  4.  4.  7.  5. 14.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  2.  3.  5.  4.  3.  4.  3. 10.  3.  5.  6.  3.  4.  5.  6.  6.  3.\n",
      "  4.  9. 10. 10.  6.  7.  1.  0.  5.  1.  5.  5.  9.  6.  8.  7.  2.  3.\n",
      " 14.  9.  3.  6.  4.  4.  3.  4.  2.  4.  2.  7.  6.  6.  5.  5.  5.  6.\n",
      "  3.  3.  0.  5.  4.  9.  8.  3.  7.  6.  7.  6.  5.  3.  1.  6.  9.  2.\n",
      "  1.  2.  5.  5.  5.  4.  5.  1.  4.  2.  4.  3.  6.  3.  4.  5.  7.  2.\n",
      "  3.  4. 10.  5.  6.  2.  3.  3.  7.  4.  9. 11.  5.  7.  5.  5.  3.  1.\n",
      "  8. 13.  6.  5.  7.  8.  5.  6.  4.  1.  3.  3.  4.  7.  8.  2.  3.  5.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  2.  2.  1.  1.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  1.  2.  6.  6.  6.  3.  9.  1.  3.  7.  9.  6.  8.  4.\n",
      "  9.  9.  2.  4.  2.  1.  5.  6.  5. 10. 13.  4.  4.  5.  3.  2. 14.  5.\n",
      "  3.  2.  2.  5.  6. 13.  4.  5.  5.  5. 10.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.140625 0.       0.03125  0.015625 0.09375  0.03125  0.078125 0.\n",
      " 0.125    0.       0.03125  0.03125  0.109375 0.03125  0.09375  0.0625\n",
      " 0.0625   0.03125  0.015625 0.046875 0.078125 0.125    0.046875 0.109375\n",
      " 0.015625 0.       0.140625 0.0625   0.0625   0.0625   0.       0.0625\n",
      " 0.03125  0.046875 0.109375 0.125    0.15625  0.03125  0.0625   0.015625\n",
      " 0.078125 0.015625 0.03125  0.078125 0.109375 0.09375  0.0625   0.109375\n",
      " 0.046875 0.046875 0.       0.       0.109375 0.015625 0.       0.09375\n",
      " 0.03125  0.171875 0.125    0.0625   0.046875 0.15625  0.109375 0.21875\n",
      " 0.078125 0.09375  0.171875 0.125    0.109375 0.       0.15625  0.0625\n",
      " 0.       0.0625   0.03125  0.015625 0.015625 0.078125 0.       0.015625\n",
      " 0.109375 0.140625 0.0625   0.03125  0.078125 0.0625   0.0625   0.015625\n",
      " 0.0625   0.078125 0.015625 0.03125  0.046875 0.015625 0.046875 0.\n",
      " 0.046875 0.046875 0.015625 0.140625 0.03125  0.09375  0.046875 0.03125\n",
      " 0.171875 0.125    0.078125 0.078125 0.125    0.015625 0.046875 0.046875\n",
      " 0.125    0.09375  0.03125  0.03125  0.03125  0.125    0.125    0.\n",
      " 0.078125 0.09375  0.046875 0.03125  0.109375 0.09375  0.078125 0.09375\n",
      " 0.015625 0.109375 0.       0.203125 0.0625   0.0625   0.0625   0.078125\n",
      " 0.125    0.       0.09375  0.03125  0.046875 0.015625 0.03125  0.015625\n",
      " 0.125    0.15625  0.0625   0.03125  0.03125  0.       0.171875 0.046875\n",
      " 0.140625 0.078125 0.046875 0.       0.140625 0.015625 0.046875 0.03125\n",
      " 0.03125  0.       0.140625 0.03125  0.015625 0.015625 0.015625 0.109375\n",
      " 0.078125 0.046875 0.078125 0.046875 0.046875 0.       0.0625   0.\n",
      " 0.125    0.015625 0.125    0.09375  0.03125  0.046875 0.015625 0.1875\n",
      " 0.046875 0.109375 0.03125  0.03125  0.078125 0.109375 0.03125  0.046875\n",
      " 0.03125  0.0625   0.       0.03125  0.046875 0.046875 0.015625 0.109375]\n",
      "Precision:  [0.23076923 0.         0.4        0.14285714 0.5        0.33333333\n",
      " 0.33333333 0.         0.57142857 0.         0.66666667 0.5\n",
      " 0.26923077 0.66666667 0.5        0.36363636 0.4        0.28571429\n",
      " 1.         0.75       0.27777778 0.47058824 0.23076923 0.4375\n",
      " 0.5        0.         0.5625     0.57142857 0.2        0.57142857\n",
      " 0.         0.57142857 0.18181818 0.33333333 0.41176471 0.4\n",
      " 0.34482759 0.22222222 0.8        0.33333333 0.71428571 0.2\n",
      " 0.5        0.71428571 0.7        0.66666667 0.66666667 0.7\n",
      " 0.75       0.75       0.         0.         0.63636364 0.5\n",
      " 0.         0.66666667 0.5        0.42307692 0.4        0.57142857\n",
      " 1.         0.71428571 0.63636364 0.7        0.38461538 0.75\n",
      " 0.45833333 0.61538462 0.53846154 0.         0.71428571 0.26666667\n",
      " 0.         0.30769231 0.2        0.2        0.5        0.625\n",
      " 0.         0.33333333 0.58333333 0.75       0.8        0.5\n",
      " 0.71428571 0.4        0.5        0.33333333 0.36363636 0.55555556\n",
      " 1.         0.33333333 0.42857143 0.5        0.3        0.\n",
      " 0.6        0.3        0.2        0.5625     0.25       0.66666667\n",
      " 0.5        0.4        0.22       0.32       0.41666667 1.\n",
      " 0.34782609 0.125      0.5        0.42857143 0.72727273 0.42857143\n",
      " 0.4        0.33333333 0.66666667 0.47058824 0.88888889 0.\n",
      " 0.71428571 0.5        0.375      0.25       0.46666667 0.375\n",
      " 0.55555556 0.66666667 0.5        0.7        0.         0.54166667\n",
      " 0.8        0.66666667 0.8        0.5        0.38095238 0.\n",
      " 0.54545455 0.33333333 0.33333333 0.25       0.28571429 0.33333333\n",
      " 0.8        0.83333333 0.33333333 0.22222222 0.13333333 0.\n",
      " 0.61111111 0.42857143 0.5625     0.33333333 0.3        0.\n",
      " 0.81818182 0.33333333 0.42857143 0.5        0.5        0.\n",
      " 0.75       0.25       0.33333333 1.         1.         0.63636364\n",
      " 0.26315789 0.75       0.45454545 0.42857143 0.1875     0.\n",
      " 0.36363636 0.         0.72727273 0.25       0.72727273 0.5\n",
      " 0.33333333 0.6        0.5        0.70588235 0.75       0.5\n",
      " 0.66666667 0.33333333 0.55555556 0.5        0.28571429 0.17647059\n",
      " 0.4        0.33333333 0.         0.4        1.         0.375\n",
      " 0.5        0.7       ]\n",
      "Recall:  [0.5        0.         0.4        0.16666667 0.6        0.4\n",
      " 0.55555556 0.         0.44444444 0.         0.28571429 0.25\n",
      " 0.7        0.33333333 0.54545455 0.4        0.4        0.4\n",
      " 0.2        0.25       0.33333333 0.44444444 0.33333333 0.5\n",
      " 0.5        0.         0.64285714 0.8        0.44444444 0.44444444\n",
      " 0.         0.4        0.2        0.3        0.77777778 0.72727273\n",
      " 0.41666667 0.18181818 0.57142857 0.14285714 0.55555556 0.2\n",
      " 0.4        0.55555556 0.77777778 0.6        0.66666667 0.5\n",
      " 0.33333333 0.33333333 0.         0.         0.58333333 0.14285714\n",
      " 0.         0.66666667 1.         0.6875     0.66666667 0.30769231\n",
      " 0.27272727 0.76923077 0.5        0.7        0.41666667 0.5\n",
      " 0.6875     0.72727273 0.875      0.         0.52631579 0.66666667\n",
      " 0.         0.66666667 0.28571429 0.16666667 0.16666667 0.55555556\n",
      " 0.         0.5        0.63636364 0.81818182 0.5        0.4\n",
      " 0.45454545 0.57142857 0.5        0.16666667 0.36363636 0.71428571\n",
      " 0.25       0.33333333 0.23076923 0.16666667 0.33333333 0.\n",
      " 0.5        0.5        0.125      0.69230769 0.18181818 0.35294118\n",
      " 0.375      0.22222222 0.6875     0.61538462 0.625      0.83333333\n",
      " 0.5        0.07142857 0.33333333 0.375      0.53333333 0.42857143\n",
      " 0.28571429 0.25       0.33333333 0.88888889 0.72727273 0.\n",
      " 0.55555556 0.46153846 0.27272727 0.5        0.7        0.54545455\n",
      " 0.33333333 0.46153846 0.16666667 0.875      0.         0.65\n",
      " 0.8        0.66666667 0.66666667 0.71428571 0.88888889 0.\n",
      " 0.85714286 0.33333333 0.42857143 0.1        0.33333333 0.2\n",
      " 0.57142857 0.71428571 0.66666667 0.4        0.66666667 0.\n",
      " 0.64705882 0.33333333 0.6        0.625      0.25       0.\n",
      " 0.75       0.125      0.25       0.25       0.2        0.\n",
      " 0.5        0.18181818 0.33333333 0.2        0.33333333 0.875\n",
      " 0.5        0.33333333 0.5        0.23076923 0.1875     0.\n",
      " 0.5        0.         0.72727273 0.33333333 0.36363636 0.54545455\n",
      " 0.4        0.6        0.33333333 0.70588235 0.33333333 0.35\n",
      " 0.33333333 0.28571429 0.5        0.58333333 0.16666667 0.27272727\n",
      " 0.2        0.4        0.         0.66666667 0.42857143 0.42857143\n",
      " 1.         0.77777778]\n",
      "Balanced Classification Rate:  [0.36538462 0.         0.4        0.1547619  0.55       0.36666667\n",
      " 0.44444444 0.         0.50793651 0.         0.47619048 0.375\n",
      " 0.48461538 0.5        0.52272727 0.38181818 0.4        0.34285714\n",
      " 0.6        0.5        0.30555556 0.45751634 0.28205128 0.46875\n",
      " 0.5        0.         0.60267857 0.68571429 0.32222222 0.50793651\n",
      " 0.         0.48571429 0.19090909 0.31666667 0.59477124 0.56363636\n",
      " 0.38074713 0.2020202  0.68571429 0.23809524 0.63492063 0.2\n",
      " 0.45       0.63492063 0.73888889 0.63333333 0.66666667 0.6\n",
      " 0.54166667 0.54166667 0.         0.         0.60984848 0.32142857\n",
      " 0.         0.66666667 0.75       0.55528846 0.53333333 0.43956044\n",
      " 0.63636364 0.74175824 0.56818182 0.7        0.40064103 0.625\n",
      " 0.57291667 0.67132867 0.70673077 0.         0.62030075 0.46666667\n",
      " 0.         0.48717949 0.24285714 0.18333333 0.33333333 0.59027778\n",
      " 0.         0.41666667 0.60984848 0.78409091 0.65       0.45\n",
      " 0.58441558 0.48571429 0.5        0.25       0.36363636 0.63492063\n",
      " 0.625      0.33333333 0.32967033 0.33333333 0.31666667 0.\n",
      " 0.55       0.4        0.1625     0.62740385 0.21590909 0.50980392\n",
      " 0.4375     0.31111111 0.45375    0.46769231 0.52083333 0.91666667\n",
      " 0.42391304 0.09821429 0.41666667 0.40178571 0.63030303 0.42857143\n",
      " 0.34285714 0.29166667 0.5        0.67973856 0.80808081 0.\n",
      " 0.63492063 0.48076923 0.32386364 0.375      0.58333333 0.46022727\n",
      " 0.44444444 0.56410256 0.33333333 0.7875     0.         0.59583333\n",
      " 0.8        0.66666667 0.73333333 0.60714286 0.63492063 0.\n",
      " 0.7012987  0.33333333 0.38095238 0.175      0.30952381 0.26666667\n",
      " 0.68571429 0.77380952 0.5        0.31111111 0.4        0.\n",
      " 0.62908497 0.38095238 0.58125    0.47916667 0.275      0.\n",
      " 0.78409091 0.22916667 0.33928571 0.375      0.35       0.\n",
      " 0.625      0.21590909 0.33333333 0.6        0.66666667 0.75568182\n",
      " 0.38157895 0.54166667 0.47727273 0.32967033 0.1875     0.\n",
      " 0.43181818 0.         0.72727273 0.29166667 0.54545455 0.52272727\n",
      " 0.36666667 0.6        0.41666667 0.70588235 0.54166667 0.425\n",
      " 0.5        0.30952381 0.52777778 0.54166667 0.22619048 0.22459893\n",
      " 0.3        0.36666667 0.         0.53333333 0.71428571 0.40178571\n",
      " 0.75       0.73888889]\n",
      "mini_batch 350\n",
      "mini_batch 351\n",
      "mini_batch 352\n",
      "mini_batch 353\n",
      "mini_batch 354\n",
      "mini_batch 355\n",
      "mini_batch 356\n",
      "mini_batch 357\n",
      "mini_batch 358\n",
      "mini_batch 359\n",
      "mini_batch 360\n",
      "mini_batch 361\n",
      "mini_batch 362\n",
      "mini_batch 363\n",
      "mini_batch 364\n",
      "mini_batch 365\n",
      "mini_batch 366\n",
      "mini_batch 367\n",
      "mini_batch 368\n",
      "mini_batch 369\n",
      "mini_batch 370\n",
      "mini_batch 371\n",
      "mini_batch 372\n",
      "mini_batch 373\n",
      "mini_batch 374\n",
      "mini_batch 375\n",
      "Finished 4 epochs of training\n",
      "mini_batch 0\n",
      "mini_batch 1\n",
      "mini_batch 2\n",
      "mini_batch 3\n",
      "mini_batch 4\n",
      "mini_batch 5\n",
      "mini_batch 6\n",
      "mini_batch 7\n",
      "mini_batch 8\n",
      "mini_batch 9\n",
      "mini_batch 10\n",
      "mini_batch 11\n",
      "mini_batch 12\n",
      "mini_batch 13\n",
      "mini_batch 14\n",
      "mini_batch 15\n",
      "mini_batch 16\n",
      "mini_batch 17\n",
      "mini_batch 18\n",
      "mini_batch 19\n",
      "mini_batch 20\n",
      "mini_batch 21\n",
      "mini_batch 22\n",
      "mini_batch 23\n",
      "mini_batch 24\n",
      "mini_batch 25\n",
      "mini_batch 26\n",
      "mini_batch 27\n",
      "mini_batch 28\n",
      "mini_batch 29\n",
      "mini_batch 30\n",
      "mini_batch 31\n",
      "mini_batch 32\n",
      "mini_batch 33\n",
      "mini_batch 34\n",
      "mini_batch 35\n",
      "mini_batch 36\n",
      "mini_batch 37\n",
      "mini_batch 38\n",
      "mini_batch 39\n",
      "mini_batch 40\n",
      "mini_batch 41\n",
      "mini_batch 42\n",
      "mini_batch 43\n",
      "mini_batch 44\n",
      "mini_batch 45\n",
      "mini_batch 46\n",
      "mini_batch 47\n",
      "mini_batch 48\n",
      "mini_batch 49\n",
      "Epoch 5\n",
      "average minibatch 50 loss: 0.981\n",
      "\n",
      "Labels:  tensor([ 88, 195,  79,  70,  75,  62, 114, 107, 182, 143, 151, 195, 132,  36,\n",
      "         90,  22,  95, 117, 167,  70,  68,  34, 138,  68,  87,  10,  32,  72,\n",
      "          4,  81,  40,  50, 164, 125, 164,  18,  58, 109,  42,  28,  68, 182,\n",
      "        134, 182,  93, 136,  54, 190, 115,  33, 109, 107, 161,  62, 108,  57,\n",
      "         36,  21, 105, 169, 100,  54, 105, 130], device='cuda:0')\n",
      "Output:  tensor([ 88, 195,   1,  70,  75,  62, 114,  37, 182, 143, 151, 195, 132,  36,\n",
      "         90,  22,  22, 117, 167, 141,  68,  34, 102,  68,  87,  10,  32,  72,\n",
      "          4,  81,  53, 140, 164, 125, 164,  18,  58,   1,  42,  28,  68, 182,\n",
      "        134,  38, 151, 136,  54, 190, 134,  33, 109, 110, 161,  62, 108,  57,\n",
      "        159,  21, 105, 164, 100,  54,  85, 130], device='cuda:0')\n",
      "True Positives:  [ 9.  0.  2.  2.  6.  2.  5.  0.  8.  1.  2.  2.  7.  2.  6.  4.  4.  3.\n",
      "  1.  3.  6.  9.  3.  7.  1.  0.  9.  5.  4.  4.  0.  5.  3.  4.  7.  9.\n",
      " 10.  2.  4.  1.  5.  2.  2.  5.  7.  6.  4.  7.  3.  3.  0.  0.  7.  3.\n",
      "  0.  6.  3. 12.  8.  4.  3. 12.  7. 14.  5.  6. 11. 11.  7.  1. 10.  5.\n",
      "  0.  4.  3.  1.  1.  5.  0.  1.  8.  9.  4.  2.  5.  4.  5.  2.  4.  6.\n",
      "  1.  2.  3.  1.  3.  0.  3.  3.  1. 10.  2.  6.  3.  2. 12.  8.  5.  6.\n",
      "  9.  1.  3.  3.  8.  7.  2.  2.  3.  8.  8.  0.  5.  6.  3.  2.  8.  6.\n",
      "  5.  6.  1.  8.  0. 14.  4.  5.  4.  6.  8.  0.  6.  2.  3.  1.  3.  1.\n",
      "  8. 10.  4.  2.  2.  0. 12.  3.  9.  5.  3.  0.  9.  1.  3.  2.  3.  0.\n",
      "  9.  4.  1.  1.  2.  7.  5.  3.  5.  3.  3.  0.  4.  0.  8.  1.  8.  6.\n",
      "  2.  5.  1. 12.  3.  7.  2.  2.  5.  8.  2.  3.  2.  4.  2.  2.  3.  3.\n",
      "  1.  7.]\n",
      "False Positives:  [32.  1.  3.  6.  6.  4. 10.  3.  6.  4.  1.  2. 19.  1.  6.  7.  6.  5.\n",
      "  0.  1. 13. 10. 10.  9.  1.  0.  7.  3. 16.  3.  1.  3.  9.  6. 10. 12.\n",
      " 20.  8.  1.  2.  2.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  5.  1.\n",
      "  1.  3.  2. 15. 12.  3.  0.  4.  4.  6.  8.  2. 13.  5.  6.  2.  4. 11.\n",
      "  1.  9.  8.  4.  1.  3.  0.  2.  5.  3.  1.  2.  3.  6.  4.  2.  7.  4.\n",
      "  0.  4.  4.  1.  7.  1.  2.  7.  4.  7.  6.  4.  3.  3. 39. 17.  7.  0.\n",
      " 15.  8.  3.  4.  3.  8.  3.  4.  1.  9.  1.  3.  2.  6.  5.  6.  8. 10.\n",
      "  4.  3.  1.  3.  3. 11.  1.  3.  1.  5. 13.  2.  5.  5.  7.  3.  5.  2.\n",
      "  2.  2.  8.  7. 13.  0.  8.  4.  7. 10.  7.  2.  2.  2.  5.  2.  2.  0.\n",
      "  3.  7.  2.  0.  0.  4. 14.  1.  6.  4. 13.  2.  7.  0.  3.  3.  3.  6.\n",
      "  4.  2.  1.  5.  1.  7.  1.  4.  4.  7.  5. 14.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  2.  3.  5.  4.  3.  4.  3. 10.  3.  5.  6.  3.  4.  5.  6.  6.  3.\n",
      "  4.  9. 10. 10.  6.  7.  1.  0.  5.  1.  5.  5.  9.  6.  8.  7.  2.  4.\n",
      " 14.  9.  3.  7.  4.  4.  3.  4.  2.  4.  2.  7.  6.  7.  5.  5.  5.  6.\n",
      "  3.  3.  0.  5.  4.  9.  8.  3.  7.  6.  7.  6.  5.  3.  1.  7.  9.  2.\n",
      "  1.  2.  5.  5.  5.  4.  6.  1.  4.  2.  4.  3.  6.  3.  4.  5.  7.  2.\n",
      "  3.  4. 11.  5.  7.  2.  3.  3.  7.  4.  9. 11.  5.  7.  6.  5.  5.  1.\n",
      "  9. 13.  6.  5.  7.  8.  6.  6.  4.  1.  3.  3.  4.  7.  8.  2.  3.  5.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  2.  2.  1.  2.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  1.  2.  6.  6.  6.  3.  9.  1.  3.  7.  9.  6.  8.  4.\n",
      "  9.  9.  2.  4.  2.  1.  6.  6.  5. 10. 13.  4.  4.  5.  3.  2. 14.  5.\n",
      "  3.  3.  2.  5.  6. 13.  4.  5.  5.  5. 10.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.140625 0.       0.03125  0.03125  0.09375  0.03125  0.078125 0.\n",
      " 0.125    0.015625 0.03125  0.03125  0.109375 0.03125  0.09375  0.0625\n",
      " 0.0625   0.046875 0.015625 0.046875 0.09375  0.140625 0.046875 0.109375\n",
      " 0.015625 0.       0.140625 0.078125 0.0625   0.0625   0.       0.078125\n",
      " 0.046875 0.0625   0.109375 0.140625 0.15625  0.03125  0.0625   0.015625\n",
      " 0.078125 0.03125  0.03125  0.078125 0.109375 0.09375  0.0625   0.109375\n",
      " 0.046875 0.046875 0.       0.       0.109375 0.046875 0.       0.09375\n",
      " 0.046875 0.1875   0.125    0.0625   0.046875 0.1875   0.109375 0.21875\n",
      " 0.078125 0.09375  0.171875 0.171875 0.109375 0.015625 0.15625  0.078125\n",
      " 0.       0.0625   0.046875 0.015625 0.015625 0.078125 0.       0.015625\n",
      " 0.125    0.140625 0.0625   0.03125  0.078125 0.0625   0.078125 0.03125\n",
      " 0.0625   0.09375  0.015625 0.03125  0.046875 0.015625 0.046875 0.\n",
      " 0.046875 0.046875 0.015625 0.15625  0.03125  0.09375  0.046875 0.03125\n",
      " 0.1875   0.125    0.078125 0.09375  0.140625 0.015625 0.046875 0.046875\n",
      " 0.125    0.109375 0.03125  0.03125  0.046875 0.125    0.125    0.\n",
      " 0.078125 0.09375  0.046875 0.03125  0.125    0.09375  0.078125 0.09375\n",
      " 0.015625 0.125    0.       0.21875  0.0625   0.078125 0.0625   0.09375\n",
      " 0.125    0.       0.09375  0.03125  0.046875 0.015625 0.046875 0.015625\n",
      " 0.125    0.15625  0.0625   0.03125  0.03125  0.       0.1875   0.046875\n",
      " 0.140625 0.078125 0.046875 0.       0.140625 0.015625 0.046875 0.03125\n",
      " 0.046875 0.       0.140625 0.0625   0.015625 0.015625 0.03125  0.109375\n",
      " 0.078125 0.046875 0.078125 0.046875 0.046875 0.       0.0625   0.\n",
      " 0.125    0.015625 0.125    0.09375  0.03125  0.078125 0.015625 0.1875\n",
      " 0.046875 0.109375 0.03125  0.03125  0.078125 0.125    0.03125  0.046875\n",
      " 0.03125  0.0625   0.03125  0.03125  0.046875 0.046875 0.015625 0.109375]\n",
      "Precision:  [0.2195122  0.         0.4        0.25       0.5        0.33333333\n",
      " 0.33333333 0.         0.57142857 0.2        0.66666667 0.5\n",
      " 0.26923077 0.66666667 0.5        0.36363636 0.4        0.375\n",
      " 1.         0.75       0.31578947 0.47368421 0.23076923 0.4375\n",
      " 0.5        0.         0.5625     0.625      0.2        0.57142857\n",
      " 0.         0.625      0.25       0.4        0.41176471 0.42857143\n",
      " 0.33333333 0.2        0.8        0.33333333 0.71428571 0.33333333\n",
      " 0.5        0.71428571 0.7        0.66666667 0.66666667 0.7\n",
      " 0.75       0.75       0.         0.         0.58333333 0.75\n",
      " 0.         0.66666667 0.6        0.44444444 0.4        0.57142857\n",
      " 1.         0.75       0.63636364 0.7        0.38461538 0.75\n",
      " 0.45833333 0.6875     0.53846154 0.33333333 0.71428571 0.3125\n",
      " 0.         0.30769231 0.27272727 0.2        0.5        0.625\n",
      " 0.         0.33333333 0.61538462 0.75       0.8        0.5\n",
      " 0.625      0.4        0.55555556 0.5        0.36363636 0.6\n",
      " 1.         0.33333333 0.42857143 0.5        0.3        0.\n",
      " 0.6        0.3        0.2        0.58823529 0.25       0.6\n",
      " 0.5        0.4        0.23529412 0.32       0.41666667 1.\n",
      " 0.375      0.11111111 0.5        0.42857143 0.72727273 0.46666667\n",
      " 0.4        0.33333333 0.75       0.47058824 0.88888889 0.\n",
      " 0.71428571 0.5        0.375      0.25       0.5        0.375\n",
      " 0.55555556 0.66666667 0.5        0.72727273 0.         0.56\n",
      " 0.8        0.625      0.8        0.54545455 0.38095238 0.\n",
      " 0.54545455 0.28571429 0.3        0.25       0.375      0.33333333\n",
      " 0.8        0.83333333 0.33333333 0.22222222 0.13333333 0.\n",
      " 0.6        0.42857143 0.5625     0.33333333 0.3        0.\n",
      " 0.81818182 0.33333333 0.375      0.5        0.6        0.\n",
      " 0.75       0.36363636 0.33333333 1.         1.         0.63636364\n",
      " 0.26315789 0.75       0.45454545 0.42857143 0.1875     0.\n",
      " 0.36363636 0.         0.72727273 0.25       0.72727273 0.5\n",
      " 0.33333333 0.71428571 0.5        0.70588235 0.75       0.5\n",
      " 0.66666667 0.33333333 0.55555556 0.53333333 0.28571429 0.17647059\n",
      " 0.4        0.33333333 0.66666667 0.4        1.         0.375\n",
      " 0.5        0.7       ]\n",
      "Recall:  [0.5        0.         0.4        0.28571429 0.6        0.4\n",
      " 0.55555556 0.         0.44444444 0.25       0.28571429 0.25\n",
      " 0.7        0.33333333 0.54545455 0.4        0.4        0.5\n",
      " 0.2        0.25       0.375      0.47368421 0.33333333 0.5\n",
      " 0.5        0.         0.64285714 0.83333333 0.44444444 0.44444444\n",
      " 0.         0.45454545 0.27272727 0.36363636 0.77777778 0.69230769\n",
      " 0.41666667 0.18181818 0.57142857 0.125      0.55555556 0.33333333\n",
      " 0.4        0.55555556 0.77777778 0.6        0.66666667 0.5\n",
      " 0.33333333 0.3        0.         0.         0.58333333 0.33333333\n",
      " 0.         0.66666667 1.         0.70588235 0.66666667 0.30769231\n",
      " 0.27272727 0.8        0.5        0.7        0.41666667 0.5\n",
      " 0.6875     0.78571429 0.875      0.125      0.52631579 0.71428571\n",
      " 0.         0.66666667 0.375      0.16666667 0.16666667 0.55555556\n",
      " 0.         0.5        0.66666667 0.81818182 0.5        0.4\n",
      " 0.45454545 0.57142857 0.55555556 0.28571429 0.36363636 0.75\n",
      " 0.25       0.33333333 0.21428571 0.16666667 0.3        0.\n",
      " 0.5        0.5        0.125      0.71428571 0.18181818 0.35294118\n",
      " 0.375      0.22222222 0.66666667 0.61538462 0.5        0.85714286\n",
      " 0.5        0.07142857 0.33333333 0.375      0.53333333 0.46666667\n",
      " 0.25       0.25       0.42857143 0.88888889 0.72727273 0.\n",
      " 0.55555556 0.46153846 0.27272727 0.5        0.72727273 0.54545455\n",
      " 0.33333333 0.46153846 0.16666667 0.88888889 0.         0.66666667\n",
      " 0.8        0.71428571 0.66666667 0.75       0.88888889 0.\n",
      " 0.85714286 0.33333333 0.42857143 0.1        0.42857143 0.2\n",
      " 0.57142857 0.71428571 0.66666667 0.4        0.66666667 0.\n",
      " 0.66666667 0.33333333 0.6        0.625      0.25       0.\n",
      " 0.75       0.125      0.25       0.25       0.27272727 0.\n",
      " 0.5        0.30769231 0.33333333 0.2        0.5        0.875\n",
      " 0.45454545 0.33333333 0.5        0.23076923 0.1875     0.\n",
      " 0.5        0.         0.72727273 0.33333333 0.36363636 0.54545455\n",
      " 0.4        0.625      0.33333333 0.70588235 0.33333333 0.35\n",
      " 0.33333333 0.28571429 0.5        0.61538462 0.16666667 0.27272727\n",
      " 0.2        0.4        0.33333333 0.66666667 0.42857143 0.42857143\n",
      " 1.         0.77777778]\n",
      "Balanced Classification Rate:  [0.3597561  0.         0.4        0.26785714 0.55       0.36666667\n",
      " 0.44444444 0.         0.50793651 0.225      0.47619048 0.375\n",
      " 0.48461538 0.5        0.52272727 0.38181818 0.4        0.4375\n",
      " 0.6        0.5        0.34539474 0.47368421 0.28205128 0.46875\n",
      " 0.5        0.         0.60267857 0.72916667 0.32222222 0.50793651\n",
      " 0.         0.53977273 0.26136364 0.38181818 0.59477124 0.56043956\n",
      " 0.375      0.19090909 0.68571429 0.22916667 0.63492063 0.33333333\n",
      " 0.45       0.63492063 0.73888889 0.63333333 0.66666667 0.6\n",
      " 0.54166667 0.525      0.         0.         0.58333333 0.54166667\n",
      " 0.         0.66666667 0.8        0.5751634  0.53333333 0.43956044\n",
      " 0.63636364 0.775      0.56818182 0.7        0.40064103 0.625\n",
      " 0.57291667 0.73660714 0.70673077 0.22916667 0.62030075 0.51339286\n",
      " 0.         0.48717949 0.32386364 0.18333333 0.33333333 0.59027778\n",
      " 0.         0.41666667 0.64102564 0.78409091 0.65       0.45\n",
      " 0.53977273 0.48571429 0.55555556 0.39285714 0.36363636 0.675\n",
      " 0.625      0.33333333 0.32142857 0.33333333 0.3        0.\n",
      " 0.55       0.4        0.1625     0.6512605  0.21590909 0.47647059\n",
      " 0.4375     0.31111111 0.45098039 0.46769231 0.45833333 0.92857143\n",
      " 0.4375     0.09126984 0.41666667 0.40178571 0.63030303 0.46666667\n",
      " 0.325      0.29166667 0.58928571 0.67973856 0.80808081 0.\n",
      " 0.63492063 0.48076923 0.32386364 0.375      0.61363636 0.46022727\n",
      " 0.44444444 0.56410256 0.33333333 0.80808081 0.         0.61333333\n",
      " 0.8        0.66964286 0.73333333 0.64772727 0.63492063 0.\n",
      " 0.7012987  0.30952381 0.36428571 0.175      0.40178571 0.26666667\n",
      " 0.68571429 0.77380952 0.5        0.31111111 0.4        0.\n",
      " 0.63333333 0.38095238 0.58125    0.47916667 0.275      0.\n",
      " 0.78409091 0.22916667 0.3125     0.375      0.43636364 0.\n",
      " 0.625      0.33566434 0.33333333 0.6        0.75       0.75568182\n",
      " 0.35885167 0.54166667 0.47727273 0.32967033 0.1875     0.\n",
      " 0.43181818 0.         0.72727273 0.29166667 0.54545455 0.52272727\n",
      " 0.36666667 0.66964286 0.41666667 0.70588235 0.54166667 0.425\n",
      " 0.5        0.30952381 0.52777778 0.57435897 0.22619048 0.22459893\n",
      " 0.3        0.36666667 0.5        0.53333333 0.71428571 0.40178571\n",
      " 0.75       0.73888889]\n",
      "mini_batch 50\n",
      "mini_batch 51\n",
      "mini_batch 52\n",
      "mini_batch 53\n",
      "mini_batch 54\n",
      "mini_batch 55\n",
      "mini_batch 56\n",
      "mini_batch 57\n",
      "mini_batch 58\n",
      "mini_batch 59\n",
      "mini_batch 60\n",
      "mini_batch 61\n",
      "mini_batch 62\n",
      "mini_batch 63\n",
      "mini_batch 64\n",
      "mini_batch 65\n",
      "mini_batch 66\n",
      "mini_batch 67\n",
      "mini_batch 68\n",
      "mini_batch 69\n",
      "mini_batch 70\n",
      "mini_batch 71\n",
      "mini_batch 72\n",
      "mini_batch 73\n",
      "mini_batch 74\n",
      "mini_batch 75\n",
      "mini_batch 76\n",
      "mini_batch 77\n",
      "mini_batch 78\n",
      "mini_batch 79\n",
      "mini_batch 80\n",
      "mini_batch 81\n",
      "mini_batch 82\n",
      "mini_batch 83\n",
      "mini_batch 84\n",
      "mini_batch 85\n",
      "mini_batch 86\n",
      "mini_batch 87\n",
      "mini_batch 88\n",
      "mini_batch 89\n",
      "mini_batch 90\n",
      "mini_batch 91\n",
      "mini_batch 92\n",
      "mini_batch 93\n",
      "mini_batch 94\n",
      "mini_batch 95\n",
      "mini_batch 96\n",
      "mini_batch 97\n",
      "mini_batch 98\n",
      "mini_batch 99\n",
      "Epoch 5\n",
      "average minibatch 100 loss: 1.049\n",
      "\n",
      "Labels:  tensor([  5,  17,  36, 147,  93, 166,  94,  25, 170, 119,  86, 175, 154,  24,\n",
      "         94, 101,  85, 154, 119,  28,  35,  86, 186, 101, 111, 135,  27, 137,\n",
      "        125,  83, 106,  10,  36,  52,  85,  78,  23,  36,  32,  78, 159, 121,\n",
      "        114,   9, 153, 157, 131,  77,  65,   4,  58,  71, 101, 126,  83, 180,\n",
      "        171, 118,   6,  63, 103, 184, 138,  40], device='cuda:0')\n",
      "Output:  tensor([147,  17,  36, 147, 109, 107,   7,  25, 170, 119,  86, 175, 154, 120,\n",
      "         94, 101,  85, 154, 119,  28,  35,  86, 186, 101, 173, 106,  27, 182,\n",
      "        125,  83, 106,  56,  71,  61,  85,  78, 126,  36, 181,  78, 103, 121,\n",
      "        114,   9, 153, 157, 131,  38,  65,   4,  58,  71, 102, 126, 177, 180,\n",
      "        171, 118,   6,  63, 103, 184, 138,   1], device='cuda:0')\n",
      "True Positives:  [ 9.  0.  2.  3.  6.  3.  5.  0.  9.  1.  2.  2.  7.  2.  6.  4.  5.  3.\n",
      "  1.  3.  6.  9.  3.  7.  2.  0. 10.  6.  4.  4.  0.  5.  3.  4.  8. 11.\n",
      " 10.  2.  4.  1.  5.  2.  2.  5.  7.  6.  4.  7.  3.  3.  0.  0.  7.  3.\n",
      "  0.  6.  3. 13.  8.  4.  3. 12.  8. 14.  6.  6. 11. 11.  7.  1. 11.  5.\n",
      "  0.  4.  3.  1.  1.  7.  0.  1.  8.  9.  5.  2.  7.  6.  5.  2.  4.  6.\n",
      "  1.  2.  3.  2.  3.  0.  3.  3.  1. 10.  4.  6.  4.  2. 12.  9.  5.  6.\n",
      "  9.  1.  3.  3.  8.  8.  2.  2.  3.  9. 10.  0.  6.  6.  3.  2.  9.  7.\n",
      "  5.  6.  1.  8.  1. 14.  4.  5.  4.  6.  8.  1.  6.  2.  3.  1.  3.  1.\n",
      "  8. 10.  5.  2.  2.  0. 12.  3. 10.  7.  3.  0. 10.  1.  3.  2.  3.  0.\n",
      "  9.  4.  1.  1.  2.  7.  5.  4.  6.  3.  3.  0.  5.  0.  8.  1.  8.  7.\n",
      "  2.  5.  1. 13.  3.  8.  2.  2.  5.  8.  2.  3.  2.  4.  2.  2.  3.  3.\n",
      "  1.  7.]\n",
      "False Positives:  [33.  1.  3.  6.  6.  4. 11.  3.  6.  4.  1.  2. 19.  1.  6.  7.  6.  5.\n",
      "  0.  1. 13. 10. 10.  9.  1.  0.  7.  3. 16.  3.  1.  3.  9.  6. 10. 12.\n",
      " 20.  9.  1.  2.  2.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  5.  1.\n",
      "  1.  4.  2. 15. 12.  3.  1.  4.  4.  6.  8.  2. 13.  5.  6.  2.  5. 11.\n",
      "  1.  9.  8.  4.  1.  3.  0.  2.  5.  3.  1.  2.  3.  6.  4.  2.  7.  4.\n",
      "  0.  4.  4.  1.  7.  1.  2.  7.  4.  7.  6.  5.  4.  3. 39. 18.  8.  0.\n",
      " 16.  8.  3.  4.  3.  8.  3.  4.  1.  9.  1.  4.  2.  6.  5.  6.  8. 11.\n",
      "  4.  3.  1.  3.  3. 11.  1.  3.  1.  5. 13.  2.  5.  5.  7.  3.  5.  2.\n",
      "  2.  2.  9.  7. 13.  0.  8.  4.  7. 10.  7.  2.  2.  2.  5.  2.  2.  0.\n",
      "  3.  7.  2.  0.  0.  4. 14.  1.  6.  4. 14.  2.  7.  0.  4.  3.  3.  6.\n",
      "  5.  3.  1.  5.  1.  7.  1.  4.  4.  7.  5. 14.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  2.  3.  5.  5.  3.  4.  3. 10.  4.  5.  6.  3.  4.  5.  6.  6.  3.\n",
      "  4.  9. 10. 10.  7.  8.  1.  0.  5.  1.  5.  5.  9.  7.  8.  7.  2.  5.\n",
      " 14.  9.  3.  8.  4.  4.  3.  4.  2.  4.  2.  7.  6.  7.  5.  6.  5.  6.\n",
      "  3.  3.  0.  5.  4.  9.  8.  3.  7.  6.  7.  6.  5.  3.  1.  7.  9.  2.\n",
      "  1.  2.  5.  5.  6.  4.  6.  1.  4.  2.  5.  3.  6.  3.  4.  5.  7.  2.\n",
      "  3.  4. 12.  6.  7.  2.  3.  3.  7.  4. 10. 11.  5.  7.  6.  5.  5.  1.\n",
      "  9. 13.  7.  5.  7.  8.  6.  6.  4.  1.  3.  3.  4.  7.  8.  2.  3.  5.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  3.  2.  2.  2.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  1.  2.  6.  6.  6.  3.  9.  1.  3.  7. 10.  6.  8.  4.\n",
      "  9.  9.  2.  5.  2.  1.  6.  6.  5. 10. 13.  4.  4.  5.  3.  2. 14.  5.\n",
      "  3.  3.  2.  5.  6. 13.  4.  5.  5.  5. 10.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.140625 0.       0.03125  0.046875 0.09375  0.046875 0.078125 0.\n",
      " 0.140625 0.015625 0.03125  0.03125  0.109375 0.03125  0.09375  0.0625\n",
      " 0.078125 0.046875 0.015625 0.046875 0.09375  0.140625 0.046875 0.109375\n",
      " 0.03125  0.       0.15625  0.09375  0.0625   0.0625   0.       0.078125\n",
      " 0.046875 0.0625   0.125    0.171875 0.15625  0.03125  0.0625   0.015625\n",
      " 0.078125 0.03125  0.03125  0.078125 0.109375 0.09375  0.0625   0.109375\n",
      " 0.046875 0.046875 0.       0.       0.109375 0.046875 0.       0.09375\n",
      " 0.046875 0.203125 0.125    0.0625   0.046875 0.1875   0.125    0.21875\n",
      " 0.09375  0.09375  0.171875 0.171875 0.109375 0.015625 0.171875 0.078125\n",
      " 0.       0.0625   0.046875 0.015625 0.015625 0.109375 0.       0.015625\n",
      " 0.125    0.140625 0.078125 0.03125  0.109375 0.09375  0.078125 0.03125\n",
      " 0.0625   0.09375  0.015625 0.03125  0.046875 0.03125  0.046875 0.\n",
      " 0.046875 0.046875 0.015625 0.15625  0.0625   0.09375  0.0625   0.03125\n",
      " 0.1875   0.140625 0.078125 0.09375  0.140625 0.015625 0.046875 0.046875\n",
      " 0.125    0.125    0.03125  0.03125  0.046875 0.140625 0.15625  0.\n",
      " 0.09375  0.09375  0.046875 0.03125  0.140625 0.109375 0.078125 0.09375\n",
      " 0.015625 0.125    0.015625 0.21875  0.0625   0.078125 0.0625   0.09375\n",
      " 0.125    0.015625 0.09375  0.03125  0.046875 0.015625 0.046875 0.015625\n",
      " 0.125    0.15625  0.078125 0.03125  0.03125  0.       0.1875   0.046875\n",
      " 0.15625  0.109375 0.046875 0.       0.15625  0.015625 0.046875 0.03125\n",
      " 0.046875 0.       0.140625 0.0625   0.015625 0.015625 0.03125  0.109375\n",
      " 0.078125 0.0625   0.09375  0.046875 0.046875 0.       0.078125 0.\n",
      " 0.125    0.015625 0.125    0.109375 0.03125  0.078125 0.015625 0.203125\n",
      " 0.046875 0.125    0.03125  0.03125  0.078125 0.125    0.03125  0.046875\n",
      " 0.03125  0.0625   0.03125  0.03125  0.046875 0.046875 0.015625 0.109375]\n",
      "Precision:  [0.21428571 0.         0.4        0.33333333 0.5        0.42857143\n",
      " 0.3125     0.         0.6        0.2        0.66666667 0.5\n",
      " 0.26923077 0.66666667 0.5        0.36363636 0.45454545 0.375\n",
      " 1.         0.75       0.31578947 0.47368421 0.23076923 0.4375\n",
      " 0.66666667 0.         0.58823529 0.66666667 0.2        0.57142857\n",
      " 0.         0.625      0.25       0.4        0.44444444 0.47826087\n",
      " 0.33333333 0.18181818 0.8        0.33333333 0.71428571 0.33333333\n",
      " 0.5        0.71428571 0.7        0.66666667 0.66666667 0.7\n",
      " 0.75       0.75       0.         0.         0.58333333 0.75\n",
      " 0.         0.6        0.6        0.46428571 0.4        0.57142857\n",
      " 0.75       0.75       0.66666667 0.7        0.42857143 0.75\n",
      " 0.45833333 0.6875     0.53846154 0.33333333 0.6875     0.3125\n",
      " 0.         0.30769231 0.27272727 0.2        0.5        0.7\n",
      " 0.         0.33333333 0.61538462 0.75       0.83333333 0.5\n",
      " 0.7        0.5        0.55555556 0.5        0.36363636 0.6\n",
      " 1.         0.33333333 0.42857143 0.66666667 0.3        0.\n",
      " 0.6        0.3        0.2        0.58823529 0.4        0.54545455\n",
      " 0.5        0.4        0.23529412 0.33333333 0.38461538 1.\n",
      " 0.36       0.11111111 0.5        0.42857143 0.72727273 0.5\n",
      " 0.4        0.33333333 0.75       0.5        0.90909091 0.\n",
      " 0.75       0.5        0.375      0.25       0.52941176 0.38888889\n",
      " 0.55555556 0.66666667 0.5        0.72727273 0.25       0.56\n",
      " 0.8        0.625      0.8        0.54545455 0.38095238 0.33333333\n",
      " 0.54545455 0.28571429 0.3        0.25       0.375      0.33333333\n",
      " 0.8        0.83333333 0.35714286 0.22222222 0.13333333 0.\n",
      " 0.6        0.42857143 0.58823529 0.41176471 0.3        0.\n",
      " 0.83333333 0.33333333 0.375      0.5        0.6        0.\n",
      " 0.75       0.36363636 0.33333333 1.         1.         0.63636364\n",
      " 0.26315789 0.8        0.5        0.42857143 0.17647059 0.\n",
      " 0.41666667 0.         0.66666667 0.25       0.72727273 0.53846154\n",
      " 0.28571429 0.625      0.5        0.72222222 0.75       0.53333333\n",
      " 0.66666667 0.33333333 0.55555556 0.53333333 0.28571429 0.17647059\n",
      " 0.4        0.33333333 0.66666667 0.4        1.         0.375\n",
      " 0.5        0.7       ]\n",
      "Recall:  [0.5        0.         0.4        0.375      0.54545455 0.5\n",
      " 0.55555556 0.         0.47368421 0.2        0.28571429 0.25\n",
      " 0.7        0.33333333 0.54545455 0.4        0.45454545 0.5\n",
      " 0.2        0.25       0.375      0.47368421 0.3        0.46666667\n",
      " 0.66666667 0.         0.66666667 0.85714286 0.44444444 0.44444444\n",
      " 0.         0.41666667 0.27272727 0.36363636 0.8        0.6875\n",
      " 0.41666667 0.18181818 0.57142857 0.11111111 0.55555556 0.33333333\n",
      " 0.4        0.55555556 0.77777778 0.6        0.66666667 0.5\n",
      " 0.33333333 0.3        0.         0.         0.58333333 0.33333333\n",
      " 0.         0.66666667 1.         0.72222222 0.66666667 0.30769231\n",
      " 0.27272727 0.8        0.53333333 0.7        0.46153846 0.5\n",
      " 0.6875     0.78571429 0.875      0.125      0.55       0.71428571\n",
      " 0.         0.66666667 0.375      0.16666667 0.14285714 0.63636364\n",
      " 0.         0.5        0.66666667 0.81818182 0.5        0.4\n",
      " 0.53846154 0.66666667 0.55555556 0.28571429 0.36363636 0.75\n",
      " 0.25       0.33333333 0.2        0.25       0.3        0.\n",
      " 0.5        0.5        0.125      0.71428571 0.28571429 0.35294118\n",
      " 0.44444444 0.22222222 0.66666667 0.64285714 0.5        0.85714286\n",
      " 0.5        0.07142857 0.3        0.375      0.53333333 0.5\n",
      " 0.25       0.25       0.42857143 0.9        0.76923077 0.\n",
      " 0.6        0.46153846 0.27272727 0.5        0.75       0.58333333\n",
      " 0.33333333 0.46153846 0.16666667 0.88888889 0.11111111 0.66666667\n",
      " 0.8        0.71428571 0.57142857 0.75       0.8        0.33333333\n",
      " 0.85714286 0.33333333 0.42857143 0.1        0.42857143 0.2\n",
      " 0.57142857 0.71428571 0.71428571 0.4        0.66666667 0.\n",
      " 0.66666667 0.33333333 0.625      0.7        0.25       0.\n",
      " 0.76923077 0.125      0.23076923 0.25       0.27272727 0.\n",
      " 0.5        0.30769231 0.33333333 0.16666667 0.5        0.875\n",
      " 0.45454545 0.4        0.54545455 0.23076923 0.1875     0.\n",
      " 0.55555556 0.         0.72727273 0.33333333 0.36363636 0.58333333\n",
      " 0.4        0.625      0.33333333 0.72222222 0.33333333 0.38095238\n",
      " 0.33333333 0.28571429 0.5        0.61538462 0.16666667 0.27272727\n",
      " 0.2        0.4        0.33333333 0.66666667 0.42857143 0.42857143\n",
      " 1.         0.77777778]\n",
      "Balanced Classification Rate:  [0.35714286 0.         0.4        0.35416667 0.52272727 0.46428571\n",
      " 0.43402778 0.         0.53684211 0.2        0.47619048 0.375\n",
      " 0.48461538 0.5        0.52272727 0.38181818 0.45454545 0.4375\n",
      " 0.6        0.5        0.34539474 0.47368421 0.26538462 0.45208333\n",
      " 0.66666667 0.         0.62745098 0.76190476 0.32222222 0.50793651\n",
      " 0.         0.52083333 0.26136364 0.38181818 0.62222222 0.58288043\n",
      " 0.375      0.18181818 0.68571429 0.22222222 0.63492063 0.33333333\n",
      " 0.45       0.63492063 0.73888889 0.63333333 0.66666667 0.6\n",
      " 0.54166667 0.525      0.         0.         0.58333333 0.54166667\n",
      " 0.         0.63333333 0.8        0.59325397 0.53333333 0.43956044\n",
      " 0.51136364 0.775      0.6        0.7        0.44505495 0.625\n",
      " 0.57291667 0.73660714 0.70673077 0.22916667 0.61875    0.51339286\n",
      " 0.         0.48717949 0.32386364 0.18333333 0.32142857 0.66818182\n",
      " 0.         0.41666667 0.64102564 0.78409091 0.66666667 0.45\n",
      " 0.61923077 0.58333333 0.55555556 0.39285714 0.36363636 0.675\n",
      " 0.625      0.33333333 0.31428571 0.45833333 0.3        0.\n",
      " 0.55       0.4        0.1625     0.6512605  0.34285714 0.44919786\n",
      " 0.47222222 0.31111111 0.45098039 0.48809524 0.44230769 0.92857143\n",
      " 0.43       0.09126984 0.4        0.40178571 0.63030303 0.5\n",
      " 0.325      0.29166667 0.58928571 0.7        0.83916084 0.\n",
      " 0.675      0.48076923 0.32386364 0.375      0.63970588 0.48611111\n",
      " 0.44444444 0.56410256 0.33333333 0.80808081 0.18055556 0.61333333\n",
      " 0.8        0.66964286 0.68571429 0.64772727 0.59047619 0.33333333\n",
      " 0.7012987  0.30952381 0.36428571 0.175      0.40178571 0.26666667\n",
      " 0.68571429 0.77380952 0.53571429 0.31111111 0.4        0.\n",
      " 0.63333333 0.38095238 0.60661765 0.55588235 0.275      0.\n",
      " 0.80128205 0.22916667 0.30288462 0.375      0.43636364 0.\n",
      " 0.625      0.33566434 0.33333333 0.58333333 0.75       0.75568182\n",
      " 0.35885167 0.6        0.52272727 0.32967033 0.18198529 0.\n",
      " 0.48611111 0.         0.6969697  0.29166667 0.54545455 0.56089744\n",
      " 0.34285714 0.625      0.41666667 0.72222222 0.54166667 0.45714286\n",
      " 0.5        0.30952381 0.52777778 0.57435897 0.22619048 0.22459893\n",
      " 0.3        0.36666667 0.5        0.53333333 0.71428571 0.40178571\n",
      " 0.75       0.73888889]\n",
      "mini_batch 100\n",
      "mini_batch 101\n",
      "mini_batch 102\n",
      "mini_batch 103\n",
      "mini_batch 104\n",
      "mini_batch 105\n",
      "mini_batch 106\n",
      "mini_batch 107\n",
      "mini_batch 108\n",
      "mini_batch 109\n",
      "mini_batch 110\n",
      "mini_batch 111\n",
      "mini_batch 112\n",
      "mini_batch 113\n",
      "mini_batch 114\n",
      "mini_batch 115\n",
      "mini_batch 116\n",
      "mini_batch 117\n",
      "mini_batch 118\n",
      "mini_batch 119\n",
      "mini_batch 120\n",
      "mini_batch 121\n",
      "mini_batch 122\n",
      "mini_batch 123\n",
      "mini_batch 124\n",
      "mini_batch 125\n",
      "mini_batch 126\n",
      "mini_batch 127\n",
      "mini_batch 128\n",
      "mini_batch 129\n",
      "mini_batch 130\n",
      "mini_batch 131\n",
      "mini_batch 132\n",
      "mini_batch 133\n",
      "mini_batch 134\n",
      "mini_batch 135\n",
      "mini_batch 136\n",
      "mini_batch 137\n",
      "mini_batch 138\n",
      "mini_batch 139\n",
      "mini_batch 140\n",
      "mini_batch 141\n",
      "mini_batch 142\n",
      "mini_batch 143\n",
      "mini_batch 144\n",
      "mini_batch 145\n",
      "mini_batch 146\n",
      "mini_batch 147\n",
      "mini_batch 148\n",
      "mini_batch 149\n",
      "Epoch 5\n",
      "average minibatch 150 loss: 1.057\n",
      "\n",
      "Labels:  tensor([ 66,  20,  64, 125,  96, 146,   1,  17,  86, 172, 164,  86, 171, 191,\n",
      "        166,  70, 158, 126, 180, 181,   6,  42,  32,  52,  48, 200,  38, 113,\n",
      "        139,  12, 171, 103, 188,  89,  65, 171, 170, 192,  69, 169, 134, 114,\n",
      "         67,  71,  29,  18, 178, 105,  79,   9, 105, 113,  15,  32,   9, 178,\n",
      "         28,  33,  77,  80,  81,   4,  39,  69], device='cuda:0')\n",
      "Output:  tensor([ 66,  20,  64,  53, 122, 146,   1,  17,  86, 172, 109,  37, 171, 131,\n",
      "         21,  70, 158,  38, 180, 143,   6,  42,  32,  52,  48, 200,  38, 113,\n",
      "        139,  67, 171, 103, 188,  66,  65, 171, 170, 192,  69, 169, 134,  33,\n",
      "         67,  38,  29,  18, 178, 105,  79,   9, 105,  55,  15,  32,   9, 178,\n",
      "         28, 169,  77,  80,  81,   4,  39,  69], device='cuda:0')\n",
      "True Positives:  [10.  0.  2.  4.  6.  4.  5.  0. 11.  1.  2.  2.  7.  2.  7.  4.  6.  4.\n",
      "  1.  4.  6.  9.  3.  7.  2.  0. 10.  7.  5.  4.  0.  7.  3.  4.  8. 11.\n",
      " 10.  3.  5.  1.  5.  3.  2.  5.  7.  6.  4.  8.  3.  3.  0.  1.  7.  3.\n",
      "  0.  6.  3. 13.  8.  4.  3. 12.  8. 15.  7.  7. 12. 11.  9.  2. 11.  5.\n",
      "  0.  4.  3.  1.  2.  7.  1.  2.  9.  9.  5.  2.  7.  7.  5.  2.  4.  6.\n",
      "  1.  2.  3.  2.  3.  0.  3.  3.  1. 10.  4.  6.  5.  2. 14.  9.  5.  6.\n",
      "  9.  1.  3.  3.  9.  8.  2.  2.  3.  9. 10.  0.  6.  6.  3.  2.  9.  7.\n",
      "  5.  6.  1.  8.  1. 14.  4.  6.  4.  6.  8.  1.  7.  2.  3.  1.  3.  1.\n",
      "  8. 11.  5.  2.  2.  0. 12.  3. 10.  7.  3.  0. 10.  2.  3.  2.  3.  0.\n",
      "  9.  4.  1.  1.  2.  7.  6.  5.  9.  4.  3.  0.  5.  0.  8.  3.  8.  8.\n",
      "  2.  5.  1. 13.  3.  8.  2.  3.  5.  8.  2.  4.  2.  4.  2.  2.  3.  3.\n",
      "  1.  8.]\n",
      "False Positives:  [33.  1.  3.  6.  6.  4. 11.  3.  6.  4.  1.  2. 19.  1.  6.  7.  6.  5.\n",
      "  0.  1. 14. 10. 10.  9.  1.  0.  7.  3. 16.  3.  1.  3. 10.  6. 10. 12.\n",
      " 21. 11.  1.  2.  2.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  6.  1.\n",
      "  2.  4.  2. 15. 12.  3.  1.  4.  4.  6.  8.  3. 14.  5.  6.  2.  5. 11.\n",
      "  1.  9.  8.  4.  1.  3.  0.  2.  5.  3.  1.  2.  3.  6.  4.  2.  7.  4.\n",
      "  0.  4.  4.  1.  7.  1.  2.  7.  4.  7.  6.  5.  4.  3. 39. 18.  8.  0.\n",
      " 17.  8.  3.  4.  3.  8.  3.  4.  1.  9.  1.  4.  2.  7.  5.  6.  8. 11.\n",
      "  4.  3.  1.  3.  4. 11.  1.  3.  1.  5. 13.  2.  5.  5.  7.  3.  6.  2.\n",
      "  2.  2.  9.  7. 13.  0.  8.  4.  7. 10.  7.  2.  2.  2.  5.  2.  2.  0.\n",
      "  3.  7.  2.  0.  0.  4. 15.  1.  6.  4. 14.  2.  7.  0.  4.  3.  3.  6.\n",
      "  5.  3.  1.  5.  1.  7.  1.  4.  4.  7.  5. 14.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [ 9.  2.  3.  5.  5.  3.  4.  3. 10.  4.  5.  7.  3.  4.  5.  6.  6.  3.\n",
      "  4.  9. 10. 10.  7.  8.  1.  0.  5.  1.  5.  5.  9.  7.  9.  7.  2.  5.\n",
      " 14.  9.  3.  8.  4.  4.  3.  4.  2.  4.  2.  7.  6.  7.  5.  6.  5.  6.\n",
      "  3.  3.  0.  5.  4.  9.  8.  3.  7.  6.  7.  6.  5.  3.  1.  7. 10.  2.\n",
      "  1.  2.  5.  5.  6.  4.  6.  1.  4.  2.  5.  3.  6.  4.  4.  5.  8.  2.\n",
      "  3.  4. 12.  6.  7.  3.  3.  3.  7.  4. 10. 11.  5.  7.  6.  5.  5.  1.\n",
      "  9. 13.  7.  5.  8.  9.  6.  6.  4.  1.  3.  3.  4.  7.  8.  2.  4.  6.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  3.  2.  2.  2.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  1.  2.  6.  6.  6.  3.  9.  1.  3.  7. 10.  6.  8.  4.\n",
      "  9. 10.  2.  6.  2.  1.  6.  6.  5. 10. 13.  4.  4.  5.  3.  2. 14.  5.\n",
      "  4.  3.  2.  5.  6. 13.  4.  5.  5.  5. 11.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.15625  0.       0.03125  0.0625   0.09375  0.0625   0.078125 0.\n",
      " 0.171875 0.015625 0.03125  0.03125  0.109375 0.03125  0.109375 0.0625\n",
      " 0.09375  0.0625   0.015625 0.0625   0.09375  0.140625 0.046875 0.109375\n",
      " 0.03125  0.       0.15625  0.109375 0.078125 0.0625   0.       0.109375\n",
      " 0.046875 0.0625   0.125    0.171875 0.15625  0.046875 0.078125 0.015625\n",
      " 0.078125 0.046875 0.03125  0.078125 0.109375 0.09375  0.0625   0.125\n",
      " 0.046875 0.046875 0.       0.015625 0.109375 0.046875 0.       0.09375\n",
      " 0.046875 0.203125 0.125    0.0625   0.046875 0.1875   0.125    0.234375\n",
      " 0.109375 0.109375 0.1875   0.171875 0.140625 0.03125  0.171875 0.078125\n",
      " 0.       0.0625   0.046875 0.015625 0.03125  0.109375 0.015625 0.03125\n",
      " 0.140625 0.140625 0.078125 0.03125  0.109375 0.109375 0.078125 0.03125\n",
      " 0.0625   0.09375  0.015625 0.03125  0.046875 0.03125  0.046875 0.\n",
      " 0.046875 0.046875 0.015625 0.15625  0.0625   0.09375  0.078125 0.03125\n",
      " 0.21875  0.140625 0.078125 0.09375  0.140625 0.015625 0.046875 0.046875\n",
      " 0.140625 0.125    0.03125  0.03125  0.046875 0.140625 0.15625  0.\n",
      " 0.09375  0.09375  0.046875 0.03125  0.140625 0.109375 0.078125 0.09375\n",
      " 0.015625 0.125    0.015625 0.21875  0.0625   0.09375  0.0625   0.09375\n",
      " 0.125    0.015625 0.109375 0.03125  0.046875 0.015625 0.046875 0.015625\n",
      " 0.125    0.171875 0.078125 0.03125  0.03125  0.       0.1875   0.046875\n",
      " 0.15625  0.109375 0.046875 0.       0.15625  0.03125  0.046875 0.03125\n",
      " 0.046875 0.       0.140625 0.0625   0.015625 0.015625 0.03125  0.109375\n",
      " 0.09375  0.078125 0.140625 0.0625   0.046875 0.       0.078125 0.\n",
      " 0.125    0.046875 0.125    0.125    0.03125  0.078125 0.015625 0.203125\n",
      " 0.046875 0.125    0.03125  0.046875 0.078125 0.125    0.03125  0.0625\n",
      " 0.03125  0.0625   0.03125  0.03125  0.046875 0.046875 0.015625 0.125   ]\n",
      "Precision:  [0.23255814 0.         0.4        0.4        0.5        0.5\n",
      " 0.3125     0.         0.64705882 0.2        0.66666667 0.5\n",
      " 0.26923077 0.66666667 0.53846154 0.36363636 0.5        0.44444444\n",
      " 1.         0.8        0.3        0.47368421 0.23076923 0.4375\n",
      " 0.66666667 0.         0.58823529 0.7        0.23809524 0.57142857\n",
      " 0.         0.7        0.23076923 0.4        0.44444444 0.47826087\n",
      " 0.32258065 0.21428571 0.83333333 0.33333333 0.71428571 0.42857143\n",
      " 0.5        0.71428571 0.7        0.66666667 0.66666667 0.72727273\n",
      " 0.75       0.75       0.         1.         0.53846154 0.75\n",
      " 0.         0.6        0.6        0.46428571 0.4        0.57142857\n",
      " 0.75       0.75       0.66666667 0.71428571 0.46666667 0.7\n",
      " 0.46153846 0.6875     0.6        0.5        0.6875     0.3125\n",
      " 0.         0.30769231 0.27272727 0.2        0.66666667 0.7\n",
      " 1.         0.5        0.64285714 0.75       0.83333333 0.5\n",
      " 0.7        0.53846154 0.55555556 0.5        0.36363636 0.6\n",
      " 1.         0.33333333 0.42857143 0.66666667 0.3        0.\n",
      " 0.6        0.3        0.2        0.58823529 0.4        0.54545455\n",
      " 0.55555556 0.4        0.26415094 0.33333333 0.38461538 1.\n",
      " 0.34615385 0.11111111 0.5        0.42857143 0.75       0.5\n",
      " 0.4        0.33333333 0.75       0.5        0.90909091 0.\n",
      " 0.75       0.46153846 0.375      0.25       0.52941176 0.38888889\n",
      " 0.55555556 0.66666667 0.5        0.72727273 0.2        0.56\n",
      " 0.8        0.66666667 0.8        0.54545455 0.38095238 0.33333333\n",
      " 0.58333333 0.28571429 0.3        0.25       0.33333333 0.33333333\n",
      " 0.8        0.84615385 0.35714286 0.22222222 0.13333333 0.\n",
      " 0.6        0.42857143 0.58823529 0.41176471 0.3        0.\n",
      " 0.83333333 0.5        0.375      0.5        0.6        0.\n",
      " 0.75       0.36363636 0.33333333 1.         1.         0.63636364\n",
      " 0.28571429 0.83333333 0.6        0.5        0.17647059 0.\n",
      " 0.41666667 0.         0.66666667 0.5        0.72727273 0.57142857\n",
      " 0.28571429 0.625      0.5        0.72222222 0.75       0.53333333\n",
      " 0.66666667 0.42857143 0.55555556 0.53333333 0.28571429 0.22222222\n",
      " 0.4        0.33333333 0.66666667 0.4        1.         0.375\n",
      " 0.5        0.72727273]\n",
      "Recall:  [0.52631579 0.         0.4        0.44444444 0.54545455 0.57142857\n",
      " 0.55555556 0.         0.52380952 0.2        0.28571429 0.22222222\n",
      " 0.7        0.33333333 0.58333333 0.4        0.5        0.57142857\n",
      " 0.2        0.30769231 0.375      0.47368421 0.3        0.46666667\n",
      " 0.66666667 0.         0.66666667 0.875      0.5        0.44444444\n",
      " 0.         0.5        0.25       0.36363636 0.8        0.6875\n",
      " 0.41666667 0.25       0.625      0.11111111 0.55555556 0.42857143\n",
      " 0.4        0.55555556 0.77777778 0.6        0.66666667 0.53333333\n",
      " 0.33333333 0.3        0.         0.14285714 0.58333333 0.33333333\n",
      " 0.         0.66666667 1.         0.72222222 0.66666667 0.30769231\n",
      " 0.27272727 0.8        0.53333333 0.71428571 0.5        0.53846154\n",
      " 0.70588235 0.78571429 0.9        0.22222222 0.52380952 0.71428571\n",
      " 0.         0.66666667 0.375      0.16666667 0.25       0.63636364\n",
      " 0.14285714 0.66666667 0.69230769 0.81818182 0.5        0.4\n",
      " 0.53846154 0.63636364 0.55555556 0.28571429 0.33333333 0.75\n",
      " 0.25       0.33333333 0.2        0.25       0.3        0.\n",
      " 0.5        0.5        0.125      0.71428571 0.28571429 0.35294118\n",
      " 0.5        0.22222222 0.7        0.64285714 0.5        0.85714286\n",
      " 0.5        0.07142857 0.3        0.375      0.52941176 0.47058824\n",
      " 0.25       0.25       0.42857143 0.9        0.76923077 0.\n",
      " 0.6        0.46153846 0.27272727 0.5        0.69230769 0.53846154\n",
      " 0.33333333 0.46153846 0.16666667 0.88888889 0.11111111 0.66666667\n",
      " 0.8        0.75       0.57142857 0.75       0.8        0.33333333\n",
      " 0.875      0.33333333 0.42857143 0.1        0.42857143 0.2\n",
      " 0.57142857 0.73333333 0.71428571 0.4        0.66666667 0.\n",
      " 0.66666667 0.33333333 0.625      0.7        0.25       0.\n",
      " 0.76923077 0.22222222 0.23076923 0.25       0.27272727 0.\n",
      " 0.5        0.28571429 0.33333333 0.14285714 0.5        0.875\n",
      " 0.5        0.45454545 0.64285714 0.28571429 0.1875     0.\n",
      " 0.55555556 0.         0.72727273 0.6        0.36363636 0.61538462\n",
      " 0.33333333 0.625      0.33333333 0.72222222 0.33333333 0.38095238\n",
      " 0.33333333 0.375      0.5        0.61538462 0.15384615 0.33333333\n",
      " 0.2        0.4        0.33333333 0.66666667 0.42857143 0.42857143\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.37943696 0.         0.4        0.42222222 0.52272727 0.53571429\n",
      " 0.43402778 0.         0.58543417 0.2        0.47619048 0.36111111\n",
      " 0.48461538 0.5        0.56089744 0.38181818 0.5        0.50793651\n",
      " 0.6        0.55384615 0.3375     0.47368421 0.26538462 0.45208333\n",
      " 0.66666667 0.         0.62745098 0.7875     0.36904762 0.50793651\n",
      " 0.         0.6        0.24038462 0.38181818 0.62222222 0.58288043\n",
      " 0.36962366 0.23214286 0.72916667 0.22222222 0.63492063 0.42857143\n",
      " 0.45       0.63492063 0.73888889 0.63333333 0.66666667 0.63030303\n",
      " 0.54166667 0.525      0.         0.57142857 0.56089744 0.54166667\n",
      " 0.         0.63333333 0.8        0.59325397 0.53333333 0.43956044\n",
      " 0.51136364 0.775      0.6        0.71428571 0.48333333 0.61923077\n",
      " 0.58371041 0.73660714 0.75       0.36111111 0.60565476 0.51339286\n",
      " 0.         0.48717949 0.32386364 0.18333333 0.45833333 0.66818182\n",
      " 0.57142857 0.58333333 0.66758242 0.78409091 0.66666667 0.45\n",
      " 0.61923077 0.58741259 0.55555556 0.39285714 0.34848485 0.675\n",
      " 0.625      0.33333333 0.31428571 0.45833333 0.3        0.\n",
      " 0.55       0.4        0.1625     0.6512605  0.34285714 0.44919786\n",
      " 0.52777778 0.31111111 0.48207547 0.48809524 0.44230769 0.92857143\n",
      " 0.42307692 0.09126984 0.4        0.40178571 0.63970588 0.48529412\n",
      " 0.325      0.29166667 0.58928571 0.7        0.83916084 0.\n",
      " 0.675      0.46153846 0.32386364 0.375      0.61085973 0.46367521\n",
      " 0.44444444 0.56410256 0.33333333 0.80808081 0.15555556 0.61333333\n",
      " 0.8        0.70833333 0.68571429 0.64772727 0.59047619 0.33333333\n",
      " 0.72916667 0.30952381 0.36428571 0.175      0.38095238 0.26666667\n",
      " 0.68571429 0.78974359 0.53571429 0.31111111 0.4        0.\n",
      " 0.63333333 0.38095238 0.60661765 0.55588235 0.275      0.\n",
      " 0.80128205 0.36111111 0.30288462 0.375      0.43636364 0.\n",
      " 0.625      0.32467532 0.33333333 0.57142857 0.75       0.75568182\n",
      " 0.39285714 0.64393939 0.62142857 0.39285714 0.18198529 0.\n",
      " 0.48611111 0.         0.6969697  0.55       0.54545455 0.59340659\n",
      " 0.30952381 0.625      0.41666667 0.72222222 0.54166667 0.45714286\n",
      " 0.5        0.40178571 0.52777778 0.57435897 0.21978022 0.27777778\n",
      " 0.3        0.36666667 0.5        0.53333333 0.71428571 0.40178571\n",
      " 0.75       0.76363636]\n",
      "mini_batch 150\n",
      "mini_batch 151\n",
      "mini_batch 152\n",
      "mini_batch 153\n",
      "mini_batch 154\n",
      "mini_batch 155\n",
      "mini_batch 156\n",
      "mini_batch 157\n",
      "mini_batch 158\n",
      "mini_batch 159\n",
      "mini_batch 160\n",
      "mini_batch 161\n",
      "mini_batch 162\n",
      "mini_batch 163\n",
      "mini_batch 164\n",
      "mini_batch 165\n",
      "mini_batch 166\n",
      "mini_batch 167\n",
      "mini_batch 168\n",
      "mini_batch 169\n",
      "mini_batch 170\n",
      "mini_batch 171\n",
      "mini_batch 172\n",
      "mini_batch 173\n",
      "mini_batch 174\n",
      "mini_batch 175\n",
      "mini_batch 176\n",
      "mini_batch 177\n",
      "mini_batch 178\n",
      "mini_batch 179\n",
      "mini_batch 180\n",
      "mini_batch 181\n",
      "mini_batch 182\n",
      "mini_batch 183\n",
      "mini_batch 184\n",
      "mini_batch 185\n",
      "mini_batch 186\n",
      "mini_batch 187\n",
      "mini_batch 188\n",
      "mini_batch 189\n",
      "mini_batch 190\n",
      "mini_batch 191\n",
      "mini_batch 192\n",
      "mini_batch 193\n",
      "mini_batch 194\n",
      "mini_batch 195\n",
      "mini_batch 196\n",
      "mini_batch 197\n",
      "mini_batch 198\n",
      "mini_batch 199\n",
      "Epoch 5\n",
      "average minibatch 200 loss: 1.061\n",
      "\n",
      "Labels:  tensor([ 24,   1, 179,  62,  53,  38,  35,  69, 190,  41,  10,  30,  81,  48,\n",
      "        171,  63, 188, 140,  28,  47,  82,   5, 169, 159, 177,  65,  83, 129,\n",
      "        184, 101,  10, 115,  22,  85, 117,  72, 110,  43,  71,  89,  67,   6,\n",
      "        155,   6, 105,  43,  71, 112,  27, 153, 154,   8,  51,  63,  67,  88,\n",
      "         36,   8, 101, 173,  51,  22, 137,  95], device='cuda:0')\n",
      "Output:  tensor([ 95,  79, 179,  62, 139,  38,  35,  69, 190,  41,  10,  30,   4,  48,\n",
      "        171,  33,  37, 140,  28,  47,  82,   5, 169, 159, 177,  65,  41, 129,\n",
      "        129, 101,  20, 115,  89,  85, 117,  72, 110,  43,  71,  89,  67,   6,\n",
      "        155,   6, 105,  43,  87, 112, 170, 153, 154,   8,  29, 152,  67,  88,\n",
      "         36,   8, 101, 173,  76,  93, 117,  95], device='cuda:0')\n",
      "True Positives:  [10.  0.  2.  4.  7.  6.  5.  2. 11.  2.  2.  2.  7.  2.  7.  4.  6.  4.\n",
      "  1.  4.  6.  9.  3.  7.  2.  0. 10.  8.  5.  5.  0.  7.  3.  4.  9. 12.\n",
      " 10.  4.  5.  1.  6.  3.  4.  5.  7.  6.  5.  9.  3.  3.  0.  1.  7.  3.\n",
      "  0.  6.  3. 13.  8.  4.  3. 13.  8. 15.  8.  7. 14. 11. 10.  2. 12.  6.\n",
      "  0.  4.  3.  1.  2.  7.  1.  2.  9. 10.  5.  2.  8.  7.  5.  3.  5.  6.\n",
      "  1.  2.  3.  2.  4.  0.  3.  3.  1. 10.  6.  6.  5.  2. 15.  9.  5.  6.\n",
      "  9.  2.  3.  4.  9.  8.  3.  2.  4.  9. 10.  0.  6.  6.  3.  2.  9.  7.\n",
      "  5.  6.  2.  8.  1. 14.  4.  6.  4.  6.  8.  1.  7.  3.  3.  1.  3.  1.\n",
      "  8. 11.  5.  2.  2.  0. 12.  3. 11.  8.  4.  0. 10.  2.  4.  2.  3.  0.\n",
      "  9.  4.  1.  1.  2.  7.  7.  5. 10.  4.  4.  0.  5.  0.  9.  3.  9.  8.\n",
      "  2.  5.  1. 13.  3.  8.  2.  3.  5.  9.  2.  4.  2.  4.  2.  2.  3.  3.\n",
      "  1.  8.]\n",
      "False Positives:  [33.  1.  3.  7.  6.  4. 11.  3.  6.  4.  1.  2. 19.  1.  6.  7.  6.  5.\n",
      "  0.  2. 14. 10. 10.  9.  1.  0.  7.  3. 17.  3.  1.  3. 11.  6. 10. 12.\n",
      " 22. 11.  1.  2.  3.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  6.  1.\n",
      "  2.  4.  2. 15. 12.  3.  1.  4.  4.  6.  8.  3. 14.  5.  6.  2.  5. 11.\n",
      "  1.  9.  8.  5.  1.  3.  1.  2.  5.  3.  1.  2.  3.  6.  5.  2.  8.  4.\n",
      "  0.  4.  5.  1.  8.  1.  2.  7.  4.  7.  6.  5.  4.  3. 39. 18.  8.  0.\n",
      " 17.  8.  3.  4.  3.  8.  3.  4.  2.  9.  1.  4.  2.  7.  5.  6.  8. 11.\n",
      "  4.  3.  2.  3.  4. 11.  1.  3.  1.  5. 13.  2.  6.  5.  7.  3.  6.  2.\n",
      "  2.  2.  9.  7. 13.  0.  8.  5.  7. 10.  7.  2.  2.  2.  5.  2.  2.  0.\n",
      "  3.  7.  2.  0.  0.  4. 15.  2.  6.  4. 14.  2.  7.  0.  4.  3.  3.  6.\n",
      "  5.  3.  1.  5.  1.  7.  1.  4.  4.  7.  5. 14.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [10.  2.  3.  5.  5.  3.  4.  3. 10.  5.  5.  7.  3.  4.  5.  6.  6.  3.\n",
      "  4.  9. 10. 12.  7.  9.  1.  0.  6.  1.  5.  5.  9.  7.  9.  7.  2.  5.\n",
      " 14.  9.  3.  8.  4.  4.  3.  4.  2.  4.  2.  7.  6.  7.  7.  6.  6.  6.\n",
      "  3.  3.  0.  5.  4.  9.  8.  3.  9.  6.  7.  6.  5.  3.  1.  7. 11.  2.\n",
      "  1.  2.  5.  5.  6.  4.  6.  1.  5.  2.  6.  3.  6.  4.  4.  5.  8.  2.\n",
      "  3.  4. 12.  6.  7.  3.  3.  3.  7.  4. 10. 11.  5.  7.  6.  5.  5.  1.\n",
      "  9. 13.  7.  5.  8.  9.  6.  6.  4.  1.  3.  3.  4.  7.  8.  2.  4.  6.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  3.  2.  3.  2.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  1.  2.  6.  6.  6.  3.  9.  1.  3.  7. 10.  6.  8.  4.\n",
      "  9. 10.  2.  6.  2.  1.  6.  6.  5. 10. 13.  4.  4.  5.  3.  2. 14.  5.\n",
      "  4.  3.  2.  6.  6. 13.  4.  6.  5.  5. 11.  8.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.15625  0.       0.03125  0.0625   0.109375 0.09375  0.078125 0.03125\n",
      " 0.171875 0.03125  0.03125  0.03125  0.109375 0.03125  0.109375 0.0625\n",
      " 0.09375  0.0625   0.015625 0.0625   0.09375  0.140625 0.046875 0.109375\n",
      " 0.03125  0.       0.15625  0.125    0.078125 0.078125 0.       0.109375\n",
      " 0.046875 0.0625   0.140625 0.1875   0.15625  0.0625   0.078125 0.015625\n",
      " 0.09375  0.046875 0.0625   0.078125 0.109375 0.09375  0.078125 0.140625\n",
      " 0.046875 0.046875 0.       0.015625 0.109375 0.046875 0.       0.09375\n",
      " 0.046875 0.203125 0.125    0.0625   0.046875 0.203125 0.125    0.234375\n",
      " 0.125    0.109375 0.21875  0.171875 0.15625  0.03125  0.1875   0.09375\n",
      " 0.       0.0625   0.046875 0.015625 0.03125  0.109375 0.015625 0.03125\n",
      " 0.140625 0.15625  0.078125 0.03125  0.125    0.109375 0.078125 0.046875\n",
      " 0.078125 0.09375  0.015625 0.03125  0.046875 0.03125  0.0625   0.\n",
      " 0.046875 0.046875 0.015625 0.15625  0.09375  0.09375  0.078125 0.03125\n",
      " 0.234375 0.140625 0.078125 0.09375  0.140625 0.03125  0.046875 0.0625\n",
      " 0.140625 0.125    0.046875 0.03125  0.0625   0.140625 0.15625  0.\n",
      " 0.09375  0.09375  0.046875 0.03125  0.140625 0.109375 0.078125 0.09375\n",
      " 0.03125  0.125    0.015625 0.21875  0.0625   0.09375  0.0625   0.09375\n",
      " 0.125    0.015625 0.109375 0.046875 0.046875 0.015625 0.046875 0.015625\n",
      " 0.125    0.171875 0.078125 0.03125  0.03125  0.       0.1875   0.046875\n",
      " 0.171875 0.125    0.0625   0.       0.15625  0.03125  0.0625   0.03125\n",
      " 0.046875 0.       0.140625 0.0625   0.015625 0.015625 0.03125  0.109375\n",
      " 0.109375 0.078125 0.15625  0.0625   0.0625   0.       0.078125 0.\n",
      " 0.140625 0.046875 0.140625 0.125    0.03125  0.078125 0.015625 0.203125\n",
      " 0.046875 0.125    0.03125  0.046875 0.078125 0.140625 0.03125  0.0625\n",
      " 0.03125  0.0625   0.03125  0.03125  0.046875 0.046875 0.015625 0.125   ]\n",
      "Precision:  [0.23255814 0.         0.4        0.36363636 0.53846154 0.6\n",
      " 0.3125     0.4        0.64705882 0.33333333 0.66666667 0.5\n",
      " 0.26923077 0.66666667 0.53846154 0.36363636 0.5        0.44444444\n",
      " 1.         0.66666667 0.3        0.47368421 0.23076923 0.4375\n",
      " 0.66666667 0.         0.58823529 0.72727273 0.22727273 0.625\n",
      " 0.         0.7        0.21428571 0.4        0.47368421 0.5\n",
      " 0.3125     0.26666667 0.83333333 0.33333333 0.66666667 0.42857143\n",
      " 0.66666667 0.71428571 0.7        0.66666667 0.71428571 0.75\n",
      " 0.75       0.75       0.         1.         0.53846154 0.75\n",
      " 0.         0.6        0.6        0.46428571 0.4        0.57142857\n",
      " 0.75       0.76470588 0.66666667 0.71428571 0.5        0.7\n",
      " 0.5        0.6875     0.625      0.5        0.70588235 0.35294118\n",
      " 0.         0.30769231 0.27272727 0.16666667 0.66666667 0.7\n",
      " 0.5        0.5        0.64285714 0.76923077 0.83333333 0.5\n",
      " 0.72727273 0.53846154 0.5        0.6        0.38461538 0.6\n",
      " 1.         0.33333333 0.375      0.66666667 0.33333333 0.\n",
      " 0.6        0.3        0.2        0.58823529 0.5        0.54545455\n",
      " 0.55555556 0.4        0.27777778 0.33333333 0.38461538 1.\n",
      " 0.34615385 0.2        0.5        0.5        0.75       0.5\n",
      " 0.5        0.33333333 0.66666667 0.5        0.90909091 0.\n",
      " 0.75       0.46153846 0.375      0.25       0.52941176 0.38888889\n",
      " 0.55555556 0.66666667 0.5        0.72727273 0.2        0.56\n",
      " 0.8        0.66666667 0.8        0.54545455 0.38095238 0.33333333\n",
      " 0.53846154 0.375      0.3        0.25       0.33333333 0.33333333\n",
      " 0.8        0.84615385 0.35714286 0.22222222 0.13333333 0.\n",
      " 0.6        0.375      0.61111111 0.44444444 0.36363636 0.\n",
      " 0.83333333 0.5        0.44444444 0.5        0.6        0.\n",
      " 0.75       0.36363636 0.33333333 1.         1.         0.63636364\n",
      " 0.31818182 0.71428571 0.625      0.5        0.22222222 0.\n",
      " 0.41666667 0.         0.69230769 0.5        0.75       0.57142857\n",
      " 0.28571429 0.625      0.5        0.72222222 0.75       0.53333333\n",
      " 0.66666667 0.42857143 0.55555556 0.5625     0.28571429 0.22222222\n",
      " 0.4        0.33333333 0.66666667 0.4        1.         0.375\n",
      " 0.5        0.72727273]\n",
      "Recall:  [0.5        0.         0.4        0.44444444 0.58333333 0.66666667\n",
      " 0.55555556 0.4        0.52380952 0.28571429 0.28571429 0.22222222\n",
      " 0.7        0.33333333 0.58333333 0.4        0.5        0.57142857\n",
      " 0.2        0.30769231 0.375      0.42857143 0.3        0.4375\n",
      " 0.66666667 0.         0.625      0.88888889 0.5        0.5\n",
      " 0.         0.5        0.25       0.36363636 0.81818182 0.70588235\n",
      " 0.41666667 0.30769231 0.625      0.11111111 0.6        0.42857143\n",
      " 0.57142857 0.55555556 0.77777778 0.6        0.71428571 0.5625\n",
      " 0.33333333 0.3        0.         0.14285714 0.53846154 0.33333333\n",
      " 0.         0.66666667 1.         0.72222222 0.66666667 0.30769231\n",
      " 0.27272727 0.8125     0.47058824 0.71428571 0.53333333 0.53846154\n",
      " 0.73684211 0.78571429 0.90909091 0.22222222 0.52173913 0.75\n",
      " 0.         0.66666667 0.375      0.16666667 0.25       0.63636364\n",
      " 0.14285714 0.66666667 0.64285714 0.83333333 0.45454545 0.4\n",
      " 0.57142857 0.63636364 0.55555556 0.375      0.38461538 0.75\n",
      " 0.25       0.33333333 0.2        0.25       0.36363636 0.\n",
      " 0.5        0.5        0.125      0.71428571 0.375      0.35294118\n",
      " 0.5        0.22222222 0.71428571 0.64285714 0.5        0.85714286\n",
      " 0.5        0.13333333 0.3        0.44444444 0.52941176 0.47058824\n",
      " 0.33333333 0.25       0.5        0.9        0.76923077 0.\n",
      " 0.6        0.46153846 0.27272727 0.5        0.69230769 0.53846154\n",
      " 0.33333333 0.46153846 0.28571429 0.88888889 0.11111111 0.66666667\n",
      " 0.8        0.75       0.57142857 0.75       0.72727273 0.33333333\n",
      " 0.875      0.42857143 0.42857143 0.1        0.42857143 0.2\n",
      " 0.57142857 0.73333333 0.71428571 0.4        0.66666667 0.\n",
      " 0.66666667 0.33333333 0.64705882 0.72727273 0.30769231 0.\n",
      " 0.76923077 0.22222222 0.28571429 0.25       0.27272727 0.\n",
      " 0.5        0.28571429 0.33333333 0.14285714 0.5        0.875\n",
      " 0.53846154 0.45454545 0.66666667 0.28571429 0.23529412 0.\n",
      " 0.55555556 0.         0.75       0.6        0.39130435 0.61538462\n",
      " 0.33333333 0.625      0.33333333 0.68421053 0.33333333 0.38095238\n",
      " 0.33333333 0.33333333 0.5        0.64285714 0.15384615 0.33333333\n",
      " 0.2        0.4        0.33333333 0.66666667 0.42857143 0.42857143\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.36627907 0.         0.4        0.4040404  0.56089744 0.63333333\n",
      " 0.43402778 0.4        0.58543417 0.30952381 0.47619048 0.36111111\n",
      " 0.48461538 0.5        0.56089744 0.38181818 0.5        0.50793651\n",
      " 0.6        0.48717949 0.3375     0.45112782 0.26538462 0.4375\n",
      " 0.66666667 0.         0.60661765 0.80808081 0.36363636 0.5625\n",
      " 0.         0.6        0.23214286 0.38181818 0.64593301 0.60294118\n",
      " 0.36458333 0.28717949 0.72916667 0.22222222 0.63333333 0.42857143\n",
      " 0.61904762 0.63492063 0.73888889 0.63333333 0.71428571 0.65625\n",
      " 0.54166667 0.525      0.         0.57142857 0.53846154 0.54166667\n",
      " 0.         0.63333333 0.8        0.59325397 0.53333333 0.43956044\n",
      " 0.51136364 0.78860294 0.56862745 0.71428571 0.51666667 0.61923077\n",
      " 0.61842105 0.73660714 0.76704545 0.36111111 0.61381074 0.55147059\n",
      " 0.         0.48717949 0.32386364 0.16666667 0.45833333 0.66818182\n",
      " 0.32142857 0.58333333 0.64285714 0.80128205 0.64393939 0.45\n",
      " 0.64935065 0.58741259 0.52777778 0.4875     0.38461538 0.675\n",
      " 0.625      0.33333333 0.2875     0.45833333 0.34848485 0.\n",
      " 0.55       0.4        0.1625     0.6512605  0.4375     0.44919786\n",
      " 0.52777778 0.31111111 0.49603175 0.48809524 0.44230769 0.92857143\n",
      " 0.42307692 0.16666667 0.4        0.47222222 0.63970588 0.48529412\n",
      " 0.41666667 0.29166667 0.58333333 0.7        0.83916084 0.\n",
      " 0.675      0.46153846 0.32386364 0.375      0.61085973 0.46367521\n",
      " 0.44444444 0.56410256 0.39285714 0.80808081 0.15555556 0.61333333\n",
      " 0.8        0.70833333 0.68571429 0.64772727 0.55411255 0.33333333\n",
      " 0.70673077 0.40178571 0.36428571 0.175      0.38095238 0.26666667\n",
      " 0.68571429 0.78974359 0.53571429 0.31111111 0.4        0.\n",
      " 0.63333333 0.35416667 0.62908497 0.58585859 0.33566434 0.\n",
      " 0.80128205 0.36111111 0.36507937 0.375      0.43636364 0.\n",
      " 0.625      0.32467532 0.33333333 0.57142857 0.75       0.75568182\n",
      " 0.42832168 0.58441558 0.64583333 0.39285714 0.22875817 0.\n",
      " 0.48611111 0.         0.72115385 0.55       0.57065217 0.59340659\n",
      " 0.30952381 0.625      0.41666667 0.70321637 0.54166667 0.45714286\n",
      " 0.5        0.38095238 0.52777778 0.60267857 0.21978022 0.27777778\n",
      " 0.3        0.36666667 0.5        0.53333333 0.71428571 0.40178571\n",
      " 0.75       0.76363636]\n",
      "mini_batch 200\n",
      "mini_batch 201\n",
      "mini_batch 202\n",
      "mini_batch 203\n",
      "mini_batch 204\n",
      "mini_batch 205\n",
      "mini_batch 206\n",
      "mini_batch 207\n",
      "mini_batch 208\n",
      "mini_batch 209\n",
      "mini_batch 210\n",
      "mini_batch 211\n",
      "mini_batch 212\n",
      "mini_batch 213\n",
      "mini_batch 214\n",
      "mini_batch 215\n",
      "mini_batch 216\n",
      "mini_batch 217\n",
      "mini_batch 218\n",
      "mini_batch 219\n",
      "mini_batch 220\n",
      "mini_batch 221\n",
      "mini_batch 222\n",
      "mini_batch 223\n",
      "mini_batch 224\n",
      "mini_batch 225\n",
      "mini_batch 226\n",
      "mini_batch 227\n",
      "mini_batch 228\n",
      "mini_batch 229\n",
      "mini_batch 230\n",
      "mini_batch 231\n",
      "mini_batch 232\n",
      "mini_batch 233\n",
      "mini_batch 234\n",
      "mini_batch 235\n",
      "mini_batch 236\n",
      "mini_batch 237\n",
      "mini_batch 238\n",
      "mini_batch 239\n",
      "mini_batch 240\n",
      "mini_batch 241\n",
      "mini_batch 242\n",
      "mini_batch 243\n",
      "mini_batch 244\n",
      "mini_batch 245\n",
      "mini_batch 246\n",
      "mini_batch 247\n",
      "mini_batch 248\n",
      "mini_batch 249\n",
      "Epoch 5\n",
      "average minibatch 250 loss: 1.088\n",
      "\n",
      "Labels:  tensor([184,  20, 164, 175, 186,  98, 164,  72, 111,  24, 120,  91,  54, 110,\n",
      "         38,  21, 193,  58,  30,  43,  90, 125,  68,  52, 132,   9, 190, 130,\n",
      "         85,  48,  35,  88, 149, 185,  22, 116, 125, 190,  84, 170,  67,  40,\n",
      "        166, 114, 137, 133,  36,  78, 145, 192, 105, 118, 172, 167, 148,  37,\n",
      "         12,  22,  62,  78,   4, 157,  48,  62], device='cuda:0')\n",
      "Output:  tensor([184,  32, 164,  36, 186,  98, 164,  72, 111,  33, 120,  91,  54, 110,\n",
      "         38,  21, 193, 180,  30,  43,  90, 125, 124,   2, 132,   9, 190, 130,\n",
      "         85,  48,  35,  88,  36,  25,  12, 116, 125, 190,  84,  61,  67,  40,\n",
      "        164, 114, 137, 133,  36,  78, 145,  59, 105, 118, 172,   2, 148,  23,\n",
      "         12, 179,  62,  78, 154,  53,  48,  62], device='cuda:0')\n",
      "True Positives:  [10.  0.  2.  4.  7.  6.  5.  2. 12.  2.  2.  3.  7.  2.  7.  4.  6.  4.\n",
      "  1.  4.  7.  9.  3.  7.  2.  0. 10.  8.  5.  6.  0.  7.  3.  4. 10. 13.\n",
      " 10.  5.  5.  2.  6.  3.  5.  5.  7.  6.  5. 11.  3.  3.  0.  1.  7.  4.\n",
      "  0.  6.  3. 13.  8.  4.  3. 15.  8. 15.  8.  7. 15. 11. 10.  2. 12.  7.\n",
      "  0.  4.  3.  1.  2.  9.  1.  2.  9. 10.  5.  3.  9.  7.  5.  4.  5.  7.\n",
      "  2.  2.  3.  2.  4.  0.  3.  4.  1. 10.  6.  6.  5.  2. 16.  9.  5.  6.\n",
      "  9.  3.  4.  4.  9.  9.  3.  3.  4. 10. 10.  1.  6.  6.  3.  2. 11.  7.\n",
      "  5.  6.  2.  9.  1. 15.  5.  6.  4.  6.  9.  1.  7.  3.  3.  1.  3.  1.\n",
      "  9. 11.  5.  3.  2.  0. 12.  3. 11.  8.  4.  0. 10.  2.  4.  2.  3.  0.\n",
      "  9.  6.  1.  1.  2.  7.  7.  5. 10.  5.  4.  0.  5.  0.  9.  3.  9.  8.\n",
      "  2.  5.  1. 14.  3.  9.  2.  3.  5. 11.  2.  4.  3.  4.  2.  2.  3.  3.\n",
      "  1.  8.]\n",
      "False Positives:  [33.  3.  3.  7.  6.  4. 11.  3.  6.  4.  1.  3. 19.  1.  6.  7.  6.  5.\n",
      "  0.  2. 14. 10. 11.  9.  2.  0.  7.  3. 17.  3.  1.  4. 12.  6. 10. 14.\n",
      " 22. 11.  1.  2.  3.  4.  2.  2.  3.  3.  2.  3.  1.  1.  3.  0.  7.  1.\n",
      "  2.  4.  2. 15. 13.  3.  2.  4.  4.  6.  8.  3. 14.  5.  6.  2.  5. 11.\n",
      "  1.  9.  8.  5.  1.  3.  1.  2.  5.  3.  1.  2.  3.  6.  5.  2.  8.  4.\n",
      "  0.  4.  5.  1.  8.  1.  2.  7.  4.  7.  6.  5.  4.  3. 39. 18.  8.  0.\n",
      " 17.  8.  3.  4.  3.  8.  3.  4.  2.  9.  1.  4.  2.  7.  5.  7.  8. 11.\n",
      "  4.  3.  2.  3.  4. 11.  1.  3.  1.  5. 13.  2.  6.  5.  7.  3.  6.  2.\n",
      "  2.  2.  9.  7. 13.  0.  8.  5.  7. 11.  7.  2.  2.  2.  5.  2.  2.  0.\n",
      "  3.  8.  2.  0.  0.  4. 15.  2.  6.  4. 14.  2.  7.  0.  4.  3.  4.  7.\n",
      "  5.  3.  1.  5.  1.  7.  1.  4.  4.  7.  5. 14.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [10.  2.  3.  6.  5.  3.  4.  3. 10.  5.  5.  7.  3.  4.  5.  6.  6.  3.\n",
      "  4. 10. 10. 14.  7. 10.  1.  0.  6.  1.  5.  5.  9.  7.  9.  7.  2.  5.\n",
      " 15.  9.  3.  8.  4.  4.  3.  4.  2.  4.  2.  7.  6.  7.  7.  7.  6.  6.\n",
      "  3.  3.  0.  6.  4.  9.  8.  3.  9.  6.  7.  6.  5.  4.  1.  7. 11.  2.\n",
      "  1.  2.  5.  5.  6.  4.  6.  1.  5.  2.  6.  3.  6.  4.  4.  5.  8.  2.\n",
      "  3.  4. 12.  6.  7.  3.  3.  3.  7.  4. 10. 11.  5.  7.  6.  5.  5.  1.\n",
      "  9. 13.  7.  5.  8.  9.  6.  6.  4.  1.  3.  3.  4.  7.  8.  2.  4.  6.\n",
      " 10.  7.  5.  1.  8.  7.  1.  2.  3.  2.  3.  2.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  2.  2.  6.  6.  6.  3.  9.  1.  4.  7. 10.  6.  8.  4.\n",
      "  9. 10.  2.  7.  3.  1.  6.  7.  5. 10. 13.  4.  5.  5.  3.  2. 14.  5.\n",
      "  4.  3.  2.  6.  7. 13.  4.  6.  5.  5. 11.  9.  8.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.15625  0.       0.03125  0.0625   0.109375 0.09375  0.078125 0.03125\n",
      " 0.1875   0.03125  0.03125  0.046875 0.109375 0.03125  0.109375 0.0625\n",
      " 0.09375  0.0625   0.015625 0.0625   0.109375 0.140625 0.046875 0.109375\n",
      " 0.03125  0.       0.15625  0.125    0.078125 0.09375  0.       0.109375\n",
      " 0.046875 0.0625   0.15625  0.203125 0.15625  0.078125 0.078125 0.03125\n",
      " 0.09375  0.046875 0.078125 0.078125 0.109375 0.09375  0.078125 0.171875\n",
      " 0.046875 0.046875 0.       0.015625 0.109375 0.0625   0.       0.09375\n",
      " 0.046875 0.203125 0.125    0.0625   0.046875 0.234375 0.125    0.234375\n",
      " 0.125    0.109375 0.234375 0.171875 0.15625  0.03125  0.1875   0.109375\n",
      " 0.       0.0625   0.046875 0.015625 0.03125  0.140625 0.015625 0.03125\n",
      " 0.140625 0.15625  0.078125 0.046875 0.140625 0.109375 0.078125 0.0625\n",
      " 0.078125 0.109375 0.03125  0.03125  0.046875 0.03125  0.0625   0.\n",
      " 0.046875 0.0625   0.015625 0.15625  0.09375  0.09375  0.078125 0.03125\n",
      " 0.25     0.140625 0.078125 0.09375  0.140625 0.046875 0.0625   0.0625\n",
      " 0.140625 0.140625 0.046875 0.046875 0.0625   0.15625  0.15625  0.015625\n",
      " 0.09375  0.09375  0.046875 0.03125  0.171875 0.109375 0.078125 0.09375\n",
      " 0.03125  0.140625 0.015625 0.234375 0.078125 0.09375  0.0625   0.09375\n",
      " 0.140625 0.015625 0.109375 0.046875 0.046875 0.015625 0.046875 0.015625\n",
      " 0.140625 0.171875 0.078125 0.046875 0.03125  0.       0.1875   0.046875\n",
      " 0.171875 0.125    0.0625   0.       0.15625  0.03125  0.0625   0.03125\n",
      " 0.046875 0.       0.140625 0.09375  0.015625 0.015625 0.03125  0.109375\n",
      " 0.109375 0.078125 0.15625  0.078125 0.0625   0.       0.078125 0.\n",
      " 0.140625 0.046875 0.140625 0.125    0.03125  0.078125 0.015625 0.21875\n",
      " 0.046875 0.140625 0.03125  0.046875 0.078125 0.171875 0.03125  0.0625\n",
      " 0.046875 0.0625   0.03125  0.03125  0.046875 0.046875 0.015625 0.125   ]\n",
      "Precision:  [0.23255814 0.         0.4        0.36363636 0.53846154 0.6\n",
      " 0.3125     0.4        0.66666667 0.33333333 0.66666667 0.5\n",
      " 0.26923077 0.66666667 0.53846154 0.36363636 0.5        0.44444444\n",
      " 1.         0.66666667 0.33333333 0.47368421 0.21428571 0.4375\n",
      " 0.5        0.         0.58823529 0.72727273 0.22727273 0.66666667\n",
      " 0.         0.63636364 0.2        0.4        0.5        0.48148148\n",
      " 0.3125     0.3125     0.83333333 0.5        0.66666667 0.42857143\n",
      " 0.71428571 0.71428571 0.7        0.66666667 0.71428571 0.78571429\n",
      " 0.75       0.75       0.         1.         0.5        0.8\n",
      " 0.         0.6        0.6        0.46428571 0.38095238 0.57142857\n",
      " 0.6        0.78947368 0.66666667 0.71428571 0.5        0.7\n",
      " 0.51724138 0.6875     0.625      0.5        0.70588235 0.38888889\n",
      " 0.         0.30769231 0.27272727 0.16666667 0.66666667 0.75\n",
      " 0.5        0.5        0.64285714 0.76923077 0.83333333 0.6\n",
      " 0.75       0.53846154 0.5        0.66666667 0.38461538 0.63636364\n",
      " 1.         0.33333333 0.375      0.66666667 0.33333333 0.\n",
      " 0.6        0.36363636 0.2        0.58823529 0.5        0.54545455\n",
      " 0.55555556 0.4        0.29090909 0.33333333 0.38461538 1.\n",
      " 0.34615385 0.27272727 0.57142857 0.5        0.75       0.52941176\n",
      " 0.5        0.42857143 0.66666667 0.52631579 0.90909091 0.2\n",
      " 0.75       0.46153846 0.375      0.22222222 0.57894737 0.38888889\n",
      " 0.55555556 0.66666667 0.5        0.75       0.2        0.57692308\n",
      " 0.83333333 0.66666667 0.8        0.54545455 0.40909091 0.33333333\n",
      " 0.53846154 0.375      0.3        0.25       0.33333333 0.33333333\n",
      " 0.81818182 0.84615385 0.35714286 0.3        0.13333333 0.\n",
      " 0.6        0.375      0.61111111 0.42105263 0.36363636 0.\n",
      " 0.83333333 0.5        0.44444444 0.5        0.6        0.\n",
      " 0.75       0.42857143 0.33333333 1.         1.         0.63636364\n",
      " 0.31818182 0.71428571 0.625      0.55555556 0.22222222 0.\n",
      " 0.41666667 0.         0.69230769 0.5        0.69230769 0.53333333\n",
      " 0.28571429 0.625      0.5        0.73684211 0.75       0.5625\n",
      " 0.66666667 0.42857143 0.55555556 0.61111111 0.28571429 0.22222222\n",
      " 0.5        0.33333333 0.66666667 0.4        1.         0.375\n",
      " 0.5        0.72727273]\n",
      "Recall:  [0.5        0.         0.4        0.4        0.58333333 0.66666667\n",
      " 0.55555556 0.4        0.54545455 0.28571429 0.28571429 0.3\n",
      " 0.7        0.33333333 0.58333333 0.4        0.5        0.57142857\n",
      " 0.2        0.28571429 0.41176471 0.39130435 0.3        0.41176471\n",
      " 0.66666667 0.         0.625      0.88888889 0.5        0.54545455\n",
      " 0.         0.5        0.25       0.36363636 0.83333333 0.72222222\n",
      " 0.4        0.35714286 0.625      0.2        0.6        0.42857143\n",
      " 0.625      0.55555556 0.77777778 0.6        0.71428571 0.61111111\n",
      " 0.33333333 0.3        0.         0.125      0.53846154 0.4\n",
      " 0.         0.66666667 1.         0.68421053 0.66666667 0.30769231\n",
      " 0.27272727 0.83333333 0.47058824 0.71428571 0.53333333 0.53846154\n",
      " 0.75       0.73333333 0.90909091 0.22222222 0.52173913 0.77777778\n",
      " 0.         0.66666667 0.375      0.16666667 0.25       0.69230769\n",
      " 0.14285714 0.66666667 0.64285714 0.83333333 0.45454545 0.5\n",
      " 0.6        0.63636364 0.55555556 0.44444444 0.38461538 0.77777778\n",
      " 0.4        0.33333333 0.2        0.25       0.36363636 0.\n",
      " 0.5        0.57142857 0.125      0.71428571 0.375      0.35294118\n",
      " 0.5        0.22222222 0.72727273 0.64285714 0.5        0.85714286\n",
      " 0.5        0.1875     0.36363636 0.44444444 0.52941176 0.5\n",
      " 0.33333333 0.33333333 0.5        0.90909091 0.76923077 0.25\n",
      " 0.6        0.46153846 0.27272727 0.5        0.73333333 0.53846154\n",
      " 0.33333333 0.46153846 0.28571429 0.9        0.11111111 0.68181818\n",
      " 0.83333333 0.75       0.57142857 0.75       0.75       0.33333333\n",
      " 0.875      0.42857143 0.42857143 0.1        0.42857143 0.2\n",
      " 0.6        0.73333333 0.71428571 0.5        0.5        0.\n",
      " 0.66666667 0.33333333 0.64705882 0.72727273 0.30769231 0.\n",
      " 0.71428571 0.22222222 0.28571429 0.25       0.27272727 0.\n",
      " 0.5        0.375      0.33333333 0.125      0.4        0.875\n",
      " 0.53846154 0.41666667 0.66666667 0.33333333 0.23529412 0.\n",
      " 0.5        0.         0.75       0.6        0.39130435 0.61538462\n",
      " 0.33333333 0.625      0.33333333 0.7        0.3        0.40909091\n",
      " 0.33333333 0.33333333 0.5        0.6875     0.15384615 0.30769231\n",
      " 0.27272727 0.4        0.33333333 0.66666667 0.42857143 0.42857143\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.36627907 0.         0.4        0.38181818 0.56089744 0.63333333\n",
      " 0.43402778 0.4        0.60606061 0.30952381 0.47619048 0.4\n",
      " 0.48461538 0.5        0.56089744 0.38181818 0.5        0.50793651\n",
      " 0.6        0.47619048 0.37254902 0.43249428 0.25714286 0.42463235\n",
      " 0.58333333 0.         0.60661765 0.80808081 0.36363636 0.60606061\n",
      " 0.         0.56818182 0.225      0.38181818 0.66666667 0.60185185\n",
      " 0.35625    0.33482143 0.72916667 0.35       0.63333333 0.42857143\n",
      " 0.66964286 0.63492063 0.73888889 0.63333333 0.71428571 0.6984127\n",
      " 0.54166667 0.525      0.         0.5625     0.51923077 0.6\n",
      " 0.         0.63333333 0.8        0.57424812 0.52380952 0.43956044\n",
      " 0.43636364 0.81140351 0.56862745 0.71428571 0.51666667 0.61923077\n",
      " 0.63362069 0.71041667 0.76704545 0.36111111 0.61381074 0.58333333\n",
      " 0.         0.48717949 0.32386364 0.16666667 0.45833333 0.72115385\n",
      " 0.32142857 0.58333333 0.64285714 0.80128205 0.64393939 0.55\n",
      " 0.675      0.58741259 0.52777778 0.55555556 0.38461538 0.70707071\n",
      " 0.7        0.33333333 0.2875     0.45833333 0.34848485 0.\n",
      " 0.55       0.46753247 0.1625     0.6512605  0.4375     0.44919786\n",
      " 0.52777778 0.31111111 0.50909091 0.48809524 0.44230769 0.92857143\n",
      " 0.42307692 0.23011364 0.46753247 0.47222222 0.63970588 0.51470588\n",
      " 0.41666667 0.38095238 0.58333333 0.71770335 0.83916084 0.225\n",
      " 0.675      0.46153846 0.32386364 0.36111111 0.65614035 0.46367521\n",
      " 0.44444444 0.56410256 0.39285714 0.825      0.15555556 0.62937063\n",
      " 0.83333333 0.70833333 0.68571429 0.64772727 0.57954545 0.33333333\n",
      " 0.70673077 0.40178571 0.36428571 0.175      0.38095238 0.26666667\n",
      " 0.70909091 0.78974359 0.53571429 0.4        0.31666667 0.\n",
      " 0.63333333 0.35416667 0.62908497 0.57416268 0.33566434 0.\n",
      " 0.77380952 0.36111111 0.36507937 0.375      0.43636364 0.\n",
      " 0.625      0.40178571 0.33333333 0.5625     0.7        0.75568182\n",
      " 0.42832168 0.56547619 0.64583333 0.44444444 0.22875817 0.\n",
      " 0.45833333 0.         0.72115385 0.55       0.54180602 0.57435897\n",
      " 0.30952381 0.625      0.41666667 0.71842105 0.525      0.48579545\n",
      " 0.5        0.38095238 0.52777778 0.64930556 0.21978022 0.26495726\n",
      " 0.38636364 0.36666667 0.5        0.53333333 0.71428571 0.40178571\n",
      " 0.75       0.76363636]\n",
      "mini_batch 250\n",
      "mini_batch 251\n",
      "mini_batch 252\n",
      "mini_batch 253\n",
      "mini_batch 254\n",
      "mini_batch 255\n",
      "mini_batch 256\n",
      "mini_batch 257\n",
      "mini_batch 258\n",
      "mini_batch 259\n",
      "mini_batch 260\n",
      "mini_batch 261\n",
      "mini_batch 262\n",
      "mini_batch 263\n",
      "mini_batch 264\n",
      "mini_batch 265\n",
      "mini_batch 266\n",
      "mini_batch 267\n",
      "mini_batch 268\n",
      "mini_batch 269\n",
      "mini_batch 270\n",
      "mini_batch 271\n",
      "mini_batch 272\n",
      "mini_batch 273\n",
      "mini_batch 274\n",
      "mini_batch 275\n",
      "mini_batch 276\n",
      "mini_batch 277\n",
      "mini_batch 278\n",
      "mini_batch 279\n",
      "mini_batch 280\n",
      "mini_batch 281\n",
      "mini_batch 282\n",
      "mini_batch 283\n",
      "mini_batch 284\n",
      "mini_batch 285\n",
      "mini_batch 286\n",
      "mini_batch 287\n",
      "mini_batch 288\n",
      "mini_batch 289\n",
      "mini_batch 290\n",
      "mini_batch 291\n",
      "mini_batch 292\n",
      "mini_batch 293\n",
      "mini_batch 294\n",
      "mini_batch 295\n",
      "mini_batch 296\n",
      "mini_batch 297\n",
      "mini_batch 298\n",
      "mini_batch 299\n",
      "Epoch 5\n",
      "average minibatch 300 loss: 1.020\n",
      "\n",
      "Labels:  tensor([120,  89, 189,  60,  23,  23, 192, 105, 181, 153,  98, 141, 110,  72,\n",
      "        141,  92,  87, 116, 180,  84,  66, 126,  33,  70, 175, 192, 151,  19,\n",
      "        170, 118, 185, 106,  88, 126,  67, 160,   4, 197,  63, 177,  16, 154,\n",
      "        112,  21,  95,  62,  51, 195,  89, 193,   9,  63, 134,  53,  18, 110,\n",
      "         22, 163, 124, 155, 180,  59, 193,  75], device='cuda:0')\n",
      "Output:  tensor([120, 161, 189,  60, 153,  72, 192, 105,  16, 153,  98, 141, 110,  72,\n",
      "        141,  92, 183, 116, 180,  84, 144, 126,  33,  17,   5, 179, 151,  19,\n",
      "        170, 151, 185,  75,  79, 126,  67, 160,   4, 197,  31,  34,  16, 154,\n",
      "        112,  21,  95,  62,  51, 195,  22, 193,   9, 114,  46,  53,  18, 110,\n",
      "         69, 163, 144, 155, 180,  59, 192,  75], device='cuda:0')\n",
      "True Positives:  [10.  0.  2.  5.  7.  6.  5.  2. 13.  2.  2.  3.  7.  2.  7.  5.  6.  5.\n",
      "  2.  4.  8.  9.  3.  7.  2.  0. 10.  8.  5.  6.  0.  7.  4.  4. 10. 13.\n",
      " 10.  5.  5.  2.  6.  3.  5.  5.  7.  6.  5. 11.  3.  3.  1.  1.  8.  4.\n",
      "  0.  6.  3. 13.  9.  5.  3. 16.  8. 15.  8.  7. 16. 11. 10.  2. 12.  8.\n",
      "  0.  4.  4.  1.  2.  9.  1.  2.  9. 10.  5.  4.  9.  7.  5.  4.  5.  7.\n",
      "  2.  3.  3.  2.  5.  0.  3.  5.  1. 10.  6.  6.  5.  2. 17.  9.  5.  6.\n",
      "  9.  5.  4.  5.  9.  9.  3.  4.  4. 10. 10.  2.  6.  6.  3.  2. 11.  9.\n",
      "  5.  6.  2.  9.  1. 15.  5.  6.  4.  6.  9.  1.  7.  3.  5.  1.  3.  1.\n",
      "  9. 11.  5.  3.  2.  0. 13.  3. 12.  9.  5.  0. 10.  2.  4.  3.  3.  0.\n",
      " 10.  6.  1.  1.  2.  7.  7.  6. 10.  5.  4.  0.  5.  0.  9.  3.  9. 10.\n",
      "  2.  5.  1. 14.  4.  9.  2.  3.  6. 11.  2.  5.  4.  4.  3.  2.  4.  3.\n",
      "  1.  8.]\n",
      "False Positives:  [33.  3.  3.  7.  7.  4. 11.  3.  6.  4.  1.  3. 19.  1.  6.  8.  7.  5.\n",
      "  0.  2. 14. 11. 11.  9.  2.  0.  7.  3. 17.  3.  2.  4. 12.  7. 10. 14.\n",
      " 22. 11.  1.  2.  3.  4.  2.  2.  3.  4.  2.  3.  1.  1.  3.  0.  7.  1.\n",
      "  2.  4.  2. 15. 13.  3.  2.  4.  4.  6.  8.  3. 14.  5.  7.  2.  5. 12.\n",
      "  1.  9.  9.  5.  1.  3.  2.  2.  5.  3.  1.  2.  3.  6.  5.  2.  8.  4.\n",
      "  0.  4.  5.  1.  8.  1.  2.  7.  4.  7.  6.  5.  4.  3. 39. 18.  8.  0.\n",
      " 17.  8.  3.  4.  3.  9.  3.  4.  2.  9.  1.  4.  2.  7.  5.  7.  8. 11.\n",
      "  4.  3.  2.  3.  4. 11.  1.  3.  1.  5. 13.  2.  6.  5.  7.  3.  6.  4.\n",
      "  2.  2.  9.  7. 13.  0.  9.  5.  8. 11.  7.  2.  2.  2.  5.  2.  3.  0.\n",
      "  3.  8.  2.  0.  0.  4. 15.  2.  6.  4. 14.  2.  7.  0.  4.  3.  5.  7.\n",
      "  5.  3.  2.  5.  1.  7.  1.  4.  4.  7.  5. 15.  3.  8.  1.  3.  0.  5.\n",
      "  1.  3.]\n",
      "False Negatives:  [10.  2.  3.  6.  5.  3.  4.  3. 10.  5.  5.  7.  3.  4.  5.  6.  6.  3.\n",
      "  4. 10. 10. 15.  9. 10.  1.  0.  6.  1.  5.  5.  9.  7.  9.  7.  2.  5.\n",
      " 15.  9.  3.  8.  4.  4.  3.  4.  2.  4.  2.  7.  6.  7.  7.  7.  6.  6.\n",
      "  3.  3.  0.  6.  4.  9.  8.  3. 11.  6.  7.  7.  5.  4.  1.  8. 11.  2.\n",
      "  1.  2.  5.  5.  6.  4.  6.  1.  5.  2.  6.  3.  6.  4.  5.  6. 10.  2.\n",
      "  3.  4. 12.  6.  7.  3.  3.  3.  7.  4. 10. 11.  5.  7.  6.  6.  5.  1.\n",
      "  9. 13.  7.  5.  8.  9.  6.  6.  4.  2.  3.  3.  4.  7.  8.  3.  4.  6.\n",
      " 10.  7.  5.  1.  8.  7.  1.  3.  3.  2.  3.  2.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  2.  2.  6.  6.  6.  3.  9.  1.  4.  7. 10.  6.  8.  4.\n",
      "  9. 10.  2.  7.  3.  1.  6.  7.  5. 10. 13.  4.  6.  5.  4.  2. 14.  5.\n",
      "  5.  3.  2.  6.  7. 13.  4.  6.  5.  5. 11. 10.  9.  6.  4.  1.  4.  4.\n",
      "  0.  2.]\n",
      "Accuracy:  [0.15625  0.       0.03125  0.078125 0.109375 0.09375  0.078125 0.03125\n",
      " 0.203125 0.03125  0.03125  0.046875 0.109375 0.03125  0.109375 0.078125\n",
      " 0.09375  0.078125 0.03125  0.0625   0.125    0.140625 0.046875 0.109375\n",
      " 0.03125  0.       0.15625  0.125    0.078125 0.09375  0.       0.109375\n",
      " 0.0625   0.0625   0.15625  0.203125 0.15625  0.078125 0.078125 0.03125\n",
      " 0.09375  0.046875 0.078125 0.078125 0.109375 0.09375  0.078125 0.171875\n",
      " 0.046875 0.046875 0.015625 0.015625 0.125    0.0625   0.       0.09375\n",
      " 0.046875 0.203125 0.140625 0.078125 0.046875 0.25     0.125    0.234375\n",
      " 0.125    0.109375 0.25     0.171875 0.15625  0.03125  0.1875   0.125\n",
      " 0.       0.0625   0.0625   0.015625 0.03125  0.140625 0.015625 0.03125\n",
      " 0.140625 0.15625  0.078125 0.0625   0.140625 0.109375 0.078125 0.0625\n",
      " 0.078125 0.109375 0.03125  0.046875 0.046875 0.03125  0.078125 0.\n",
      " 0.046875 0.078125 0.015625 0.15625  0.09375  0.09375  0.078125 0.03125\n",
      " 0.265625 0.140625 0.078125 0.09375  0.140625 0.078125 0.0625   0.078125\n",
      " 0.140625 0.140625 0.046875 0.0625   0.0625   0.15625  0.15625  0.03125\n",
      " 0.09375  0.09375  0.046875 0.03125  0.171875 0.140625 0.078125 0.09375\n",
      " 0.03125  0.140625 0.015625 0.234375 0.078125 0.09375  0.0625   0.09375\n",
      " 0.140625 0.015625 0.109375 0.046875 0.078125 0.015625 0.046875 0.015625\n",
      " 0.140625 0.171875 0.078125 0.046875 0.03125  0.       0.203125 0.046875\n",
      " 0.1875   0.140625 0.078125 0.       0.15625  0.03125  0.0625   0.046875\n",
      " 0.046875 0.       0.15625  0.09375  0.015625 0.015625 0.03125  0.109375\n",
      " 0.109375 0.09375  0.15625  0.078125 0.0625   0.       0.078125 0.\n",
      " 0.140625 0.046875 0.140625 0.15625  0.03125  0.078125 0.015625 0.21875\n",
      " 0.0625   0.140625 0.03125  0.046875 0.09375  0.171875 0.03125  0.078125\n",
      " 0.0625   0.0625   0.046875 0.03125  0.0625   0.046875 0.015625 0.125   ]\n",
      "Precision:  [0.23255814 0.         0.4        0.41666667 0.5        0.6\n",
      " 0.3125     0.4        0.68421053 0.33333333 0.66666667 0.5\n",
      " 0.26923077 0.66666667 0.53846154 0.38461538 0.46153846 0.5\n",
      " 1.         0.66666667 0.36363636 0.45       0.21428571 0.4375\n",
      " 0.5        0.         0.58823529 0.72727273 0.22727273 0.66666667\n",
      " 0.         0.63636364 0.25       0.36363636 0.5        0.48148148\n",
      " 0.3125     0.3125     0.83333333 0.5        0.66666667 0.42857143\n",
      " 0.71428571 0.71428571 0.7        0.6        0.71428571 0.78571429\n",
      " 0.75       0.75       0.25       1.         0.53333333 0.8\n",
      " 0.         0.6        0.6        0.46428571 0.40909091 0.625\n",
      " 0.6        0.8        0.66666667 0.71428571 0.5        0.7\n",
      " 0.53333333 0.6875     0.58823529 0.5        0.70588235 0.4\n",
      " 0.         0.30769231 0.30769231 0.16666667 0.66666667 0.75\n",
      " 0.33333333 0.5        0.64285714 0.76923077 0.83333333 0.66666667\n",
      " 0.75       0.53846154 0.5        0.66666667 0.38461538 0.63636364\n",
      " 1.         0.42857143 0.375      0.66666667 0.38461538 0.\n",
      " 0.6        0.41666667 0.2        0.58823529 0.5        0.54545455\n",
      " 0.55555556 0.4        0.30357143 0.33333333 0.38461538 1.\n",
      " 0.34615385 0.38461538 0.57142857 0.55555556 0.75       0.5\n",
      " 0.5        0.5        0.66666667 0.52631579 0.90909091 0.33333333\n",
      " 0.75       0.46153846 0.375      0.22222222 0.57894737 0.45\n",
      " 0.55555556 0.66666667 0.5        0.75       0.2        0.57692308\n",
      " 0.83333333 0.66666667 0.8        0.54545455 0.40909091 0.33333333\n",
      " 0.53846154 0.375      0.41666667 0.25       0.33333333 0.2\n",
      " 0.81818182 0.84615385 0.35714286 0.3        0.13333333 0.\n",
      " 0.59090909 0.375      0.6        0.45       0.41666667 0.\n",
      " 0.83333333 0.5        0.44444444 0.6        0.5        0.\n",
      " 0.76923077 0.42857143 0.33333333 1.         1.         0.63636364\n",
      " 0.31818182 0.75       0.625      0.55555556 0.22222222 0.\n",
      " 0.41666667 0.         0.69230769 0.5        0.64285714 0.58823529\n",
      " 0.28571429 0.625      0.33333333 0.73684211 0.8        0.5625\n",
      " 0.66666667 0.42857143 0.6        0.61111111 0.28571429 0.25\n",
      " 0.57142857 0.33333333 0.75       0.4        1.         0.375\n",
      " 0.5        0.72727273]\n",
      "Recall:  [0.5        0.         0.4        0.45454545 0.58333333 0.66666667\n",
      " 0.55555556 0.4        0.56521739 0.28571429 0.28571429 0.3\n",
      " 0.7        0.33333333 0.58333333 0.45454545 0.5        0.625\n",
      " 0.33333333 0.28571429 0.44444444 0.375      0.25       0.41176471\n",
      " 0.66666667 0.         0.625      0.88888889 0.5        0.54545455\n",
      " 0.         0.5        0.30769231 0.36363636 0.83333333 0.72222222\n",
      " 0.4        0.35714286 0.625      0.2        0.6        0.42857143\n",
      " 0.625      0.55555556 0.77777778 0.6        0.71428571 0.61111111\n",
      " 0.33333333 0.3        0.125      0.125      0.57142857 0.4\n",
      " 0.         0.66666667 1.         0.68421053 0.69230769 0.35714286\n",
      " 0.27272727 0.84210526 0.42105263 0.71428571 0.53333333 0.5\n",
      " 0.76190476 0.73333333 0.90909091 0.2        0.52173913 0.8\n",
      " 0.         0.66666667 0.44444444 0.16666667 0.25       0.69230769\n",
      " 0.14285714 0.66666667 0.64285714 0.83333333 0.45454545 0.57142857\n",
      " 0.6        0.63636364 0.5        0.4        0.33333333 0.77777778\n",
      " 0.4        0.42857143 0.2        0.25       0.41666667 0.\n",
      " 0.5        0.625      0.125      0.71428571 0.375      0.35294118\n",
      " 0.5        0.22222222 0.73913043 0.6        0.5        0.85714286\n",
      " 0.5        0.27777778 0.36363636 0.5        0.52941176 0.5\n",
      " 0.33333333 0.4        0.5        0.83333333 0.76923077 0.4\n",
      " 0.6        0.46153846 0.27272727 0.4        0.73333333 0.6\n",
      " 0.33333333 0.46153846 0.28571429 0.9        0.11111111 0.68181818\n",
      " 0.83333333 0.66666667 0.57142857 0.75       0.75       0.33333333\n",
      " 0.875      0.42857143 0.55555556 0.1        0.42857143 0.2\n",
      " 0.6        0.73333333 0.71428571 0.5        0.5        0.\n",
      " 0.68421053 0.33333333 0.66666667 0.75       0.35714286 0.\n",
      " 0.71428571 0.22222222 0.28571429 0.33333333 0.27272727 0.\n",
      " 0.52631579 0.375      0.33333333 0.125      0.4        0.875\n",
      " 0.53846154 0.46153846 0.66666667 0.33333333 0.23529412 0.\n",
      " 0.45454545 0.         0.69230769 0.6        0.39130435 0.66666667\n",
      " 0.28571429 0.625      0.33333333 0.7        0.36363636 0.40909091\n",
      " 0.33333333 0.33333333 0.54545455 0.6875     0.15384615 0.33333333\n",
      " 0.30769231 0.4        0.42857143 0.66666667 0.5        0.42857143\n",
      " 1.         0.8       ]\n",
      "Balanced Classification Rate:  [0.36627907 0.         0.4        0.43560606 0.54166667 0.63333333\n",
      " 0.43402778 0.4        0.62471396 0.30952381 0.47619048 0.4\n",
      " 0.48461538 0.5        0.56089744 0.41958042 0.48076923 0.5625\n",
      " 0.66666667 0.47619048 0.4040404  0.4125     0.23214286 0.42463235\n",
      " 0.58333333 0.         0.60661765 0.80808081 0.36363636 0.60606061\n",
      " 0.         0.56818182 0.27884615 0.36363636 0.66666667 0.60185185\n",
      " 0.35625    0.33482143 0.72916667 0.35       0.63333333 0.42857143\n",
      " 0.66964286 0.63492063 0.73888889 0.6        0.71428571 0.6984127\n",
      " 0.54166667 0.525      0.1875     0.5625     0.55238095 0.6\n",
      " 0.         0.63333333 0.8        0.57424812 0.5506993  0.49107143\n",
      " 0.43636364 0.82105263 0.54385965 0.71428571 0.51666667 0.6\n",
      " 0.64761905 0.71041667 0.7486631  0.35       0.61381074 0.6\n",
      " 0.         0.48717949 0.37606838 0.16666667 0.45833333 0.72115385\n",
      " 0.23809524 0.58333333 0.64285714 0.80128205 0.64393939 0.61904762\n",
      " 0.675      0.58741259 0.5        0.53333333 0.35897436 0.70707071\n",
      " 0.7        0.42857143 0.2875     0.45833333 0.40064103 0.\n",
      " 0.55       0.52083333 0.1625     0.6512605  0.4375     0.44919786\n",
      " 0.52777778 0.31111111 0.52135093 0.46666667 0.44230769 0.92857143\n",
      " 0.42307692 0.33119658 0.46753247 0.52777778 0.63970588 0.5\n",
      " 0.41666667 0.45       0.58333333 0.67982456 0.83916084 0.36666667\n",
      " 0.675      0.46153846 0.32386364 0.31111111 0.65614035 0.525\n",
      " 0.44444444 0.56410256 0.39285714 0.825      0.15555556 0.62937063\n",
      " 0.83333333 0.66666667 0.68571429 0.64772727 0.57954545 0.33333333\n",
      " 0.70673077 0.40178571 0.48611111 0.175      0.38095238 0.2\n",
      " 0.70909091 0.78974359 0.53571429 0.4        0.31666667 0.\n",
      " 0.63755981 0.35416667 0.63333333 0.6        0.38690476 0.\n",
      " 0.77380952 0.36111111 0.36507937 0.46666667 0.38636364 0.\n",
      " 0.64777328 0.40178571 0.33333333 0.5625     0.7        0.75568182\n",
      " 0.42832168 0.60576923 0.64583333 0.44444444 0.22875817 0.\n",
      " 0.43560606 0.         0.69230769 0.55       0.51708075 0.62745098\n",
      " 0.28571429 0.625      0.33333333 0.71842105 0.58181818 0.48579545\n",
      " 0.5        0.38095238 0.57272727 0.64930556 0.21978022 0.29166667\n",
      " 0.43956044 0.36666667 0.58928571 0.53333333 0.75       0.40178571\n",
      " 0.75       0.76363636]\n",
      "mini_batch 300\n",
      "mini_batch 301\n",
      "mini_batch 302\n",
      "mini_batch 303\n",
      "mini_batch 304\n",
      "mini_batch 305\n",
      "mini_batch 306\n",
      "mini_batch 307\n",
      "mini_batch 308\n",
      "mini_batch 309\n",
      "mini_batch 310\n",
      "mini_batch 311\n",
      "mini_batch 312\n",
      "mini_batch 313\n",
      "mini_batch 314\n",
      "mini_batch 315\n",
      "mini_batch 316\n",
      "mini_batch 317\n",
      "mini_batch 318\n",
      "mini_batch 319\n",
      "mini_batch 320\n",
      "mini_batch 321\n",
      "mini_batch 322\n",
      "mini_batch 323\n",
      "mini_batch 324\n",
      "mini_batch 325\n",
      "mini_batch 326\n",
      "mini_batch 327\n",
      "mini_batch 328\n",
      "mini_batch 329\n",
      "mini_batch 330\n",
      "mini_batch 331\n",
      "mini_batch 332\n",
      "mini_batch 333\n",
      "mini_batch 334\n",
      "mini_batch 335\n",
      "mini_batch 336\n",
      "mini_batch 337\n",
      "mini_batch 338\n",
      "mini_batch 339\n",
      "mini_batch 340\n",
      "mini_batch 341\n",
      "mini_batch 342\n",
      "mini_batch 343\n",
      "mini_batch 344\n",
      "mini_batch 345\n",
      "mini_batch 346\n",
      "mini_batch 347\n",
      "mini_batch 348\n",
      "mini_batch 349\n",
      "Epoch 5\n",
      "average minibatch 350 loss: 1.075\n",
      "\n",
      "Labels:  tensor([ 18, 177,  86, 155, 100,  35,  33, 136, 160, 152, 137, 188, 155,   1,\n",
      "        157, 105,  53,  69, 133,  38,  72, 121,  80,  34, 109, 176,  77,  81,\n",
      "         64,  85,  10,  21,  13,  80,  46,  85, 180,  10, 133, 127, 115, 110,\n",
      "        100,  38,  78,  46,  89,  75,   1, 187,  49, 102, 103, 109, 200,  70,\n",
      "         25,  59, 105,  98,  89,  60,  22, 177], device='cuda:0')\n",
      "Output:  tensor([ 18, 177,  13, 155, 100,  35,  33, 136, 160, 152, 137,  23, 155,   1,\n",
      "        157, 105,  53,  69,  58,  38,  72, 121,  80,  34, 109, 176,  77,  81,\n",
      "         64,  85, 112,  21,  13,  80,  46,  85, 182,  13, 146, 127, 115, 110,\n",
      "        100,  38,  78,  46, 173,  75,  89, 187,  49, 102, 127, 109, 185, 174,\n",
      "         13,  59, 105,  98,  89,  33,  22, 198], device='cuda:0')\n",
      "True Positives:  [11.  0.  2.  5.  7.  6.  5.  2. 13.  2.  2.  3.  8.  2.  7.  5.  6.  6.\n",
      "  2.  4.  9. 10.  3.  7.  2.  0. 10.  8.  5.  6.  0.  7.  5.  5. 11. 13.\n",
      " 10.  7.  5.  2.  6.  3.  5.  5.  7.  8.  5. 11.  4.  3.  1.  1.  9.  4.\n",
      "  0.  6.  3. 13. 10.  5.  3. 16.  8. 16.  8.  7. 16. 11. 11.  2. 12.  9.\n",
      "  0.  4.  5.  1.  3. 10.  1.  4. 10. 10.  5.  4. 11.  7.  5.  4.  6.  7.\n",
      "  2.  3.  3.  2.  5.  0.  3.  6.  1. 12.  6.  7.  5.  2. 19.  9.  5.  6.\n",
      " 11.  6.  4.  5.  9.  9.  4.  4.  4. 10. 10.  2.  7.  6.  3.  2. 11.  9.\n",
      "  6.  6.  2.  9.  1. 15.  5.  6.  4.  7. 10.  1.  7.  3.  5.  1.  3.  1.\n",
      "  9. 11.  5.  3.  2.  0. 13.  4. 12.  9.  7.  0. 11.  2.  4.  4.  3.  0.\n",
      " 10.  6.  1.  1.  2.  7.  7.  6. 10.  5.  4.  0.  5.  1. 10.  3.  9. 10.\n",
      "  2.  5.  1. 14.  4.  9.  3.  3.  6. 11.  2.  5.  4.  4.  3.  2.  4.  3.\n",
      "  1.  8.]\n",
      "False Positives:  [33.  3.  3.  7.  7.  4. 11.  3.  6.  4.  1.  3. 22.  1.  6.  8.  7.  5.\n",
      "  0.  2. 14. 11. 12.  9.  2.  0.  7.  3. 17.  3.  2.  4. 13.  7. 10. 14.\n",
      " 22. 11.  1.  2.  3.  4.  2.  2.  3.  4.  2.  3.  1.  1.  3.  0.  7.  1.\n",
      "  2.  4.  2. 16. 13.  3.  2.  4.  4.  6.  8.  3. 14.  5.  7.  2.  5. 12.\n",
      "  1.  9.  9.  5.  1.  3.  2.  2.  5.  3.  1.  2.  3.  6.  5.  2.  9.  4.\n",
      "  0.  4.  5.  1.  8.  1.  2.  7.  4.  7.  6.  5.  4.  3. 39. 18.  8.  0.\n",
      " 17.  8.  3.  5.  3.  9.  3.  4.  2.  9.  1.  4.  2.  7.  5.  7.  8. 11.\n",
      "  5.  3.  2.  3.  4. 11.  1.  3.  1.  5. 13.  2.  6.  5.  7.  3.  6.  4.\n",
      "  2.  3.  9.  7. 13.  0.  9.  5.  8. 11.  7.  2.  2.  2.  5.  2.  3.  0.\n",
      "  3.  8.  2.  0.  0.  4. 15.  2.  6.  4. 15.  3.  7.  0.  4.  3.  5.  7.\n",
      "  5.  4.  2.  5.  2.  7.  1.  4.  4.  7.  5. 15.  3.  8.  1.  3.  0.  6.\n",
      "  1.  3.]\n",
      "False Negatives:  [11.  2.  3.  6.  5.  3.  4.  3. 10.  7.  5.  7.  3.  4.  5.  6.  6.  3.\n",
      "  4. 10. 10. 15.  9. 10.  2.  0.  6.  1.  5.  5.  9.  7.  9.  7.  2.  5.\n",
      " 15.  9.  3.  8.  4.  4.  3.  4.  2.  4.  2.  7.  6.  7.  7.  7.  6.  6.\n",
      "  3.  3.  0.  6.  4. 10.  8.  3. 11.  6.  7.  7.  5.  4.  1.  9. 11.  2.\n",
      "  1.  2.  5.  5.  6.  4.  6.  1.  5.  2.  6.  3.  6.  5.  5.  6. 11.  2.\n",
      "  3.  4. 12.  6.  7.  3.  3.  3.  7.  4. 10. 11.  6.  7.  6.  6.  5.  1.\n",
      "  9. 13.  7.  5.  8.  9.  6.  6.  4.  2.  3.  3.  4.  7.  8.  3.  4.  6.\n",
      " 10.  7.  5.  1.  8.  7.  3.  3.  3.  2.  3.  2.  1.  4.  4.  9.  4.  4.\n",
      "  6.  4.  2.  3.  2.  2.  6.  6.  6.  3.  9.  1.  4.  7. 10.  6.  8.  4.\n",
      "  9. 10.  2.  7.  3.  1.  6.  7.  5. 10. 13.  4.  6.  5.  5.  2. 14.  6.\n",
      "  5.  3.  2.  6.  7. 13.  4.  7.  5.  5. 11. 10.  9.  6.  4.  1.  4.  4.\n",
      "  0.  3.]\n",
      "Accuracy:  [0.171875 0.       0.03125  0.078125 0.109375 0.09375  0.078125 0.03125\n",
      " 0.203125 0.03125  0.03125  0.046875 0.125    0.03125  0.109375 0.078125\n",
      " 0.09375  0.09375  0.03125  0.0625   0.140625 0.15625  0.046875 0.109375\n",
      " 0.03125  0.       0.15625  0.125    0.078125 0.09375  0.       0.109375\n",
      " 0.078125 0.078125 0.171875 0.203125 0.15625  0.109375 0.078125 0.03125\n",
      " 0.09375  0.046875 0.078125 0.078125 0.109375 0.125    0.078125 0.171875\n",
      " 0.0625   0.046875 0.015625 0.015625 0.140625 0.0625   0.       0.09375\n",
      " 0.046875 0.203125 0.15625  0.078125 0.046875 0.25     0.125    0.25\n",
      " 0.125    0.109375 0.25     0.171875 0.171875 0.03125  0.1875   0.140625\n",
      " 0.       0.0625   0.078125 0.015625 0.046875 0.15625  0.015625 0.0625\n",
      " 0.15625  0.15625  0.078125 0.0625   0.171875 0.109375 0.078125 0.0625\n",
      " 0.09375  0.109375 0.03125  0.046875 0.046875 0.03125  0.078125 0.\n",
      " 0.046875 0.09375  0.015625 0.1875   0.09375  0.109375 0.078125 0.03125\n",
      " 0.296875 0.140625 0.078125 0.09375  0.171875 0.09375  0.0625   0.078125\n",
      " 0.140625 0.140625 0.0625   0.0625   0.0625   0.15625  0.15625  0.03125\n",
      " 0.109375 0.09375  0.046875 0.03125  0.171875 0.140625 0.09375  0.09375\n",
      " 0.03125  0.140625 0.015625 0.234375 0.078125 0.09375  0.0625   0.109375\n",
      " 0.15625  0.015625 0.109375 0.046875 0.078125 0.015625 0.046875 0.015625\n",
      " 0.140625 0.171875 0.078125 0.046875 0.03125  0.       0.203125 0.0625\n",
      " 0.1875   0.140625 0.109375 0.       0.171875 0.03125  0.0625   0.0625\n",
      " 0.046875 0.       0.15625  0.09375  0.015625 0.015625 0.03125  0.109375\n",
      " 0.109375 0.09375  0.15625  0.078125 0.0625   0.       0.078125 0.015625\n",
      " 0.15625  0.046875 0.140625 0.15625  0.03125  0.078125 0.015625 0.21875\n",
      " 0.0625   0.140625 0.046875 0.046875 0.09375  0.171875 0.03125  0.078125\n",
      " 0.0625   0.0625   0.046875 0.03125  0.0625   0.046875 0.015625 0.125   ]\n",
      "Precision:  [0.25       0.         0.4        0.41666667 0.5        0.6\n",
      " 0.3125     0.4        0.68421053 0.33333333 0.66666667 0.5\n",
      " 0.26666667 0.66666667 0.53846154 0.38461538 0.46153846 0.54545455\n",
      " 1.         0.66666667 0.39130435 0.47619048 0.2        0.4375\n",
      " 0.5        0.         0.58823529 0.72727273 0.22727273 0.66666667\n",
      " 0.         0.63636364 0.27777778 0.41666667 0.52380952 0.48148148\n",
      " 0.3125     0.38888889 0.83333333 0.5        0.66666667 0.42857143\n",
      " 0.71428571 0.71428571 0.7        0.66666667 0.71428571 0.78571429\n",
      " 0.8        0.75       0.25       1.         0.5625     0.8\n",
      " 0.         0.6        0.6        0.44827586 0.43478261 0.625\n",
      " 0.6        0.8        0.66666667 0.72727273 0.5        0.7\n",
      " 0.53333333 0.6875     0.61111111 0.5        0.70588235 0.42857143\n",
      " 0.         0.30769231 0.35714286 0.16666667 0.75       0.76923077\n",
      " 0.33333333 0.66666667 0.66666667 0.76923077 0.83333333 0.66666667\n",
      " 0.78571429 0.53846154 0.5        0.66666667 0.4        0.63636364\n",
      " 1.         0.42857143 0.375      0.66666667 0.38461538 0.\n",
      " 0.6        0.46153846 0.2        0.63157895 0.5        0.58333333\n",
      " 0.55555556 0.4        0.32758621 0.33333333 0.38461538 1.\n",
      " 0.39285714 0.42857143 0.57142857 0.5        0.75       0.5\n",
      " 0.57142857 0.5        0.66666667 0.52631579 0.90909091 0.33333333\n",
      " 0.77777778 0.46153846 0.375      0.22222222 0.57894737 0.45\n",
      " 0.54545455 0.66666667 0.5        0.75       0.2        0.57692308\n",
      " 0.83333333 0.66666667 0.8        0.58333333 0.43478261 0.33333333\n",
      " 0.53846154 0.375      0.41666667 0.25       0.33333333 0.2\n",
      " 0.81818182 0.78571429 0.35714286 0.3        0.13333333 0.\n",
      " 0.59090909 0.44444444 0.6        0.45       0.5        0.\n",
      " 0.84615385 0.5        0.44444444 0.66666667 0.5        0.\n",
      " 0.76923077 0.42857143 0.33333333 1.         1.         0.63636364\n",
      " 0.31818182 0.75       0.625      0.55555556 0.21052632 0.\n",
      " 0.41666667 1.         0.71428571 0.5        0.64285714 0.58823529\n",
      " 0.28571429 0.55555556 0.33333333 0.73684211 0.66666667 0.5625\n",
      " 0.75       0.42857143 0.6        0.61111111 0.28571429 0.25\n",
      " 0.57142857 0.33333333 0.75       0.4        1.         0.33333333\n",
      " 0.5        0.72727273]\n",
      "Recall:  [0.5        0.         0.4        0.45454545 0.58333333 0.66666667\n",
      " 0.55555556 0.4        0.56521739 0.22222222 0.28571429 0.3\n",
      " 0.72727273 0.33333333 0.58333333 0.45454545 0.5        0.66666667\n",
      " 0.33333333 0.28571429 0.47368421 0.4        0.25       0.41176471\n",
      " 0.5        0.         0.625      0.88888889 0.5        0.54545455\n",
      " 0.         0.5        0.35714286 0.41666667 0.84615385 0.72222222\n",
      " 0.4        0.4375     0.625      0.2        0.6        0.42857143\n",
      " 0.625      0.55555556 0.77777778 0.66666667 0.71428571 0.61111111\n",
      " 0.4        0.3        0.125      0.125      0.6        0.4\n",
      " 0.         0.66666667 1.         0.68421053 0.71428571 0.33333333\n",
      " 0.27272727 0.84210526 0.42105263 0.72727273 0.53333333 0.5\n",
      " 0.76190476 0.73333333 0.91666667 0.18181818 0.52173913 0.81818182\n",
      " 0.         0.66666667 0.5        0.16666667 0.33333333 0.71428571\n",
      " 0.14285714 0.8        0.66666667 0.83333333 0.45454545 0.57142857\n",
      " 0.64705882 0.58333333 0.5        0.4        0.35294118 0.77777778\n",
      " 0.4        0.42857143 0.2        0.25       0.41666667 0.\n",
      " 0.5        0.66666667 0.125      0.75       0.375      0.38888889\n",
      " 0.45454545 0.22222222 0.76       0.6        0.5        0.85714286\n",
      " 0.55       0.31578947 0.36363636 0.5        0.52941176 0.5\n",
      " 0.4        0.4        0.5        0.83333333 0.76923077 0.4\n",
      " 0.63636364 0.46153846 0.27272727 0.4        0.73333333 0.6\n",
      " 0.375      0.46153846 0.28571429 0.9        0.11111111 0.68181818\n",
      " 0.625      0.66666667 0.57142857 0.77777778 0.76923077 0.33333333\n",
      " 0.875      0.42857143 0.55555556 0.1        0.42857143 0.2\n",
      " 0.6        0.73333333 0.71428571 0.5        0.5        0.\n",
      " 0.68421053 0.4        0.66666667 0.75       0.4375     0.\n",
      " 0.73333333 0.22222222 0.28571429 0.4        0.27272727 0.\n",
      " 0.52631579 0.375      0.33333333 0.125      0.4        0.875\n",
      " 0.53846154 0.46153846 0.66666667 0.33333333 0.23529412 0.\n",
      " 0.45454545 0.16666667 0.66666667 0.6        0.39130435 0.625\n",
      " 0.28571429 0.625      0.33333333 0.7        0.36363636 0.40909091\n",
      " 0.42857143 0.3        0.54545455 0.6875     0.15384615 0.33333333\n",
      " 0.30769231 0.4        0.42857143 0.66666667 0.5        0.42857143\n",
      " 1.         0.72727273]\n",
      "Balanced Classification Rate:  [0.375      0.         0.4        0.43560606 0.54166667 0.63333333\n",
      " 0.43402778 0.4        0.62471396 0.27777778 0.47619048 0.4\n",
      " 0.4969697  0.5        0.56089744 0.41958042 0.48076923 0.60606061\n",
      " 0.66666667 0.47619048 0.43249428 0.43809524 0.225      0.42463235\n",
      " 0.5        0.         0.60661765 0.80808081 0.36363636 0.60606061\n",
      " 0.         0.56818182 0.31746032 0.41666667 0.68498168 0.60185185\n",
      " 0.35625    0.41319444 0.72916667 0.35       0.63333333 0.42857143\n",
      " 0.66964286 0.63492063 0.73888889 0.66666667 0.71428571 0.6984127\n",
      " 0.6        0.525      0.1875     0.5625     0.58125    0.6\n",
      " 0.         0.63333333 0.8        0.56624319 0.57453416 0.47916667\n",
      " 0.43636364 0.82105263 0.54385965 0.72727273 0.51666667 0.6\n",
      " 0.64761905 0.71041667 0.76388889 0.34090909 0.61381074 0.62337662\n",
      " 0.         0.48717949 0.42857143 0.16666667 0.54166667 0.74175824\n",
      " 0.23809524 0.73333333 0.66666667 0.80128205 0.64393939 0.61904762\n",
      " 0.71638655 0.56089744 0.5        0.53333333 0.37647059 0.70707071\n",
      " 0.7        0.42857143 0.2875     0.45833333 0.40064103 0.\n",
      " 0.55       0.56410256 0.1625     0.69078947 0.4375     0.48611111\n",
      " 0.50505051 0.31111111 0.5437931  0.46666667 0.44230769 0.92857143\n",
      " 0.47142857 0.37218045 0.46753247 0.5        0.63970588 0.5\n",
      " 0.48571429 0.45       0.58333333 0.67982456 0.83916084 0.36666667\n",
      " 0.70707071 0.46153846 0.32386364 0.31111111 0.65614035 0.525\n",
      " 0.46022727 0.56410256 0.39285714 0.825      0.15555556 0.62937063\n",
      " 0.72916667 0.66666667 0.68571429 0.68055556 0.60200669 0.33333333\n",
      " 0.70673077 0.40178571 0.48611111 0.175      0.38095238 0.2\n",
      " 0.70909091 0.75952381 0.53571429 0.4        0.31666667 0.\n",
      " 0.63755981 0.42222222 0.63333333 0.6        0.46875    0.\n",
      " 0.78974359 0.36111111 0.36507937 0.53333333 0.38636364 0.\n",
      " 0.64777328 0.40178571 0.33333333 0.5625     0.7        0.75568182\n",
      " 0.42832168 0.60576923 0.64583333 0.44444444 0.22291022 0.\n",
      " 0.43560606 0.58333333 0.69047619 0.55       0.51708075 0.60661765\n",
      " 0.28571429 0.59027778 0.33333333 0.71842105 0.51515152 0.48579545\n",
      " 0.58928571 0.36428571 0.57272727 0.64930556 0.21978022 0.29166667\n",
      " 0.43956044 0.36666667 0.58928571 0.53333333 0.75       0.38095238\n",
      " 0.75       0.72727273]\n",
      "mini_batch 350\n",
      "mini_batch 351\n",
      "mini_batch 352\n",
      "mini_batch 353\n",
      "mini_batch 354\n",
      "mini_batch 355\n",
      "mini_batch 356\n",
      "mini_batch 357\n",
      "mini_batch 358\n",
      "mini_batch 359\n",
      "mini_batch 360\n",
      "mini_batch 361\n",
      "mini_batch 362\n",
      "mini_batch 363\n",
      "mini_batch 364\n",
      "mini_batch 365\n",
      "mini_batch 366\n",
      "mini_batch 367\n",
      "mini_batch 368\n",
      "mini_batch 369\n",
      "mini_batch 370\n",
      "mini_batch 371\n",
      "mini_batch 372\n",
      "mini_batch 373\n",
      "mini_batch 374\n",
      "mini_batch 375\n",
      "Finished 5 epochs of training\n"
     ]
    }
   ],
   "source": [
    "# Track the loss across training\n",
    "total_loss = []\n",
    "avg_minibatch_loss = []\n",
    "N = 50\n",
    "\n",
    "validation_loss = []\n",
    "\n",
    "truePositives = np.zeros(200)\n",
    "falsePositives = np.zeros(200)\n",
    "falseNegatives = np.zeros(200)\n",
    "\n",
    "for epoch in range(50):\n",
    "    N_minibatch_loss = 0.0\n",
    "\n",
    "    # Get the next minibatch of images, labels for training\n",
    "    for minibatch_count, (images, labels) in enumerate(train_loader, 0):\n",
    "        print(\"mini_batch\", minibatch_count)\n",
    "        # Zero out the stored gradient (buffer) from the previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        # Perform the forward pass through the network and compute the loss\n",
    "        outputs = net(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        # Automagically compute the gradients and backpropagate the loss through the network\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        # Add this iteration's loss to the total_loss\n",
    "        total_loss.append(loss.item())\n",
    "        N_minibatch_loss += loss\n",
    "                    \n",
    "                \n",
    "        if minibatch_count % N == N-1:\n",
    "            #Print the loss averaged over the last N mini-batches\n",
    "            N_minibatch_loss /= N\n",
    "            print('Epoch %d' % (epoch + 1))\n",
    "            print('average minibatch %d loss: %.3f' % (minibatch_count+1, N_minibatch_loss))\n",
    "            print('')\n",
    "            printStatistics(labels, outputs)\n",
    "\n",
    "            # Add the averaged loss over N minibatches and reset the counter\n",
    "            avg_minibatch_loss.append(N_minibatch_loss)\n",
    "            N_minibatch_loss = 0.0\n",
    "\n",
    "    print(\"Finished\", epoch + 1, \"epochs of training\")\n",
    "    # TODO: Implement validation #with torch.no_grad():\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        for minibatch_count, (images, labels) in enumerate(validation_loader, 0):\n",
    "            print(\"Validation mini_batch\", minibatch_count)\n",
    "            images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            valid_loss += criterion(outputs, labels)\n",
    "        validation_loss.append(valid_loss)\n",
    "        \n",
    "    if epoch >= 5:\n",
    "        early_stop = True\n",
    "        for i in range(5):\n",
    "            if validation_loss[epoch - i] < validation_loss[epoch - i - 1]:\n",
    "                early_stop = False\n",
    "        \n",
    "        if early_stop == True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the test dataset\n",
    "test_dataset = loader('test.csv',transform=transform)\n",
    "test_size = len(test_dataset)\n",
    "test_indices = list(range(test_size))\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
    "                                           sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluation metrics\n",
    "total_test_loss = []\n",
    "N = 50\n",
    "\n",
    "truePositives = np.zeros(200)\n",
    "falsePositives = np.zeros(200)\n",
    "falseNegatives = np.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_batch 0\n",
      "mini_batch 1\n",
      "mini_batch 2\n",
      "mini_batch 3\n",
      "mini_batch 4\n",
      "mini_batch 5\n",
      "mini_batch 6\n",
      "mini_batch 7\n",
      "mini_batch 8\n",
      "mini_batch 9\n",
      "mini_batch 10\n",
      "mini_batch 11\n",
      "mini_batch 12\n",
      "mini_batch 13\n",
      "mini_batch 14\n",
      "mini_batch 15\n",
      "mini_batch 16\n",
      "mini_batch 17\n",
      "mini_batch 18\n",
      "mini_batch 19\n",
      "mini_batch 20\n",
      "mini_batch 21\n",
      "mini_batch 22\n",
      "mini_batch 23\n",
      "mini_batch 24\n",
      "mini_batch 25\n",
      "mini_batch 26\n",
      "mini_batch 27\n",
      "mini_batch 28\n",
      "mini_batch 29\n",
      "mini_batch 30\n",
      "mini_batch 31\n",
      "mini_batch 32\n",
      "mini_batch 33\n",
      "mini_batch 34\n",
      "mini_batch 35\n",
      "mini_batch 36\n",
      "mini_batch 37\n",
      "mini_batch 38\n",
      "mini_batch 39\n",
      "mini_batch 40\n",
      "mini_batch 41\n",
      "mini_batch 42\n",
      "mini_batch 43\n",
      "mini_batch 44\n",
      "mini_batch 45\n",
      "mini_batch 46\n",
      "mini_batch 47\n",
      "mini_batch 48\n",
      "mini_batch 49\n",
      "mini_batch 50\n",
      "True Positives:  [19.  1.  9.  4. 10.  7. 11.  4. 16.  8.  4.  4. 13.  3. 12. 11.  8.  7.\n",
      "  6.  8.  8.  6.  5. 17.  9.  1.  7. 12. 21.  6.  5.  6. 14.  5. 20. 13.\n",
      "  8. 11.  6.  8.  7.  2.  4.  7.  4.  8.  7. 11.  5. 10.  5.  6. 13.  9.\n",
      "  3.  4.  6. 20. 12.  5.  1. 14.  7.  9. 15.  9. 11. 14. 18.  2.  7.  7.\n",
      "  1. 11. 12.  7.  4. 16.  4.  1. 15. 14.  9.  3. 15.  6.  8.  1.  9. 10.\n",
      "  4.  4. 11. 11. 13.  0.  3.  8.  5. 22.  9. 13. 11.  2. 18.  9. 12.  8.\n",
      " 24. 10.  8.  9.  5. 18.  3.  9.  8. 20. 12.  4.  8. 13. 12.  0. 13.  4.\n",
      " 12.  8.  6.  5.  4. 10.  7. 13.  7. 13. 15.  7.  6.  4.  9.  1.  9.  5.\n",
      " 10. 19.  8.  9. 17.  1. 17.  8. 15. 11. 10.  1. 15.  7.  9.  5.  5.  6.\n",
      "  9. 12.  2.  4.  7. 14. 15.  8. 17. 13. 15.  5.  8.  8. 18.  4. 23. 17.\n",
      "  6.  4.  5. 15.  9. 15.  2.  5.  9. 14.  3. 12.  2. 16.  7.  4.  4. 12.\n",
      "  6. 14.]\n",
      "False Positives:  [29.  1.  5.  6. 17.  1.  2.  9.  4. 28.  2.  1.  2.  3.  4.  6.  4.  1.\n",
      "  0.  0.  6.  5. 11. 22. 10.  3. 18.  5. 10.  7.  3.  0. 42.  9. 10.  4.\n",
      " 14. 11.  1. 15.  2.  2.  0.  2.  2.  2.  0.  3.  5.  8. 18.  4.  4.  1.\n",
      "  3. 12.  7.  4. 12. 15.  3.  5.  4.  7. 26. 13.  5.  2.  9.  3.  0.  6.\n",
      "  0.  5.  9. 10.  1. 14. 16.  2.  9.  2.  9.  2. 11.  4.  1.  9.  4.  3.\n",
      "  2.  6. 14.  7.  4.  1.  1.  2.  5.  2.  8.  9. 15.  4. 27. 13.  2.  4.\n",
      " 36. 18.  5. 13.  1. 11.  7.  4.  4.  6.  3.  9.  1. 24. 16.  3.  6.  3.\n",
      " 13.  3.  6.  1. 11.  3.  7. 12.  4.  7.  5. 12.  3.  1.  2.  2.  6. 12.\n",
      "  3. 14.  5.  1.  9.  1.  2.  8.  3.  8.  2.  3. 15. 13.  5.  0.  5. 24.\n",
      "  5. 10.  1.  1. 20.  6.  9. 11.  2. 11. 16.  2.  3.  8. 10.  2. 11.  1.\n",
      "  7.  7.  2. 11.  8.  5.  1.  7.  3. 18.  3. 32.  0.  5.  4.  4.  5. 23.\n",
      "  0. 23.]\n",
      "False Negatives:  [13.  8.  5. 11.  3.  4. 14.  6. 11.  3.  4.  9. 15.  3.  7.  4.  4. 15.\n",
      "  7.  8. 23. 26. 16. 12.  8.  4.  9.  6.  4.  3.  5. 12.  8.  8.  7. 11.\n",
      " 22.  7.  6.  7.  6.  9.  8.  2. 11.  6.  3.  5.  5.  4. 11.  7.  7.  5.\n",
      "  4.  5.  6.  4.  7.  9. 10.  5. 15. 12.  5.  8. 19.  4.  2.  7. 17. 12.\n",
      "  6.  4.  8.  6.  5.  1.  6.  5.  3.  6.  4.  5.  7. 14. 11. 12. 16.  3.\n",
      "  3.  6. 18.  4.  8.  9.  5.  7.  4.  5. 14. 11.  4.  5. 13.  9.  7.  2.\n",
      "  6. 11.  4.  4.  9.  3. 10.  6.  5.  3.  7.  8.  6.  6.  2. 13.  9. 12.\n",
      "  8.  7.  8.  6.  8. 12.  1.  1.  4.  3.  5.  4.  4.  6. 11. 12.  1.  5.\n",
      "  3.  7.  3.  7.  4.  5.  7.  5.  9.  9. 16.  5.  0.  7.  9.  7. 11.  2.\n",
      "  9. 15.  4.  6.  3.  3. 10.  9.  2.  8. 11.  7.  6.  3.  4.  5.  7. 11.\n",
      "  4.  7.  1.  8.  7.  5.  9. 11.  6.  9. 18. 14.  5.  2.  4.  4.  5. 10.\n",
      "  0.  3.]\n",
      "Accuracy:  [0.296875 0.015625 0.140625 0.0625   0.15625  0.109375 0.171875 0.0625\n",
      " 0.25     0.125    0.0625   0.0625   0.203125 0.046875 0.1875   0.171875\n",
      " 0.125    0.109375 0.09375  0.125    0.125    0.09375  0.078125 0.265625\n",
      " 0.140625 0.015625 0.109375 0.1875   0.328125 0.09375  0.078125 0.09375\n",
      " 0.21875  0.078125 0.3125   0.203125 0.125    0.171875 0.09375  0.125\n",
      " 0.109375 0.03125  0.0625   0.109375 0.0625   0.125    0.109375 0.171875\n",
      " 0.078125 0.15625  0.078125 0.09375  0.203125 0.140625 0.046875 0.0625\n",
      " 0.09375  0.3125   0.1875   0.078125 0.015625 0.21875  0.109375 0.140625\n",
      " 0.234375 0.140625 0.171875 0.21875  0.28125  0.03125  0.109375 0.109375\n",
      " 0.015625 0.171875 0.1875   0.109375 0.0625   0.25     0.0625   0.015625\n",
      " 0.234375 0.21875  0.140625 0.046875 0.234375 0.09375  0.125    0.015625\n",
      " 0.140625 0.15625  0.0625   0.0625   0.171875 0.171875 0.203125 0.\n",
      " 0.046875 0.125    0.078125 0.34375  0.140625 0.203125 0.171875 0.03125\n",
      " 0.28125  0.140625 0.1875   0.125    0.375    0.15625  0.125    0.140625\n",
      " 0.078125 0.28125  0.046875 0.140625 0.125    0.3125   0.1875   0.0625\n",
      " 0.125    0.203125 0.1875   0.       0.203125 0.0625   0.1875   0.125\n",
      " 0.09375  0.078125 0.0625   0.15625  0.109375 0.203125 0.109375 0.203125\n",
      " 0.234375 0.109375 0.09375  0.0625   0.140625 0.015625 0.140625 0.078125\n",
      " 0.15625  0.296875 0.125    0.140625 0.265625 0.015625 0.265625 0.125\n",
      " 0.234375 0.171875 0.15625  0.015625 0.234375 0.109375 0.140625 0.078125\n",
      " 0.078125 0.09375  0.140625 0.1875   0.03125  0.0625   0.109375 0.21875\n",
      " 0.234375 0.125    0.265625 0.203125 0.234375 0.078125 0.125    0.125\n",
      " 0.28125  0.0625   0.359375 0.265625 0.09375  0.0625   0.078125 0.234375\n",
      " 0.140625 0.234375 0.03125  0.078125 0.140625 0.21875  0.046875 0.1875\n",
      " 0.03125  0.25     0.109375 0.0625   0.0625   0.1875   0.09375  0.21875 ]\n",
      "Precision:  [0.39583333 0.5        0.64285714 0.4        0.37037037 0.875\n",
      " 0.84615385 0.30769231 0.8        0.22222222 0.66666667 0.8\n",
      " 0.86666667 0.5        0.75       0.64705882 0.66666667 0.875\n",
      " 1.         1.         0.57142857 0.54545455 0.3125     0.43589744\n",
      " 0.47368421 0.25       0.28       0.70588235 0.67741935 0.46153846\n",
      " 0.625      1.         0.25       0.35714286 0.66666667 0.76470588\n",
      " 0.36363636 0.5        0.85714286 0.34782609 0.77777778 0.5\n",
      " 1.         0.77777778 0.66666667 0.8        1.         0.78571429\n",
      " 0.5        0.55555556 0.2173913  0.6        0.76470588 0.9\n",
      " 0.5        0.25       0.46153846 0.83333333 0.5        0.25\n",
      " 0.25       0.73684211 0.63636364 0.5625     0.36585366 0.40909091\n",
      " 0.6875     0.875      0.66666667 0.4        1.         0.53846154\n",
      " 1.         0.6875     0.57142857 0.41176471 0.8        0.53333333\n",
      " 0.2        0.33333333 0.625      0.875      0.5        0.6\n",
      " 0.57692308 0.6        0.88888889 0.1        0.69230769 0.76923077\n",
      " 0.66666667 0.4        0.44       0.61111111 0.76470588 0.\n",
      " 0.75       0.8        0.5        0.91666667 0.52941176 0.59090909\n",
      " 0.42307692 0.33333333 0.4        0.40909091 0.85714286 0.66666667\n",
      " 0.4        0.35714286 0.61538462 0.40909091 0.83333333 0.62068966\n",
      " 0.3        0.69230769 0.66666667 0.76923077 0.8        0.30769231\n",
      " 0.88888889 0.35135135 0.42857143 0.         0.68421053 0.57142857\n",
      " 0.48       0.72727273 0.5        0.83333333 0.26666667 0.76923077\n",
      " 0.5        0.52       0.63636364 0.65       0.75       0.36842105\n",
      " 0.66666667 0.8        0.81818182 0.33333333 0.6        0.29411765\n",
      " 0.76923077 0.57575758 0.61538462 0.9        0.65384615 0.5\n",
      " 0.89473684 0.5        0.83333333 0.57894737 0.83333333 0.25\n",
      " 0.5        0.35       0.64285714 1.         0.5        0.2\n",
      " 0.64285714 0.54545455 0.66666667 0.8        0.25925926 0.7\n",
      " 0.625      0.42105263 0.89473684 0.54166667 0.48387097 0.71428571\n",
      " 0.72727273 0.5        0.64285714 0.66666667 0.67647059 0.94444444\n",
      " 0.46153846 0.36363636 0.71428571 0.57692308 0.52941176 0.75\n",
      " 0.66666667 0.41666667 0.75       0.4375     0.5        0.27272727\n",
      " 1.         0.76190476 0.63636364 0.5        0.44444444 0.34285714\n",
      " 1.         0.37837838]\n",
      "Recall:  [0.59375    0.11111111 0.64285714 0.26666667 0.76923077 0.63636364\n",
      " 0.44       0.4        0.59259259 0.72727273 0.5        0.30769231\n",
      " 0.46428571 0.5        0.63157895 0.73333333 0.66666667 0.31818182\n",
      " 0.46153846 0.5        0.25806452 0.1875     0.23809524 0.5862069\n",
      " 0.52941176 0.2        0.4375     0.66666667 0.84       0.66666667\n",
      " 0.5        0.33333333 0.63636364 0.38461538 0.74074074 0.54166667\n",
      " 0.26666667 0.61111111 0.5        0.53333333 0.53846154 0.18181818\n",
      " 0.33333333 0.77777778 0.26666667 0.57142857 0.7        0.6875\n",
      " 0.5        0.71428571 0.3125     0.46153846 0.65       0.64285714\n",
      " 0.42857143 0.44444444 0.5        0.83333333 0.63157895 0.35714286\n",
      " 0.09090909 0.73684211 0.31818182 0.42857143 0.75       0.52941176\n",
      " 0.36666667 0.77777778 0.9        0.22222222 0.29166667 0.36842105\n",
      " 0.14285714 0.73333333 0.6        0.53846154 0.44444444 0.94117647\n",
      " 0.4        0.16666667 0.83333333 0.7        0.69230769 0.375\n",
      " 0.68181818 0.3        0.42105263 0.07692308 0.36       0.76923077\n",
      " 0.57142857 0.4        0.37931034 0.73333333 0.61904762 0.\n",
      " 0.375      0.53333333 0.55555556 0.81481481 0.39130435 0.54166667\n",
      " 0.73333333 0.28571429 0.58064516 0.5        0.63157895 0.8\n",
      " 0.8        0.47619048 0.66666667 0.69230769 0.35714286 0.85714286\n",
      " 0.23076923 0.6        0.61538462 0.86956522 0.63157895 0.33333333\n",
      " 0.57142857 0.68421053 0.85714286 0.         0.59090909 0.25\n",
      " 0.6        0.53333333 0.42857143 0.45454545 0.33333333 0.45454545\n",
      " 0.875      0.92857143 0.63636364 0.8125     0.75       0.63636364\n",
      " 0.6        0.4        0.45       0.07692308 0.9        0.5\n",
      " 0.76923077 0.73076923 0.72727273 0.5625     0.80952381 0.16666667\n",
      " 0.70833333 0.61538462 0.625      0.55       0.38461538 0.16666667\n",
      " 1.         0.5        0.5        0.41666667 0.3125     0.75\n",
      " 0.5        0.44444444 0.33333333 0.4        0.7        0.82352941\n",
      " 0.6        0.47058824 0.89473684 0.61904762 0.57692308 0.41666667\n",
      " 0.57142857 0.72727273 0.81818182 0.44444444 0.76666667 0.60714286\n",
      " 0.6        0.36363636 0.83333333 0.65217391 0.5625     0.75\n",
      " 0.18181818 0.3125     0.6        0.60869565 0.14285714 0.46153846\n",
      " 0.28571429 0.88888889 0.63636364 0.5        0.44444444 0.54545455\n",
      " 1.         0.82352941]\n",
      "Balanced Classification Rate:  [0.49479167 0.30555556 0.64285714 0.33333333 0.56980057 0.75568182\n",
      " 0.64307692 0.35384615 0.6962963  0.47474747 0.58333333 0.55384615\n",
      " 0.66547619 0.5        0.69078947 0.69019608 0.66666667 0.59659091\n",
      " 0.73076923 0.75       0.41474654 0.36647727 0.27529762 0.51105217\n",
      " 0.50154799 0.225      0.35875    0.68627451 0.75870968 0.56410256\n",
      " 0.5625     0.66666667 0.44318182 0.37087912 0.7037037  0.65318627\n",
      " 0.31515152 0.55555556 0.67857143 0.44057971 0.65811966 0.34090909\n",
      " 0.66666667 0.77777778 0.46666667 0.68571429 0.85       0.73660714\n",
      " 0.5        0.63492063 0.26494565 0.53076923 0.70735294 0.77142857\n",
      " 0.46428571 0.34722222 0.48076923 0.83333333 0.56578947 0.30357143\n",
      " 0.17045455 0.73684211 0.47727273 0.49553571 0.55792683 0.46925134\n",
      " 0.52708333 0.82638889 0.78333333 0.31111111 0.64583333 0.4534413\n",
      " 0.57142857 0.71041667 0.58571429 0.47511312 0.62222222 0.7372549\n",
      " 0.3        0.25       0.72916667 0.7875     0.59615385 0.4875\n",
      " 0.62937063 0.45       0.65497076 0.08846154 0.52615385 0.76923077\n",
      " 0.61904762 0.4        0.40965517 0.67222222 0.69187675 0.\n",
      " 0.5625     0.66666667 0.52777778 0.86574074 0.46035806 0.56628788\n",
      " 0.57820513 0.30952381 0.49032258 0.45454545 0.7443609  0.73333333\n",
      " 0.6        0.41666667 0.64102564 0.5506993  0.5952381  0.73891626\n",
      " 0.26538462 0.64615385 0.64102564 0.81939799 0.71578947 0.32051282\n",
      " 0.73015873 0.51778094 0.64285714 0.         0.63755981 0.41071429\n",
      " 0.54       0.63030303 0.46428571 0.64393939 0.3        0.61188811\n",
      " 0.6875     0.72428571 0.63636364 0.73125    0.75       0.50239234\n",
      " 0.63333333 0.6        0.63409091 0.20512821 0.75       0.39705882\n",
      " 0.76923077 0.6532634  0.67132867 0.73125    0.73168498 0.33333333\n",
      " 0.80153509 0.55769231 0.72916667 0.56447368 0.60897436 0.20833333\n",
      " 0.75       0.425      0.57142857 0.70833333 0.40625    0.475\n",
      " 0.57142857 0.49494949 0.5        0.6        0.47962963 0.76176471\n",
      " 0.6125     0.44582043 0.89473684 0.58035714 0.53039702 0.56547619\n",
      " 0.64935065 0.61363636 0.73051948 0.55555556 0.72156863 0.77579365\n",
      " 0.53076923 0.36363636 0.77380952 0.61454849 0.54595588 0.75\n",
      " 0.42424242 0.36458333 0.675      0.52309783 0.32142857 0.36713287\n",
      " 0.64285714 0.82539683 0.63636364 0.5        0.44444444 0.44415584\n",
      " 1.         0.6009539 ]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    # Get the next minibatch of images, labels for training\n",
    "    for minibatch_count, (images, labels) in enumerate(test_loader, 0):\n",
    "        print(\"mini_batch\", minibatch_count)\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        # Perform the forward pass through the network and compute the loss\n",
    "        outputs = net(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Add this iteration's loss to the total_loss\n",
    "        total_test_loss.append(loss.item())\n",
    "\n",
    "        loadStatistics(labels, outputs)\n",
    "        \n",
    "    printStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
